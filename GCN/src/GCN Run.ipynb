{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db71bc80-633c-4533-b9cf-def4e7b08c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import pprint\n",
    "from torch.optim import Adam\n",
    "from torch.optim import SGD\n",
    "from torch.optim import Adadelta\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996274d0-1487-4134-a840-31d665b4d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    y_pred = output.max(1)[1].type_as(labels)\n",
    "    correct = y_pred.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "\n",
    "def prepare_dataset(labels, num_classes, configg):\n",
    "    \"\"\" Splits the loaded dataset into train/validation/test sets. \"\"\"\n",
    "    if not configg.follow_paper:\n",
    "        # Follow train/val/test indices as in the official implementation\n",
    "        # on GitHub: https://github.com/tkipf/pygcn\n",
    "        train_set = range(140)\n",
    "        validation_set = range(200, 500)\n",
    "        test_set = range(500, 1500)\n",
    "    else:\n",
    "        # https://arxiv.org/pdf/1609.02907.pdf\n",
    "        # The original paper proposes that the training set is composed\n",
    "        # out of 20 samples per class -> 140 samples, but the indices\n",
    "        # above (range(140)) do not contain 20 samples per class\n",
    "        # The remaining val/test indices were selected empirically\n",
    "        classes = [ind for ind in range(num_classes)]\n",
    "        train_set = []\n",
    "\n",
    "        # Construct train set (indices) out of 20 samples per each class\n",
    "        for class_label in classes:\n",
    "            target_indices = torch.nonzero(labels == class_label, as_tuple=False).tolist()\n",
    "            train_set += [ind[0] for ind in target_indices[:configg.train_size_per_class]]\n",
    "\n",
    "        # Extract the remaining samples\n",
    "        validation_test_set = [ind for ind in range(len(labels)) if ind not in train_set]\n",
    "        # Split the remaining samples into validation/test set\n",
    "        validation_set = validation_test_set[:configg.validation_size]\n",
    "        test_set = validation_test_set[configg.validation_size:configg.validation_size+configg.test_size]\n",
    "\n",
    "    return train_set, validation_set, test_set\n",
    "\n",
    "\n",
    "def enumerate_labels(labels):\n",
    "    \"\"\" Converts the labels from the original\n",
    "        string form to the integer [0:MaxLabels-1]\n",
    "    \"\"\"\n",
    "    unique = list(set(labels))\n",
    "    labels = np.array([unique.index(label) for label in labels])\n",
    "    return labels\n",
    "\n",
    "\n",
    "def normalize_adjacency(adj):\n",
    "    \"\"\" Normalizes the adjacency matrix according to the\n",
    "        paper by Kipf et al.\n",
    "        https://arxiv.org/pdf/1609.02907.pdf\n",
    "    \"\"\"\n",
    "    adj = adj + sparse.eye(adj.shape[0])\n",
    "\n",
    "    node_degrees = np.array(adj.sum(1))\n",
    "    node_degrees = np.power(node_degrees, -0.5).flatten()\n",
    "    node_degrees[np.isinf(node_degrees)] = 0.0\n",
    "    node_degrees[np.isnan(node_degrees)] = 0.0\n",
    "    degree_matrix = sparse.diags(node_degrees, dtype=np.float32)\n",
    "\n",
    "    adj = degree_matrix @ adj @ degree_matrix\n",
    "    return adj\n",
    "\n",
    "\n",
    "def convert_scipy_to_torch_sparse(matrix):\n",
    "    matrix_helper_coo = matrix.tocoo().astype('float32')\n",
    "    data = torch.FloatTensor(matrix_helper_coo.data)\n",
    "    rows = torch.LongTensor(matrix_helper_coo.row)\n",
    "    cols = torch.LongTensor(matrix_helper_coo.col)\n",
    "    indices = torch.vstack([rows, cols])\n",
    "\n",
    "    shape = torch.Size(matrix_helper_coo.shape)\n",
    "    matrix = torch.sparse.FloatTensor(indices, data, shape)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def load_data(configg):\n",
    "    \"\"\" Loads the graph data and stores them using\n",
    "        efficient sparse matrices approach.\n",
    "    \"\"\"\n",
    "    print(\"Loading Cora dataset...\")\n",
    "    ###############################\n",
    "    # Loading Graph Nodes Data\n",
    "    ###############################\n",
    "    raw_nodes_data = np.genfromtxt(configg.nodes_path, dtype=\"str\")\n",
    "    raw_node_ids = raw_nodes_data[:, 0].astype('int32')  # unique identifier of each node\n",
    "    raw_node_labels = raw_nodes_data[:, -1]\n",
    "    labels_enumerated = enumerate_labels(raw_node_labels)  # target labels as integers\n",
    "    node_features = sparse.csr_matrix(raw_nodes_data[:, 1:-1], dtype=\"float32\")\n",
    "\n",
    "    ################################\n",
    "    # Loading Graph Structure Data\n",
    "    ################################\n",
    "    ids_ordered = {raw_id: order for order, raw_id in enumerate(raw_node_ids)}\n",
    "    raw_edges_data = np.genfromtxt(configg.edges_path, dtype=\"int32\")\n",
    "    edges_ordered = np.array(list(map(ids_ordered.get, raw_edges_data.flatten())),\n",
    "                             dtype='int32').reshape(raw_edges_data.shape)\n",
    "    ####################\n",
    "    # ADJACENCY MATRIX\n",
    "    ####################\n",
    "    adj = sparse.coo_matrix((np.ones(edges_ordered.shape[0]), (edges_ordered[:, 0], edges_ordered[:, 1])),\n",
    "                            shape=(labels_enumerated.shape[0], labels_enumerated.shape[0]),\n",
    "                            dtype=np.float32)\n",
    "    # Make the adjacency matrix symmetric\n",
    "    adj = adj + adj.T.multiply(adj.T > adj)\n",
    "    adj = normalize_adjacency(adj)\n",
    "\n",
    "    ####################################\n",
    "    # Adapt the data to PyTorch format\n",
    "    ####################################\n",
    "    features = torch.FloatTensor(node_features.toarray())\n",
    "    labels = torch.LongTensor(labels_enumerated)\n",
    "    adj = convert_scipy_to_torch_sparse(adj)\n",
    "\n",
    "    print(\"Dataset loaded.\")\n",
    "\n",
    "    return features, labels, adj, edges_ordered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "738fbb55-0e2d-4b16-bbbc-c451e9dc8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--cuda\", type=bool, default=use_cuda)\n",
    "parser.add_argument(\"--nodes_path\", type=str, default=\"../data/cora.content\")\n",
    "parser.add_argument(\"--edges_path\", type=str, default=\"../data/cora.cites\")\n",
    "parser.add_argument(\"--hidden_dim\", type=int, default=16)\n",
    "parser.add_argument(\"--dropout\", type=float, default=0.5)\n",
    "parser.add_argument(\"--use_bias\", type=bool, default=True)\n",
    "parser.add_argument(\"--train_size_per_class\", type=int, default=20)\n",
    "parser.add_argument(\"--validation_size\", type=int, default=500)\n",
    "parser.add_argument(\"--test_size\", type=int, default=1000)\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-2)\n",
    "parser.add_argument(\"--weight_decay\", type=float, default=5e-3)\n",
    "parser.add_argument(\"--patience\", type=int, default=10)\n",
    "parser.add_argument(\"--epochs\", type=int, default=200)\n",
    "parser.add_argument(\"--use_early_stopping\", type=bool, default=True)\n",
    "parser.add_argument(\"--multiple_runs\", type=bool, default=False)\n",
    "parser.add_argument(\"--num_of_runs\", type=int, default=100)\n",
    "parser.add_argument(\"--follow_paper\", type=bool, default=True)\n",
    "\n",
    "configg = parser.parse_args(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4af9265-cc2f-4aa8-94dc-40fa1d36d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, use_bias=True):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(torch.zeros(size=(in_features, out_features))))\n",
    "        if use_bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(torch.zeros(size=(out_features,))))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        if self.bias is not None:\n",
    "            nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            x += self.bias\n",
    "\n",
    "        return torch.sparse.mm(adj, x)\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, node_features, hidden_dim, num_classes, dropout, use_bias=True):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gcn_1 = GCNLayer(node_features, hidden_dim, use_bias)\n",
    "        self.gcn_2 = GCNLayer(hidden_dim, num_classes, use_bias)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        self.gcn_1.initialize_weights()\n",
    "        self.gcn_2.initialize_weights()\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gcn_1(x, adj))\n",
    "        x = self.dropout(x)\n",
    "        x = self.gcn_2(x, adj)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04c5788-f5ab-4d9e-95ad-a82d9a01defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, features, labels, adj, train_set_ind, val_set_ind, configg, epochh, optimizerval, lrval):\n",
    "    if configg.cuda:\n",
    "        model.cuda()\n",
    "        adj = adj.cuda()\n",
    "        features = features.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    if optimizerval == 'Adam':\n",
    "        optimizer = Adam(model.parameters(), lr=lrval)\n",
    "    elif optimizerval == 'SGD':\n",
    "        optimizer = SGD(model.parameters(), lr=lrval, momentum=0.9)\n",
    "    elif optimizerval == 'Adadelta':\n",
    "        optimizer = Adadelta(model.parameters(), lr=lrval, weight_decay=configg.weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    validation_acc = []\n",
    "    validation_loss = []\n",
    "\n",
    "    if configg.use_early_stopping:\n",
    "        last_min_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        stopped_early = False\n",
    "\n",
    "    t_start = time.time()\n",
    "    for epoch in range(epochh):\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "\n",
    "        y_pred = model(features, adj)\n",
    "        train_loss = criterion(y_pred[train_set_ind], labels[train_set_ind])\n",
    "        train_acc = accuracy(y_pred[train_set_ind], labels[train_set_ind])\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        wandb.log({\"training_acc\": train_acc})\n",
    "        wandb.log({\"training_loss\": train_loss.item()})\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_loss = criterion(y_pred[val_set_ind], labels[val_set_ind])\n",
    "            val_acc = accuracy(y_pred[val_set_ind], labels[val_set_ind])\n",
    "\n",
    "            validation_loss.append(val_loss.item())\n",
    "            validation_acc.append(val_acc)\n",
    "            wandb.log({\"epoch\": epoch})\n",
    "            wandb.log({\"val_acc\": val_acc})\n",
    "            wandb.log({\"val_loss\": val_loss.item()})\n",
    "            if configg.use_early_stopping:\n",
    "                if val_loss < last_min_val_loss:\n",
    "                    last_min_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter == configg.patience:\n",
    "                        stopped_early = True\n",
    "                        t_end = time.time()\n",
    "\n",
    "        if not configg.multiple_runs:\n",
    "            print(\" | \".join([f\"Epoch: {epoch:4d}\", f\"Train loss: {train_loss.item():.3f}\",\n",
    "                              f\"Train acc: {train_acc:.2f}\",\n",
    "                              f\"Val loss: {val_loss.item():.3f}\",\n",
    "                              f\"Val acc: {val_acc:.2f}\"]))\n",
    "\n",
    "        if configg.use_early_stopping and stopped_early:\n",
    "            break\n",
    "\n",
    "    if (not configg.multiple_runs) and configg.use_early_stopping and stopped_early:\n",
    "        print(f\"EARLY STOPPING condition met. Stopped at epoch: {epoch}.\")\n",
    "    else:\n",
    "        t_end = time.time()\n",
    "\n",
    "    if not configg.multiple_runs:\n",
    "        print(f\"Total training time: {t_end-t_start:.2f} seconds\")\n",
    "\n",
    "    # print(type(validation_acc))\n",
    "    # print(validation_acc)\n",
    "\n",
    "    # print(type(validation_loss))\n",
    "    # print(validation_loss)\n",
    "\n",
    "    return validation_acc, validation_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65749430-eb4f-410d-91d6-d39b1e6cfafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(model, features, labels, adj, test_ind, configg):\n",
    "    if configg.cuda:\n",
    "        model.cuda()\n",
    "        adj = adj.cuda()\n",
    "        features = features.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        y_pred = model(features, adj)\n",
    "        test_loss = criterion(y_pred[test_ind], labels[test_ind])\n",
    "        test_acc = accuracy(y_pred[test_ind], labels[test_ind])\n",
    "\n",
    "    if not configg.multiple_runs:\n",
    "        print()\n",
    "        print(f\"Test loss: {test_loss:.3f}  |  Test acc: {test_acc:.2f}\")\n",
    "        return y_pred\n",
    "    else:\n",
    "        return test_acc.item(), test_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2335f01-b0e4-49ba-b541-46deec0c0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_runs(model, features, labels, adj, indices, configg, training_loop, evaluate_on_test):\n",
    "    train_set_ind, val_set_ind, test_set_ind = indices\n",
    "    acc = []\n",
    "    loss = []\n",
    "\n",
    "    t1 = time.time()\n",
    "    for i in range(configg.num_of_runs):\n",
    "        print(\"Run:\", i+1)\n",
    "        model.initialize_weights()\n",
    "        training_loop(model, features, labels, adj,\n",
    "                      train_set_ind, val_set_ind, configg)\n",
    "\n",
    "        acc_curr, loss_curr = evaluate_on_test(model, features, labels,\n",
    "                                               adj, test_set_ind, configg)\n",
    "        acc.append(acc_curr)\n",
    "        loss.append(loss_curr)\n",
    "\n",
    "    print(f\"ACC:  mean: {np.mean(acc):.2f} | std: {np.std(acc):.2f}\")\n",
    "    print(f\"LOSS: mean: {np.mean(loss):.2f} | std: {np.std(loss):.2f}\")\n",
    "    print(f\"Total training time: {time.time()-t1:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2fdc83e-893c-43d3-8e90-aec08af7ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color map for each class\n",
    "cora_label_to_color_map = {0: \"red\", 1: \"blue\", 2: \"green\",\n",
    "                           3: \"orange\", 4: \"yellow\", 5: \"pink\", 6: \"gray\"}\n",
    "\n",
    "\n",
    "def visualize_embedding_tSNE(labels, out_features, num_classes):\n",
    "    \"\"\" https://github.com/gordicaleksa/pytorch-GAT \"\"\"\n",
    "    node_labels = labels.cpu().numpy()\n",
    "    out_features = out_features.cpu().numpy()\n",
    "    t_sne_embeddings = TSNE(n_components=2, perplexity=30, method='barnes_hut').fit_transform(out_features)\n",
    "\n",
    "    plt.figure()\n",
    "    for class_id in range(num_classes):\n",
    "        plt.scatter(t_sne_embeddings[node_labels == class_id, 0],\n",
    "                    t_sne_embeddings[node_labels == class_id, 1], s=20,\n",
    "                    color=cora_label_to_color_map[class_id],\n",
    "                    edgecolors='black', linewidths=0.15)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"t-SNE projection of the learned features\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_graph(edges, node_labels, save=False):\n",
    "    \"\"\" Most of the code within this function was taken and \"fine-tuned\"\n",
    "        from the Aleksa Gordić's repo:\n",
    "        https://github.com/gordicaleksa/pytorch-GAT\n",
    "    \"\"\"\n",
    "    num_of_nodes = len(node_labels)\n",
    "    edge_index_tuples = list(zip(edges[:, 0], edges[:, 1]))\n",
    "\n",
    "    ig_graph = ig.Graph()\n",
    "    ig_graph.add_vertices(num_of_nodes)\n",
    "    ig_graph.add_edges(edge_index_tuples)\n",
    "\n",
    "    # Prepare the visualization settings dictionary\n",
    "    visual_style = {\"bbox\": (1000, 1000), \"margin\": 50}\n",
    "\n",
    "    # Normalization of the edge weights\n",
    "    edge_weights_raw = np.clip(np.log(np.asarray(ig_graph.edge_betweenness()) + 1e-16), a_min=0, a_max=None)\n",
    "    edge_weights_raw_normalized = edge_weights_raw / np.max(edge_weights_raw)\n",
    "    edge_weights = [w/3 for w in edge_weights_raw_normalized]\n",
    "    visual_style[\"edge_width\"] = edge_weights\n",
    "\n",
    "    # A simple heuristic for vertex size. Multiplying with 0.75 gave decent visualization\n",
    "    visual_style[\"vertex_size\"] = [0.75*deg for deg in ig_graph.degree()]\n",
    "\n",
    "    visual_style[\"vertex_color\"] = [cora_label_to_color_map[label] for label in node_labels]\n",
    "\n",
    "    # Display the cora graph\n",
    "    visual_style[\"layout\"] = ig_graph.layout_kamada_kawai()\n",
    "    out = ig.plot(ig_graph, **visual_style)\n",
    "\n",
    "    if save:\n",
    "        out.save(\"cora_visualized.png\")\n",
    "\n",
    "\n",
    "def visualize_validation_performance(val_acc, val_loss):\n",
    "    val_acc = [v.cpu().item() if isinstance(v, torch.Tensor) else v for v in val_acc]\n",
    "    val_loss = [v.cpu().item() if isinstance(v, torch.Tensor) else v for v in val_loss]\n",
    "\n",
    "    f, axs = plt.subplots(1, 2, figsize=(13, 5.5))\n",
    "    axs[0].plot(val_loss, linewidth=2, color=\"red\")\n",
    "    axs[0].set_title(\"Validation loss\")\n",
    "    axs[0].set_ylabel(\"Cross Entropy Loss\")\n",
    "    axs[0].set_xlabel(\"Epoch\")\n",
    "    axs[0].grid()\n",
    "\n",
    "    axs[1].plot(val_acc, linewidth=2, color=\"red\")\n",
    "    axs[1].set_title(\"Validation accuracy\")\n",
    "    axs[1].set_ylabel(\"Acc\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].grid()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc2865ff-cce3-4444-bed8-bcb20f849443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/vg2507/.local/bin/wandb\", line 5, in <module>\n",
      "    from wandb.cli.cli import cli\n",
      "  File \"/home/vg2507/.local/lib/python3.11/site-packages/wandb/__init__.py\", line 22, in <module>\n",
      "    from wandb.errors import Error\n",
      "ModuleNotFoundError: No module named 'wandb.errors'\n",
      "{'method': 'random',\n",
      " 'parameters': {'epochh': {'values': [100, 150, 200]},\n",
      "                'lrval': {'values': [1, 0.1, 0.01, 0.001]},\n",
      "                'optimizerval': {'values': ['Adam', 'Adadelta']}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: xnresywg\n",
      "Sweep URL: https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg\n"
     ]
    }
   ],
   "source": [
    "!wandb login 3b0311b8e53fccf34f947a23cec3783cb54aa5c0\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "}\n",
    "\n",
    "parameters_dict = {\n",
    "    'lrval': {\n",
    "        'values': [1, 0.1, 0.01, 0.001]\n",
    "      },\n",
    "    'optimizerval': {\n",
    "        'values': ['Adam', 'Adadelta']\n",
    "        },\n",
    "    'epochh': {\n",
    "        'values': [100, 150, 200]\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "pprint.pprint(sweep_config)\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"dl-gcn-project-final-run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afca96b6-59d0-48be-b07f-7ce0a37fa21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Cora dataset...\n",
      "Dataset loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i6lyk655 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvishgoki\u001b[0m (\u001b[33mteam9449\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234022-i6lyk655</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/i6lyk655' target=\"_blank\">devout-sweep-1</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/i6lyk655' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/i6lyk655</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.956 | Train acc: 0.14 | Val loss: 1.924 | Val acc: 0.31\n",
      "Epoch:    1 | Train loss: 1.944 | Train acc: 0.17 | Val loss: 1.917 | Val acc: 0.31\n",
      "Epoch:    2 | Train loss: 1.931 | Train acc: 0.19 | Val loss: 1.915 | Val acc: 0.30\n",
      "Epoch:    3 | Train loss: 1.916 | Train acc: 0.24 | Val loss: 1.907 | Val acc: 0.30\n",
      "Epoch:    4 | Train loss: 1.908 | Train acc: 0.24 | Val loss: 1.900 | Val acc: 0.31\n",
      "Epoch:    5 | Train loss: 1.897 | Train acc: 0.29 | Val loss: 1.889 | Val acc: 0.37\n",
      "Epoch:    6 | Train loss: 1.882 | Train acc: 0.34 | Val loss: 1.884 | Val acc: 0.36\n",
      "Epoch:    7 | Train loss: 1.862 | Train acc: 0.41 | Val loss: 1.870 | Val acc: 0.45\n",
      "Epoch:    8 | Train loss: 1.846 | Train acc: 0.43 | Val loss: 1.863 | Val acc: 0.44\n",
      "Epoch:    9 | Train loss: 1.839 | Train acc: 0.42 | Val loss: 1.854 | Val acc: 0.48\n",
      "Epoch:   10 | Train loss: 1.834 | Train acc: 0.44 | Val loss: 1.843 | Val acc: 0.45\n",
      "Epoch:   11 | Train loss: 1.811 | Train acc: 0.49 | Val loss: 1.825 | Val acc: 0.50\n",
      "Epoch:   12 | Train loss: 1.793 | Train acc: 0.54 | Val loss: 1.817 | Val acc: 0.52\n",
      "Epoch:   13 | Train loss: 1.779 | Train acc: 0.57 | Val loss: 1.806 | Val acc: 0.52\n",
      "Epoch:   14 | Train loss: 1.761 | Train acc: 0.49 | Val loss: 1.784 | Val acc: 0.54\n",
      "Epoch:   15 | Train loss: 1.754 | Train acc: 0.56 | Val loss: 1.786 | Val acc: 0.50\n",
      "Epoch:   16 | Train loss: 1.722 | Train acc: 0.64 | Val loss: 1.763 | Val acc: 0.56\n",
      "Epoch:   17 | Train loss: 1.727 | Train acc: 0.56 | Val loss: 1.752 | Val acc: 0.55\n",
      "Epoch:   18 | Train loss: 1.713 | Train acc: 0.55 | Val loss: 1.735 | Val acc: 0.54\n",
      "Epoch:   19 | Train loss: 1.690 | Train acc: 0.60 | Val loss: 1.721 | Val acc: 0.56\n",
      "Epoch:   20 | Train loss: 1.683 | Train acc: 0.57 | Val loss: 1.724 | Val acc: 0.54\n",
      "Epoch:   21 | Train loss: 1.646 | Train acc: 0.64 | Val loss: 1.703 | Val acc: 0.55\n",
      "Epoch:   22 | Train loss: 1.637 | Train acc: 0.63 | Val loss: 1.698 | Val acc: 0.55\n",
      "Epoch:   23 | Train loss: 1.620 | Train acc: 0.63 | Val loss: 1.679 | Val acc: 0.57\n",
      "Epoch:   24 | Train loss: 1.624 | Train acc: 0.67 | Val loss: 1.679 | Val acc: 0.56\n",
      "Epoch:   25 | Train loss: 1.581 | Train acc: 0.65 | Val loss: 1.642 | Val acc: 0.58\n",
      "Epoch:   26 | Train loss: 1.584 | Train acc: 0.64 | Val loss: 1.640 | Val acc: 0.58\n",
      "Epoch:   27 | Train loss: 1.540 | Train acc: 0.69 | Val loss: 1.598 | Val acc: 0.62\n",
      "Epoch:   28 | Train loss: 1.525 | Train acc: 0.71 | Val loss: 1.610 | Val acc: 0.62\n",
      "Epoch:   29 | Train loss: 1.532 | Train acc: 0.70 | Val loss: 1.592 | Val acc: 0.60\n",
      "Epoch:   30 | Train loss: 1.516 | Train acc: 0.67 | Val loss: 1.588 | Val acc: 0.63\n",
      "Epoch:   31 | Train loss: 1.480 | Train acc: 0.75 | Val loss: 1.581 | Val acc: 0.61\n",
      "Epoch:   32 | Train loss: 1.486 | Train acc: 0.74 | Val loss: 1.582 | Val acc: 0.59\n",
      "Epoch:   33 | Train loss: 1.452 | Train acc: 0.70 | Val loss: 1.553 | Val acc: 0.60\n",
      "Epoch:   34 | Train loss: 1.444 | Train acc: 0.69 | Val loss: 1.532 | Val acc: 0.61\n",
      "Epoch:   35 | Train loss: 1.446 | Train acc: 0.79 | Val loss: 1.534 | Val acc: 0.63\n",
      "Epoch:   36 | Train loss: 1.444 | Train acc: 0.73 | Val loss: 1.540 | Val acc: 0.64\n",
      "Epoch:   37 | Train loss: 1.384 | Train acc: 0.78 | Val loss: 1.519 | Val acc: 0.65\n",
      "Epoch:   38 | Train loss: 1.375 | Train acc: 0.74 | Val loss: 1.503 | Val acc: 0.65\n",
      "Epoch:   39 | Train loss: 1.389 | Train acc: 0.70 | Val loss: 1.508 | Val acc: 0.64\n",
      "Epoch:   40 | Train loss: 1.350 | Train acc: 0.79 | Val loss: 1.499 | Val acc: 0.66\n",
      "Epoch:   41 | Train loss: 1.329 | Train acc: 0.79 | Val loss: 1.469 | Val acc: 0.65\n",
      "Epoch:   42 | Train loss: 1.296 | Train acc: 0.81 | Val loss: 1.451 | Val acc: 0.69\n",
      "Epoch:   43 | Train loss: 1.330 | Train acc: 0.81 | Val loss: 1.460 | Val acc: 0.66\n",
      "Epoch:   44 | Train loss: 1.306 | Train acc: 0.84 | Val loss: 1.452 | Val acc: 0.67\n",
      "Epoch:   45 | Train loss: 1.266 | Train acc: 0.83 | Val loss: 1.426 | Val acc: 0.66\n",
      "Epoch:   46 | Train loss: 1.264 | Train acc: 0.80 | Val loss: 1.444 | Val acc: 0.65\n",
      "Epoch:   47 | Train loss: 1.257 | Train acc: 0.79 | Val loss: 1.409 | Val acc: 0.67\n",
      "Epoch:   48 | Train loss: 1.230 | Train acc: 0.84 | Val loss: 1.398 | Val acc: 0.69\n",
      "Epoch:   49 | Train loss: 1.221 | Train acc: 0.82 | Val loss: 1.406 | Val acc: 0.69\n",
      "Epoch:   50 | Train loss: 1.197 | Train acc: 0.85 | Val loss: 1.376 | Val acc: 0.71\n",
      "Epoch:   51 | Train loss: 1.203 | Train acc: 0.79 | Val loss: 1.404 | Val acc: 0.68\n",
      "Epoch:   52 | Train loss: 1.185 | Train acc: 0.86 | Val loss: 1.380 | Val acc: 0.70\n",
      "Epoch:   53 | Train loss: 1.143 | Train acc: 0.89 | Val loss: 1.350 | Val acc: 0.75\n",
      "Epoch:   54 | Train loss: 1.171 | Train acc: 0.84 | Val loss: 1.363 | Val acc: 0.69\n",
      "Epoch:   55 | Train loss: 1.145 | Train acc: 0.86 | Val loss: 1.334 | Val acc: 0.73\n",
      "Epoch:   56 | Train loss: 1.125 | Train acc: 0.88 | Val loss: 1.356 | Val acc: 0.71\n",
      "Epoch:   57 | Train loss: 1.133 | Train acc: 0.89 | Val loss: 1.346 | Val acc: 0.71\n",
      "Epoch:   58 | Train loss: 1.097 | Train acc: 0.88 | Val loss: 1.329 | Val acc: 0.72\n",
      "Epoch:   59 | Train loss: 1.075 | Train acc: 0.82 | Val loss: 1.302 | Val acc: 0.72\n",
      "Epoch:   60 | Train loss: 1.089 | Train acc: 0.90 | Val loss: 1.314 | Val acc: 0.72\n",
      "Epoch:   61 | Train loss: 1.069 | Train acc: 0.86 | Val loss: 1.325 | Val acc: 0.70\n",
      "Epoch:   62 | Train loss: 1.066 | Train acc: 0.86 | Val loss: 1.302 | Val acc: 0.73\n",
      "Epoch:   63 | Train loss: 1.052 | Train acc: 0.89 | Val loss: 1.253 | Val acc: 0.75\n",
      "Epoch:   64 | Train loss: 1.039 | Train acc: 0.90 | Val loss: 1.279 | Val acc: 0.74\n",
      "Epoch:   65 | Train loss: 1.000 | Train acc: 0.90 | Val loss: 1.265 | Val acc: 0.72\n",
      "Epoch:   66 | Train loss: 0.986 | Train acc: 0.89 | Val loss: 1.242 | Val acc: 0.73\n",
      "Epoch:   67 | Train loss: 1.001 | Train acc: 0.86 | Val loss: 1.247 | Val acc: 0.73\n",
      "Epoch:   68 | Train loss: 0.996 | Train acc: 0.87 | Val loss: 1.224 | Val acc: 0.74\n",
      "Epoch:   69 | Train loss: 0.993 | Train acc: 0.88 | Val loss: 1.262 | Val acc: 0.70\n",
      "Epoch:   70 | Train loss: 0.980 | Train acc: 0.87 | Val loss: 1.244 | Val acc: 0.75\n",
      "Epoch:   71 | Train loss: 0.935 | Train acc: 0.91 | Val loss: 1.233 | Val acc: 0.74\n",
      "Epoch:   72 | Train loss: 0.879 | Train acc: 0.91 | Val loss: 1.180 | Val acc: 0.76\n",
      "Epoch:   73 | Train loss: 0.970 | Train acc: 0.89 | Val loss: 1.245 | Val acc: 0.71\n",
      "Epoch:   74 | Train loss: 0.917 | Train acc: 0.91 | Val loss: 1.196 | Val acc: 0.74\n",
      "Epoch:   75 | Train loss: 0.943 | Train acc: 0.90 | Val loss: 1.235 | Val acc: 0.74\n",
      "Epoch:   76 | Train loss: 0.913 | Train acc: 0.86 | Val loss: 1.198 | Val acc: 0.73\n",
      "Epoch:   77 | Train loss: 0.845 | Train acc: 0.94 | Val loss: 1.177 | Val acc: 0.75\n",
      "Epoch:   78 | Train loss: 0.900 | Train acc: 0.89 | Val loss: 1.191 | Val acc: 0.76\n",
      "Epoch:   79 | Train loss: 0.885 | Train acc: 0.91 | Val loss: 1.166 | Val acc: 0.76\n",
      "Epoch:   80 | Train loss: 0.834 | Train acc: 0.92 | Val loss: 1.153 | Val acc: 0.74\n",
      "Epoch:   81 | Train loss: 0.858 | Train acc: 0.92 | Val loss: 1.157 | Val acc: 0.77\n",
      "Epoch:   82 | Train loss: 0.820 | Train acc: 0.91 | Val loss: 1.139 | Val acc: 0.77\n",
      "Epoch:   83 | Train loss: 0.829 | Train acc: 0.92 | Val loss: 1.151 | Val acc: 0.75\n",
      "Epoch:   84 | Train loss: 0.810 | Train acc: 0.94 | Val loss: 1.166 | Val acc: 0.75\n",
      "Epoch:   85 | Train loss: 0.829 | Train acc: 0.92 | Val loss: 1.136 | Val acc: 0.75\n",
      "Epoch:   86 | Train loss: 0.791 | Train acc: 0.94 | Val loss: 1.133 | Val acc: 0.75\n",
      "Epoch:   87 | Train loss: 0.783 | Train acc: 0.94 | Val loss: 1.116 | Val acc: 0.73\n",
      "Epoch:   88 | Train loss: 0.815 | Train acc: 0.91 | Val loss: 1.081 | Val acc: 0.75\n",
      "Epoch:   89 | Train loss: 0.777 | Train acc: 0.95 | Val loss: 1.107 | Val acc: 0.75\n",
      "Epoch:   90 | Train loss: 0.766 | Train acc: 0.94 | Val loss: 1.108 | Val acc: 0.75\n",
      "Epoch:   91 | Train loss: 0.716 | Train acc: 0.94 | Val loss: 1.072 | Val acc: 0.75\n",
      "Epoch:   92 | Train loss: 0.769 | Train acc: 0.94 | Val loss: 1.112 | Val acc: 0.77\n",
      "Epoch:   93 | Train loss: 0.733 | Train acc: 0.94 | Val loss: 1.085 | Val acc: 0.76\n",
      "Epoch:   94 | Train loss: 0.723 | Train acc: 0.93 | Val loss: 1.069 | Val acc: 0.78\n",
      "Epoch:   95 | Train loss: 0.735 | Train acc: 0.91 | Val loss: 1.069 | Val acc: 0.79\n",
      "Epoch:   96 | Train loss: 0.718 | Train acc: 0.94 | Val loss: 1.039 | Val acc: 0.76\n",
      "Epoch:   97 | Train loss: 0.690 | Train acc: 0.94 | Val loss: 1.058 | Val acc: 0.75\n",
      "Epoch:   98 | Train loss: 0.670 | Train acc: 0.92 | Val loss: 1.046 | Val acc: 0.74\n",
      "Epoch:   99 | Train loss: 0.733 | Train acc: 0.93 | Val loss: 1.064 | Val acc: 0.76\n",
      "Epoch:  100 | Train loss: 0.682 | Train acc: 0.96 | Val loss: 1.058 | Val acc: 0.76\n",
      "Epoch:  101 | Train loss: 0.664 | Train acc: 0.96 | Val loss: 1.044 | Val acc: 0.77\n",
      "Epoch:  102 | Train loss: 0.682 | Train acc: 0.94 | Val loss: 1.031 | Val acc: 0.76\n",
      "Epoch:  103 | Train loss: 0.624 | Train acc: 0.93 | Val loss: 1.003 | Val acc: 0.75\n",
      "Epoch:  104 | Train loss: 0.653 | Train acc: 0.92 | Val loss: 1.009 | Val acc: 0.78\n",
      "Epoch:  105 | Train loss: 0.658 | Train acc: 0.96 | Val loss: 1.058 | Val acc: 0.75\n",
      "Epoch:  106 | Train loss: 0.614 | Train acc: 0.94 | Val loss: 1.017 | Val acc: 0.75\n",
      "Epoch:  107 | Train loss: 0.601 | Train acc: 0.96 | Val loss: 0.999 | Val acc: 0.77\n",
      "Epoch:  108 | Train loss: 0.639 | Train acc: 0.93 | Val loss: 1.032 | Val acc: 0.75\n",
      "Epoch:  109 | Train loss: 0.596 | Train acc: 0.96 | Val loss: 1.028 | Val acc: 0.75\n",
      "Epoch:  110 | Train loss: 0.625 | Train acc: 0.94 | Val loss: 0.986 | Val acc: 0.79\n",
      "Epoch:  111 | Train loss: 0.643 | Train acc: 0.94 | Val loss: 0.991 | Val acc: 0.76\n",
      "Epoch:  112 | Train loss: 0.584 | Train acc: 0.95 | Val loss: 0.996 | Val acc: 0.76\n",
      "Epoch:  113 | Train loss: 0.575 | Train acc: 0.96 | Val loss: 1.019 | Val acc: 0.76\n",
      "Epoch:  114 | Train loss: 0.598 | Train acc: 0.94 | Val loss: 0.993 | Val acc: 0.77\n",
      "Epoch:  115 | Train loss: 0.595 | Train acc: 0.96 | Val loss: 0.990 | Val acc: 0.75\n",
      "Epoch:  116 | Train loss: 0.592 | Train acc: 0.96 | Val loss: 0.973 | Val acc: 0.79\n",
      "Epoch:  117 | Train loss: 0.599 | Train acc: 0.95 | Val loss: 0.994 | Val acc: 0.77\n",
      "Epoch:  118 | Train loss: 0.571 | Train acc: 0.96 | Val loss: 0.942 | Val acc: 0.79\n",
      "Epoch:  119 | Train loss: 0.569 | Train acc: 0.96 | Val loss: 0.966 | Val acc: 0.75\n",
      "Epoch:  120 | Train loss: 0.536 | Train acc: 0.96 | Val loss: 0.969 | Val acc: 0.77\n",
      "Epoch:  121 | Train loss: 0.535 | Train acc: 0.96 | Val loss: 0.978 | Val acc: 0.76\n",
      "Epoch:  122 | Train loss: 0.499 | Train acc: 0.97 | Val loss: 0.939 | Val acc: 0.75\n",
      "Epoch:  123 | Train loss: 0.548 | Train acc: 0.95 | Val loss: 0.959 | Val acc: 0.76\n",
      "Epoch:  124 | Train loss: 0.547 | Train acc: 0.96 | Val loss: 0.983 | Val acc: 0.76\n",
      "Epoch:  125 | Train loss: 0.488 | Train acc: 0.97 | Val loss: 0.965 | Val acc: 0.75\n",
      "Epoch:  126 | Train loss: 0.512 | Train acc: 0.96 | Val loss: 0.949 | Val acc: 0.76\n",
      "Epoch:  127 | Train loss: 0.522 | Train acc: 0.98 | Val loss: 0.945 | Val acc: 0.75\n",
      "Epoch:  128 | Train loss: 0.499 | Train acc: 0.97 | Val loss: 0.936 | Val acc: 0.74\n",
      "Epoch:  129 | Train loss: 0.488 | Train acc: 0.96 | Val loss: 0.923 | Val acc: 0.79\n",
      "Epoch:  130 | Train loss: 0.490 | Train acc: 0.99 | Val loss: 0.944 | Val acc: 0.71\n",
      "Epoch:  131 | Train loss: 0.483 | Train acc: 0.97 | Val loss: 0.887 | Val acc: 0.79\n",
      "Epoch:  132 | Train loss: 0.489 | Train acc: 0.96 | Val loss: 0.933 | Val acc: 0.76\n",
      "Epoch:  133 | Train loss: 0.494 | Train acc: 0.96 | Val loss: 0.914 | Val acc: 0.76\n",
      "Epoch:  134 | Train loss: 0.501 | Train acc: 0.95 | Val loss: 0.907 | Val acc: 0.76\n",
      "Epoch:  135 | Train loss: 0.481 | Train acc: 0.94 | Val loss: 0.948 | Val acc: 0.76\n",
      "Epoch:  136 | Train loss: 0.444 | Train acc: 0.94 | Val loss: 0.893 | Val acc: 0.77\n",
      "Epoch:  137 | Train loss: 0.448 | Train acc: 0.95 | Val loss: 0.867 | Val acc: 0.78\n",
      "Epoch:  138 | Train loss: 0.424 | Train acc: 0.97 | Val loss: 0.914 | Val acc: 0.75\n",
      "Epoch:  139 | Train loss: 0.425 | Train acc: 0.97 | Val loss: 0.884 | Val acc: 0.79\n",
      "Epoch:  140 | Train loss: 0.435 | Train acc: 0.96 | Val loss: 0.874 | Val acc: 0.76\n",
      "Epoch:  141 | Train loss: 0.394 | Train acc: 0.97 | Val loss: 0.866 | Val acc: 0.76\n",
      "Epoch:  142 | Train loss: 0.450 | Train acc: 0.95 | Val loss: 0.879 | Val acc: 0.77\n",
      "Epoch:  143 | Train loss: 0.429 | Train acc: 0.96 | Val loss: 0.894 | Val acc: 0.76\n",
      "Epoch:  144 | Train loss: 0.449 | Train acc: 0.97 | Val loss: 0.875 | Val acc: 0.77\n",
      "Epoch:  145 | Train loss: 0.445 | Train acc: 0.94 | Val loss: 0.891 | Val acc: 0.75\n",
      "Epoch:  146 | Train loss: 0.441 | Train acc: 0.94 | Val loss: 0.916 | Val acc: 0.77\n",
      "Epoch:  147 | Train loss: 0.465 | Train acc: 0.96 | Val loss: 0.910 | Val acc: 0.76\n",
      "Epoch:  148 | Train loss: 0.424 | Train acc: 0.97 | Val loss: 0.844 | Val acc: 0.80\n",
      "Epoch:  149 | Train loss: 0.437 | Train acc: 0.97 | Val loss: 0.914 | Val acc: 0.76\n",
      "Epoch:  150 | Train loss: 0.423 | Train acc: 0.95 | Val loss: 0.850 | Val acc: 0.78\n",
      "Epoch:  151 | Train loss: 0.387 | Train acc: 0.96 | Val loss: 0.868 | Val acc: 0.77\n",
      "Epoch:  152 | Train loss: 0.400 | Train acc: 0.96 | Val loss: 0.898 | Val acc: 0.74\n",
      "Epoch:  153 | Train loss: 0.363 | Train acc: 0.96 | Val loss: 0.824 | Val acc: 0.78\n",
      "Epoch:  154 | Train loss: 0.411 | Train acc: 0.95 | Val loss: 0.901 | Val acc: 0.75\n",
      "Epoch:  155 | Train loss: 0.431 | Train acc: 0.97 | Val loss: 0.873 | Val acc: 0.77\n",
      "Epoch:  156 | Train loss: 0.377 | Train acc: 0.96 | Val loss: 0.888 | Val acc: 0.77\n",
      "Epoch:  157 | Train loss: 0.406 | Train acc: 0.96 | Val loss: 0.844 | Val acc: 0.76\n",
      "Epoch:  158 | Train loss: 0.378 | Train acc: 0.98 | Val loss: 0.885 | Val acc: 0.74\n",
      "Epoch:  159 | Train loss: 0.352 | Train acc: 0.98 | Val loss: 0.842 | Val acc: 0.75\n",
      "Epoch:  160 | Train loss: 0.366 | Train acc: 0.98 | Val loss: 0.860 | Val acc: 0.79\n",
      "Epoch:  161 | Train loss: 0.346 | Train acc: 0.98 | Val loss: 0.852 | Val acc: 0.75\n",
      "Epoch:  162 | Train loss: 0.384 | Train acc: 0.96 | Val loss: 0.828 | Val acc: 0.78\n",
      "Epoch:  163 | Train loss: 0.369 | Train acc: 0.97 | Val loss: 0.855 | Val acc: 0.76\n",
      "EARLY STOPPING condition met. Stopped at epoch: 163.\n",
      "Total training time: 6.27 seconds\n",
      "\n",
      "Test loss: 0.867  |  Test acc: 0.80\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_acc</td><td>▁▂▃▅▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>training_loss</td><td>███▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█▇▇▇██▇▇███▇████▇████</td></tr><tr><td>val_loss</td><td>███▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>163</td></tr><tr><td>training_acc</td><td>0.97143</td></tr><tr><td>training_loss</td><td>0.36868</td></tr><tr><td>val_acc</td><td>0.756</td></tr><tr><td>val_loss</td><td>0.85516</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devout-sweep-1</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/i6lyk655' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/i6lyk655</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234022-i6lyk655/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h16ro818 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adadelta\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234048-h16ro818</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/h16ro818' target=\"_blank\">polar-sweep-2</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/h16ro818' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/h16ro818</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.942 | Train acc: 0.16 | Val loss: 1.948 | Val acc: 0.14\n",
      "Epoch:    1 | Train loss: 1.939 | Train acc: 0.13 | Val loss: 1.948 | Val acc: 0.15\n",
      "Epoch:    2 | Train loss: 1.937 | Train acc: 0.15 | Val loss: 1.950 | Val acc: 0.14\n",
      "Epoch:    3 | Train loss: 1.937 | Train acc: 0.14 | Val loss: 1.950 | Val acc: 0.14\n",
      "Epoch:    4 | Train loss: 1.945 | Train acc: 0.13 | Val loss: 1.954 | Val acc: 0.15\n",
      "Epoch:    5 | Train loss: 1.945 | Train acc: 0.16 | Val loss: 1.949 | Val acc: 0.15\n",
      "Epoch:    6 | Train loss: 1.945 | Train acc: 0.12 | Val loss: 1.955 | Val acc: 0.14\n",
      "Epoch:    7 | Train loss: 1.937 | Train acc: 0.16 | Val loss: 1.948 | Val acc: 0.17\n",
      "Epoch:    8 | Train loss: 1.943 | Train acc: 0.14 | Val loss: 1.953 | Val acc: 0.14\n",
      "Epoch:    9 | Train loss: 1.948 | Train acc: 0.14 | Val loss: 1.954 | Val acc: 0.14\n",
      "Epoch:   10 | Train loss: 1.948 | Train acc: 0.11 | Val loss: 1.957 | Val acc: 0.12\n",
      "Epoch:   11 | Train loss: 1.946 | Train acc: 0.14 | Val loss: 1.950 | Val acc: 0.14\n",
      "EARLY STOPPING condition met. Stopped at epoch: 11.\n",
      "Total training time: 0.11 seconds\n",
      "\n",
      "Test loss: 1.947  |  Test acc: 0.14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>training_acc</td><td>█▄▆▅▄█▃▇▅▅▁▅</td></tr><tr><td>training_loss</td><td>▄▃▁▁▆▆▆▁▅▇█▆</td></tr><tr><td>val_acc</td><td>▄▅▄▅▅▅▄█▄▄▁▄</td></tr><tr><td>val_loss</td><td>▂▁▃▃▆▂▆▁▅▆█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>11</td></tr><tr><td>training_acc</td><td>0.13571</td></tr><tr><td>training_loss</td><td>1.94552</td></tr><tr><td>val_acc</td><td>0.14</td></tr><tr><td>val_loss</td><td>1.94985</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-sweep-2</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/h16ro818' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/h16ro818</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234048-h16ro818/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u7mq1gge with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234104-u7mq1gge</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/u7mq1gge' target=\"_blank\">cosmic-sweep-3</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/u7mq1gge' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/u7mq1gge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.951 | Train acc: 0.19 | Val loss: 1.940 | Val acc: 0.19\n",
      "Epoch:    1 | Train loss: 28.717 | Train acc: 0.33 | Val loss: 36.959 | Val acc: 0.10\n",
      "Epoch:    2 | Train loss: 40.331 | Train acc: 0.28 | Val loss: 20.635 | Val acc: 0.43\n",
      "Epoch:    3 | Train loss: 6.951 | Train acc: 0.32 | Val loss: 4.357 | Val acc: 0.35\n",
      "Epoch:    4 | Train loss: 3.171 | Train acc: 0.31 | Val loss: 2.810 | Val acc: 0.23\n",
      "Epoch:    5 | Train loss: 3.241 | Train acc: 0.38 | Val loss: 3.014 | Val acc: 0.25\n",
      "Epoch:    6 | Train loss: 1.884 | Train acc: 0.43 | Val loss: 2.851 | Val acc: 0.22\n",
      "Epoch:    7 | Train loss: 1.785 | Train acc: 0.41 | Val loss: 3.139 | Val acc: 0.21\n",
      "Epoch:    8 | Train loss: 1.912 | Train acc: 0.38 | Val loss: 2.915 | Val acc: 0.16\n",
      "Epoch:    9 | Train loss: 1.545 | Train acc: 0.41 | Val loss: 2.701 | Val acc: 0.19\n",
      "Epoch:   10 | Train loss: 1.663 | Train acc: 0.39 | Val loss: 2.804 | Val acc: 0.18\n",
      "EARLY STOPPING condition met. Stopped at epoch: 10.\n",
      "Total training time: 0.13 seconds\n",
      "\n",
      "Test loss: 2.501  |  Test acc: 0.20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>training_acc</td><td>▁▅▄▅▅▇██▇▇▇</td></tr><tr><td>training_loss</td><td>▁▆█▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▃▁█▆▄▄▄▃▂▃▃</td></tr><tr><td>val_loss</td><td>▁█▅▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>training_acc</td><td>0.38571</td></tr><tr><td>training_loss</td><td>1.6633</td></tr><tr><td>val_acc</td><td>0.184</td></tr><tr><td>val_loss</td><td>2.80414</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-sweep-3</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/u7mq1gge' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/u7mq1gge</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234104-u7mq1gge/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9wxzng2n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 150\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adadelta\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234129-9wxzng2n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/9wxzng2n' target=\"_blank\">woven-sweep-4</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/9wxzng2n' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/9wxzng2n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.954 | Train acc: 0.06 | Val loss: 1.943 | Val acc: 0.11\n",
      "Epoch:    1 | Train loss: 1.941 | Train acc: 0.16 | Val loss: 1.941 | Val acc: 0.14\n",
      "Epoch:    2 | Train loss: 1.923 | Train acc: 0.26 | Val loss: 1.935 | Val acc: 0.16\n",
      "Epoch:    3 | Train loss: 1.908 | Train acc: 0.31 | Val loss: 1.927 | Val acc: 0.23\n",
      "Epoch:    4 | Train loss: 1.891 | Train acc: 0.39 | Val loss: 1.919 | Val acc: 0.23\n",
      "Epoch:    5 | Train loss: 1.866 | Train acc: 0.54 | Val loss: 1.900 | Val acc: 0.33\n",
      "Epoch:    6 | Train loss: 1.853 | Train acc: 0.52 | Val loss: 1.891 | Val acc: 0.32\n",
      "Epoch:    7 | Train loss: 1.829 | Train acc: 0.52 | Val loss: 1.874 | Val acc: 0.38\n",
      "Epoch:    8 | Train loss: 1.797 | Train acc: 0.64 | Val loss: 1.848 | Val acc: 0.46\n",
      "Epoch:    9 | Train loss: 1.762 | Train acc: 0.65 | Val loss: 1.836 | Val acc: 0.42\n",
      "Epoch:   10 | Train loss: 1.717 | Train acc: 0.71 | Val loss: 1.812 | Val acc: 0.49\n",
      "Epoch:   11 | Train loss: 1.682 | Train acc: 0.74 | Val loss: 1.784 | Val acc: 0.53\n",
      "Epoch:   12 | Train loss: 1.667 | Train acc: 0.76 | Val loss: 1.780 | Val acc: 0.50\n",
      "Epoch:   13 | Train loss: 1.660 | Train acc: 0.66 | Val loss: 1.755 | Val acc: 0.54\n",
      "Epoch:   14 | Train loss: 1.590 | Train acc: 0.76 | Val loss: 1.722 | Val acc: 0.57\n",
      "Epoch:   15 | Train loss: 1.559 | Train acc: 0.75 | Val loss: 1.692 | Val acc: 0.59\n",
      "Epoch:   16 | Train loss: 1.541 | Train acc: 0.80 | Val loss: 1.691 | Val acc: 0.63\n",
      "Epoch:   17 | Train loss: 1.487 | Train acc: 0.82 | Val loss: 1.657 | Val acc: 0.61\n",
      "Epoch:   18 | Train loss: 1.470 | Train acc: 0.84 | Val loss: 1.634 | Val acc: 0.61\n",
      "Epoch:   19 | Train loss: 1.424 | Train acc: 0.83 | Val loss: 1.603 | Val acc: 0.64\n",
      "Epoch:   20 | Train loss: 1.395 | Train acc: 0.81 | Val loss: 1.596 | Val acc: 0.60\n",
      "Epoch:   21 | Train loss: 1.412 | Train acc: 0.76 | Val loss: 1.563 | Val acc: 0.63\n",
      "Epoch:   22 | Train loss: 1.324 | Train acc: 0.82 | Val loss: 1.534 | Val acc: 0.65\n",
      "Epoch:   23 | Train loss: 1.288 | Train acc: 0.79 | Val loss: 1.501 | Val acc: 0.70\n",
      "Epoch:   24 | Train loss: 1.247 | Train acc: 0.84 | Val loss: 1.485 | Val acc: 0.68\n",
      "Epoch:   25 | Train loss: 1.216 | Train acc: 0.88 | Val loss: 1.501 | Val acc: 0.62\n",
      "Epoch:   26 | Train loss: 1.194 | Train acc: 0.83 | Val loss: 1.444 | Val acc: 0.67\n",
      "Epoch:   27 | Train loss: 1.127 | Train acc: 0.84 | Val loss: 1.393 | Val acc: 0.69\n",
      "Epoch:   28 | Train loss: 1.094 | Train acc: 0.88 | Val loss: 1.382 | Val acc: 0.69\n",
      "Epoch:   29 | Train loss: 1.035 | Train acc: 0.89 | Val loss: 1.354 | Val acc: 0.69\n",
      "Epoch:   30 | Train loss: 1.029 | Train acc: 0.83 | Val loss: 1.312 | Val acc: 0.72\n",
      "Epoch:   31 | Train loss: 0.990 | Train acc: 0.88 | Val loss: 1.294 | Val acc: 0.72\n",
      "Epoch:   32 | Train loss: 1.011 | Train acc: 0.83 | Val loss: 1.318 | Val acc: 0.64\n",
      "Epoch:   33 | Train loss: 0.902 | Train acc: 0.91 | Val loss: 1.275 | Val acc: 0.72\n",
      "Epoch:   34 | Train loss: 0.934 | Train acc: 0.86 | Val loss: 1.268 | Val acc: 0.67\n",
      "Epoch:   35 | Train loss: 0.920 | Train acc: 0.88 | Val loss: 1.241 | Val acc: 0.70\n",
      "Epoch:   36 | Train loss: 0.916 | Train acc: 0.84 | Val loss: 1.231 | Val acc: 0.70\n",
      "Epoch:   37 | Train loss: 0.850 | Train acc: 0.88 | Val loss: 1.157 | Val acc: 0.73\n",
      "Epoch:   38 | Train loss: 0.847 | Train acc: 0.89 | Val loss: 1.198 | Val acc: 0.69\n",
      "Epoch:   39 | Train loss: 0.836 | Train acc: 0.89 | Val loss: 1.156 | Val acc: 0.72\n",
      "Epoch:   40 | Train loss: 0.793 | Train acc: 0.92 | Val loss: 1.142 | Val acc: 0.73\n",
      "Epoch:   41 | Train loss: 0.777 | Train acc: 0.91 | Val loss: 1.136 | Val acc: 0.72\n",
      "Epoch:   42 | Train loss: 0.748 | Train acc: 0.91 | Val loss: 1.120 | Val acc: 0.73\n",
      "Epoch:   43 | Train loss: 0.709 | Train acc: 0.91 | Val loss: 1.086 | Val acc: 0.71\n",
      "Epoch:   44 | Train loss: 0.633 | Train acc: 0.94 | Val loss: 1.063 | Val acc: 0.73\n",
      "Epoch:   45 | Train loss: 0.652 | Train acc: 0.90 | Val loss: 1.062 | Val acc: 0.71\n",
      "Epoch:   46 | Train loss: 0.644 | Train acc: 0.94 | Val loss: 1.051 | Val acc: 0.74\n",
      "Epoch:   47 | Train loss: 0.683 | Train acc: 0.94 | Val loss: 1.075 | Val acc: 0.71\n",
      "Epoch:   48 | Train loss: 0.692 | Train acc: 0.89 | Val loss: 1.022 | Val acc: 0.74\n",
      "Epoch:   49 | Train loss: 0.632 | Train acc: 0.89 | Val loss: 1.033 | Val acc: 0.72\n",
      "Epoch:   50 | Train loss: 0.604 | Train acc: 0.96 | Val loss: 1.023 | Val acc: 0.68\n",
      "Epoch:   51 | Train loss: 0.581 | Train acc: 0.93 | Val loss: 1.008 | Val acc: 0.73\n",
      "Epoch:   52 | Train loss: 0.572 | Train acc: 0.94 | Val loss: 0.978 | Val acc: 0.77\n",
      "Epoch:   53 | Train loss: 0.556 | Train acc: 0.95 | Val loss: 0.990 | Val acc: 0.73\n",
      "Epoch:   54 | Train loss: 0.557 | Train acc: 0.93 | Val loss: 0.929 | Val acc: 0.75\n",
      "Epoch:   55 | Train loss: 0.542 | Train acc: 0.93 | Val loss: 0.947 | Val acc: 0.73\n",
      "Epoch:   56 | Train loss: 0.515 | Train acc: 0.94 | Val loss: 1.020 | Val acc: 0.68\n",
      "Epoch:   57 | Train loss: 0.500 | Train acc: 0.91 | Val loss: 0.969 | Val acc: 0.72\n",
      "Epoch:   58 | Train loss: 0.538 | Train acc: 0.94 | Val loss: 0.948 | Val acc: 0.73\n",
      "Epoch:   59 | Train loss: 0.488 | Train acc: 0.94 | Val loss: 0.865 | Val acc: 0.75\n",
      "Epoch:   60 | Train loss: 0.461 | Train acc: 0.95 | Val loss: 0.891 | Val acc: 0.77\n",
      "Epoch:   61 | Train loss: 0.454 | Train acc: 0.94 | Val loss: 0.935 | Val acc: 0.72\n",
      "Epoch:   62 | Train loss: 0.503 | Train acc: 0.93 | Val loss: 0.882 | Val acc: 0.74\n",
      "Epoch:   63 | Train loss: 0.432 | Train acc: 0.95 | Val loss: 0.904 | Val acc: 0.71\n",
      "Epoch:   64 | Train loss: 0.474 | Train acc: 0.92 | Val loss: 0.897 | Val acc: 0.74\n",
      "Epoch:   65 | Train loss: 0.384 | Train acc: 0.94 | Val loss: 0.831 | Val acc: 0.77\n",
      "Epoch:   66 | Train loss: 0.455 | Train acc: 0.93 | Val loss: 0.898 | Val acc: 0.74\n",
      "Epoch:   67 | Train loss: 0.418 | Train acc: 0.94 | Val loss: 0.900 | Val acc: 0.73\n",
      "Epoch:   68 | Train loss: 0.429 | Train acc: 0.93 | Val loss: 0.846 | Val acc: 0.73\n",
      "Epoch:   69 | Train loss: 0.402 | Train acc: 0.95 | Val loss: 0.954 | Val acc: 0.68\n",
      "Epoch:   70 | Train loss: 0.375 | Train acc: 0.93 | Val loss: 0.848 | Val acc: 0.75\n",
      "Epoch:   71 | Train loss: 0.422 | Train acc: 0.91 | Val loss: 0.862 | Val acc: 0.76\n",
      "Epoch:   72 | Train loss: 0.426 | Train acc: 0.94 | Val loss: 0.945 | Val acc: 0.71\n",
      "Epoch:   73 | Train loss: 0.434 | Train acc: 0.92 | Val loss: 0.881 | Val acc: 0.75\n",
      "Epoch:   74 | Train loss: 0.434 | Train acc: 0.91 | Val loss: 0.884 | Val acc: 0.74\n",
      "Epoch:   75 | Train loss: 0.378 | Train acc: 0.93 | Val loss: 0.846 | Val acc: 0.76\n",
      "EARLY STOPPING condition met. Stopped at epoch: 75.\n",
      "Total training time: 0.92 seconds\n",
      "\n",
      "Test loss: 0.800  |  Test acc: 0.81\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_acc</td><td>▁▂▃▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇████▇██████████████</td></tr><tr><td>training_loss</td><td>████▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▄▄▅▆▆▆▇▇▇▆▇▇▇▇▇▇▇█████▇█████▇▇██▇███</td></tr><tr><td>val_loss</td><td>█████▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>75</td></tr><tr><td>training_acc</td><td>0.92857</td></tr><tr><td>training_loss</td><td>0.37759</td></tr><tr><td>val_acc</td><td>0.764</td></tr><tr><td>val_loss</td><td>0.84585</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">woven-sweep-4</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/9wxzng2n' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/9wxzng2n</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234129-9wxzng2n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rx39gvc0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234154-rx39gvc0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/rx39gvc0' target=\"_blank\">kind-sweep-5</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/rx39gvc0' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/rx39gvc0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.955 | Train acc: 0.13 | Val loss: 1.951 | Val acc: 0.12\n",
      "Epoch:    1 | Train loss: 1.943 | Train acc: 0.20 | Val loss: 1.943 | Val acc: 0.16\n",
      "Epoch:    2 | Train loss: 1.918 | Train acc: 0.25 | Val loss: 1.930 | Val acc: 0.18\n",
      "Epoch:    3 | Train loss: 1.914 | Train acc: 0.24 | Val loss: 1.929 | Val acc: 0.19\n",
      "Epoch:    4 | Train loss: 1.901 | Train acc: 0.29 | Val loss: 1.919 | Val acc: 0.24\n",
      "Epoch:    5 | Train loss: 1.882 | Train acc: 0.36 | Val loss: 1.908 | Val acc: 0.28\n",
      "Epoch:    6 | Train loss: 1.871 | Train acc: 0.42 | Val loss: 1.905 | Val acc: 0.29\n",
      "Epoch:    7 | Train loss: 1.866 | Train acc: 0.43 | Val loss: 1.900 | Val acc: 0.29\n",
      "Epoch:    8 | Train loss: 1.847 | Train acc: 0.51 | Val loss: 1.890 | Val acc: 0.36\n",
      "Epoch:    9 | Train loss: 1.827 | Train acc: 0.49 | Val loss: 1.880 | Val acc: 0.35\n",
      "Epoch:   10 | Train loss: 1.822 | Train acc: 0.54 | Val loss: 1.875 | Val acc: 0.37\n",
      "Epoch:   11 | Train loss: 1.802 | Train acc: 0.53 | Val loss: 1.869 | Val acc: 0.40\n",
      "Epoch:   12 | Train loss: 1.789 | Train acc: 0.54 | Val loss: 1.855 | Val acc: 0.39\n",
      "Epoch:   13 | Train loss: 1.775 | Train acc: 0.57 | Val loss: 1.841 | Val acc: 0.44\n",
      "Epoch:   14 | Train loss: 1.753 | Train acc: 0.66 | Val loss: 1.833 | Val acc: 0.43\n",
      "Epoch:   15 | Train loss: 1.746 | Train acc: 0.59 | Val loss: 1.824 | Val acc: 0.39\n",
      "Epoch:   16 | Train loss: 1.720 | Train acc: 0.61 | Val loss: 1.804 | Val acc: 0.47\n",
      "Epoch:   17 | Train loss: 1.698 | Train acc: 0.66 | Val loss: 1.797 | Val acc: 0.47\n",
      "Epoch:   18 | Train loss: 1.706 | Train acc: 0.66 | Val loss: 1.785 | Val acc: 0.47\n",
      "Epoch:   19 | Train loss: 1.687 | Train acc: 0.71 | Val loss: 1.783 | Val acc: 0.48\n",
      "Epoch:   20 | Train loss: 1.661 | Train acc: 0.65 | Val loss: 1.776 | Val acc: 0.45\n",
      "Epoch:   21 | Train loss: 1.631 | Train acc: 0.66 | Val loss: 1.751 | Val acc: 0.48\n",
      "Epoch:   22 | Train loss: 1.623 | Train acc: 0.69 | Val loss: 1.751 | Val acc: 0.50\n",
      "Epoch:   23 | Train loss: 1.601 | Train acc: 0.76 | Val loss: 1.740 | Val acc: 0.48\n",
      "Epoch:   24 | Train loss: 1.567 | Train acc: 0.72 | Val loss: 1.714 | Val acc: 0.51\n",
      "Epoch:   25 | Train loss: 1.578 | Train acc: 0.72 | Val loss: 1.713 | Val acc: 0.51\n",
      "Epoch:   26 | Train loss: 1.550 | Train acc: 0.74 | Val loss: 1.696 | Val acc: 0.53\n",
      "Epoch:   27 | Train loss: 1.532 | Train acc: 0.75 | Val loss: 1.685 | Val acc: 0.57\n",
      "Epoch:   28 | Train loss: 1.518 | Train acc: 0.76 | Val loss: 1.679 | Val acc: 0.52\n",
      "Epoch:   29 | Train loss: 1.463 | Train acc: 0.80 | Val loss: 1.645 | Val acc: 0.59\n",
      "Epoch:   30 | Train loss: 1.469 | Train acc: 0.78 | Val loss: 1.638 | Val acc: 0.58\n",
      "Epoch:   31 | Train loss: 1.451 | Train acc: 0.79 | Val loss: 1.630 | Val acc: 0.59\n",
      "Epoch:   32 | Train loss: 1.445 | Train acc: 0.81 | Val loss: 1.616 | Val acc: 0.60\n",
      "Epoch:   33 | Train loss: 1.425 | Train acc: 0.79 | Val loss: 1.607 | Val acc: 0.61\n",
      "Epoch:   34 | Train loss: 1.390 | Train acc: 0.79 | Val loss: 1.598 | Val acc: 0.54\n",
      "Epoch:   35 | Train loss: 1.363 | Train acc: 0.79 | Val loss: 1.587 | Val acc: 0.59\n",
      "Epoch:   36 | Train loss: 1.366 | Train acc: 0.81 | Val loss: 1.578 | Val acc: 0.61\n",
      "Epoch:   37 | Train loss: 1.349 | Train acc: 0.81 | Val loss: 1.575 | Val acc: 0.57\n",
      "Epoch:   38 | Train loss: 1.334 | Train acc: 0.81 | Val loss: 1.563 | Val acc: 0.60\n",
      "Epoch:   39 | Train loss: 1.321 | Train acc: 0.86 | Val loss: 1.546 | Val acc: 0.62\n",
      "Epoch:   40 | Train loss: 1.276 | Train acc: 0.87 | Val loss: 1.527 | Val acc: 0.63\n",
      "Epoch:   41 | Train loss: 1.284 | Train acc: 0.82 | Val loss: 1.531 | Val acc: 0.61\n",
      "Epoch:   42 | Train loss: 1.269 | Train acc: 0.83 | Val loss: 1.525 | Val acc: 0.63\n",
      "Epoch:   43 | Train loss: 1.279 | Train acc: 0.82 | Val loss: 1.520 | Val acc: 0.63\n",
      "Epoch:   44 | Train loss: 1.198 | Train acc: 0.86 | Val loss: 1.475 | Val acc: 0.65\n",
      "Epoch:   45 | Train loss: 1.227 | Train acc: 0.85 | Val loss: 1.469 | Val acc: 0.66\n",
      "Epoch:   46 | Train loss: 1.183 | Train acc: 0.85 | Val loss: 1.465 | Val acc: 0.63\n",
      "Epoch:   47 | Train loss: 1.169 | Train acc: 0.88 | Val loss: 1.455 | Val acc: 0.60\n",
      "Epoch:   48 | Train loss: 1.163 | Train acc: 0.84 | Val loss: 1.435 | Val acc: 0.68\n",
      "Epoch:   49 | Train loss: 1.120 | Train acc: 0.88 | Val loss: 1.444 | Val acc: 0.65\n",
      "Epoch:   50 | Train loss: 1.136 | Train acc: 0.85 | Val loss: 1.431 | Val acc: 0.63\n",
      "Epoch:   51 | Train loss: 1.132 | Train acc: 0.84 | Val loss: 1.392 | Val acc: 0.70\n",
      "Epoch:   52 | Train loss: 1.106 | Train acc: 0.89 | Val loss: 1.414 | Val acc: 0.66\n",
      "Epoch:   53 | Train loss: 1.097 | Train acc: 0.86 | Val loss: 1.397 | Val acc: 0.66\n",
      "Epoch:   54 | Train loss: 1.112 | Train acc: 0.88 | Val loss: 1.391 | Val acc: 0.66\n",
      "Epoch:   55 | Train loss: 1.040 | Train acc: 0.89 | Val loss: 1.387 | Val acc: 0.65\n",
      "Epoch:   56 | Train loss: 1.086 | Train acc: 0.84 | Val loss: 1.379 | Val acc: 0.66\n",
      "Epoch:   57 | Train loss: 1.037 | Train acc: 0.86 | Val loss: 1.376 | Val acc: 0.65\n",
      "Epoch:   58 | Train loss: 1.020 | Train acc: 0.87 | Val loss: 1.353 | Val acc: 0.66\n",
      "Epoch:   59 | Train loss: 0.992 | Train acc: 0.87 | Val loss: 1.311 | Val acc: 0.70\n",
      "Epoch:   60 | Train loss: 0.987 | Train acc: 0.89 | Val loss: 1.303 | Val acc: 0.72\n",
      "Epoch:   61 | Train loss: 0.986 | Train acc: 0.86 | Val loss: 1.308 | Val acc: 0.73\n",
      "Epoch:   62 | Train loss: 0.962 | Train acc: 0.89 | Val loss: 1.322 | Val acc: 0.67\n",
      "Epoch:   63 | Train loss: 0.935 | Train acc: 0.90 | Val loss: 1.277 | Val acc: 0.71\n",
      "Epoch:   64 | Train loss: 0.924 | Train acc: 0.91 | Val loss: 1.283 | Val acc: 0.71\n",
      "Epoch:   65 | Train loss: 0.903 | Train acc: 0.89 | Val loss: 1.249 | Val acc: 0.71\n",
      "Epoch:   66 | Train loss: 0.920 | Train acc: 0.91 | Val loss: 1.276 | Val acc: 0.71\n",
      "Epoch:   67 | Train loss: 0.895 | Train acc: 0.89 | Val loss: 1.267 | Val acc: 0.72\n",
      "Epoch:   68 | Train loss: 0.860 | Train acc: 0.94 | Val loss: 1.227 | Val acc: 0.73\n",
      "Epoch:   69 | Train loss: 0.870 | Train acc: 0.92 | Val loss: 1.245 | Val acc: 0.70\n",
      "Epoch:   70 | Train loss: 0.879 | Train acc: 0.89 | Val loss: 1.250 | Val acc: 0.72\n",
      "Epoch:   71 | Train loss: 0.872 | Train acc: 0.91 | Val loss: 1.251 | Val acc: 0.71\n",
      "Epoch:   72 | Train loss: 0.856 | Train acc: 0.92 | Val loss: 1.224 | Val acc: 0.74\n",
      "Epoch:   73 | Train loss: 0.831 | Train acc: 0.90 | Val loss: 1.210 | Val acc: 0.72\n",
      "Epoch:   74 | Train loss: 0.782 | Train acc: 0.92 | Val loss: 1.212 | Val acc: 0.72\n",
      "Epoch:   75 | Train loss: 0.794 | Train acc: 0.92 | Val loss: 1.217 | Val acc: 0.69\n",
      "Epoch:   76 | Train loss: 0.797 | Train acc: 0.90 | Val loss: 1.240 | Val acc: 0.69\n",
      "Epoch:   77 | Train loss: 0.802 | Train acc: 0.92 | Val loss: 1.220 | Val acc: 0.70\n",
      "Epoch:   78 | Train loss: 0.789 | Train acc: 0.91 | Val loss: 1.143 | Val acc: 0.75\n",
      "Epoch:   79 | Train loss: 0.767 | Train acc: 0.95 | Val loss: 1.173 | Val acc: 0.73\n",
      "Epoch:   80 | Train loss: 0.779 | Train acc: 0.92 | Val loss: 1.180 | Val acc: 0.69\n",
      "Epoch:   81 | Train loss: 0.764 | Train acc: 0.92 | Val loss: 1.151 | Val acc: 0.73\n",
      "Epoch:   82 | Train loss: 0.721 | Train acc: 0.94 | Val loss: 1.131 | Val acc: 0.75\n",
      "Epoch:   83 | Train loss: 0.735 | Train acc: 0.94 | Val loss: 1.162 | Val acc: 0.73\n",
      "Epoch:   84 | Train loss: 0.714 | Train acc: 0.94 | Val loss: 1.158 | Val acc: 0.72\n",
      "Epoch:   85 | Train loss: 0.709 | Train acc: 0.94 | Val loss: 1.151 | Val acc: 0.68\n",
      "Epoch:   86 | Train loss: 0.692 | Train acc: 0.94 | Val loss: 1.138 | Val acc: 0.72\n",
      "Epoch:   87 | Train loss: 0.677 | Train acc: 0.94 | Val loss: 1.122 | Val acc: 0.74\n",
      "Epoch:   88 | Train loss: 0.702 | Train acc: 0.94 | Val loss: 1.148 | Val acc: 0.73\n",
      "Epoch:   89 | Train loss: 0.635 | Train acc: 0.94 | Val loss: 1.105 | Val acc: 0.73\n",
      "Epoch:   90 | Train loss: 0.698 | Train acc: 0.92 | Val loss: 1.152 | Val acc: 0.69\n",
      "Epoch:   91 | Train loss: 0.621 | Train acc: 0.94 | Val loss: 1.125 | Val acc: 0.72\n",
      "Epoch:   92 | Train loss: 0.622 | Train acc: 0.97 | Val loss: 1.091 | Val acc: 0.74\n",
      "Epoch:   93 | Train loss: 0.654 | Train acc: 0.97 | Val loss: 1.130 | Val acc: 0.71\n",
      "Epoch:   94 | Train loss: 0.584 | Train acc: 0.97 | Val loss: 1.072 | Val acc: 0.73\n",
      "Epoch:   95 | Train loss: 0.616 | Train acc: 0.96 | Val loss: 1.071 | Val acc: 0.76\n",
      "Epoch:   96 | Train loss: 0.614 | Train acc: 0.92 | Val loss: 1.113 | Val acc: 0.69\n",
      "Epoch:   97 | Train loss: 0.611 | Train acc: 0.95 | Val loss: 1.063 | Val acc: 0.69\n",
      "Epoch:   98 | Train loss: 0.594 | Train acc: 0.94 | Val loss: 1.056 | Val acc: 0.72\n",
      "Epoch:   99 | Train loss: 0.638 | Train acc: 0.94 | Val loss: 1.025 | Val acc: 0.78\n",
      "Epoch:  100 | Train loss: 0.583 | Train acc: 0.96 | Val loss: 1.017 | Val acc: 0.74\n",
      "Epoch:  101 | Train loss: 0.591 | Train acc: 0.93 | Val loss: 1.038 | Val acc: 0.74\n",
      "Epoch:  102 | Train loss: 0.580 | Train acc: 0.94 | Val loss: 1.031 | Val acc: 0.73\n",
      "Epoch:  103 | Train loss: 0.551 | Train acc: 0.92 | Val loss: 1.043 | Val acc: 0.71\n",
      "Epoch:  104 | Train loss: 0.562 | Train acc: 0.96 | Val loss: 1.039 | Val acc: 0.72\n",
      "Epoch:  105 | Train loss: 0.593 | Train acc: 0.94 | Val loss: 1.043 | Val acc: 0.72\n",
      "Epoch:  106 | Train loss: 0.520 | Train acc: 0.96 | Val loss: 1.045 | Val acc: 0.74\n",
      "Epoch:  107 | Train loss: 0.582 | Train acc: 0.94 | Val loss: 1.039 | Val acc: 0.73\n",
      "Epoch:  108 | Train loss: 0.527 | Train acc: 0.94 | Val loss: 0.947 | Val acc: 0.79\n",
      "Epoch:  109 | Train loss: 0.528 | Train acc: 0.94 | Val loss: 1.006 | Val acc: 0.73\n",
      "Epoch:  110 | Train loss: 0.510 | Train acc: 0.96 | Val loss: 1.030 | Val acc: 0.73\n",
      "Epoch:  111 | Train loss: 0.506 | Train acc: 0.95 | Val loss: 1.004 | Val acc: 0.73\n",
      "Epoch:  112 | Train loss: 0.516 | Train acc: 0.95 | Val loss: 1.015 | Val acc: 0.74\n",
      "Epoch:  113 | Train loss: 0.508 | Train acc: 0.99 | Val loss: 1.016 | Val acc: 0.75\n",
      "Epoch:  114 | Train loss: 0.469 | Train acc: 0.99 | Val loss: 1.010 | Val acc: 0.73\n",
      "Epoch:  115 | Train loss: 0.533 | Train acc: 0.96 | Val loss: 1.028 | Val acc: 0.74\n",
      "Epoch:  116 | Train loss: 0.480 | Train acc: 0.97 | Val loss: 1.005 | Val acc: 0.71\n",
      "Epoch:  117 | Train loss: 0.466 | Train acc: 0.98 | Val loss: 0.985 | Val acc: 0.73\n",
      "Epoch:  118 | Train loss: 0.464 | Train acc: 0.95 | Val loss: 0.979 | Val acc: 0.73\n",
      "EARLY STOPPING condition met. Stopped at epoch: 118.\n",
      "Total training time: 1.42 seconds\n",
      "\n",
      "Test loss: 0.993  |  Test acc: 0.79\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_acc</td><td>▁▂▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇███████</td></tr><tr><td>training_loss</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇█▇▇▇</td></tr><tr><td>val_loss</td><td>████▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>118</td></tr><tr><td>training_acc</td><td>0.95</td></tr><tr><td>training_loss</td><td>0.46391</td></tr><tr><td>val_acc</td><td>0.734</td></tr><tr><td>val_loss</td><td>0.9795</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">kind-sweep-5</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/rx39gvc0' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/rx39gvc0</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234154-rx39gvc0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h1khzwx4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234211-h1khzwx4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/h1khzwx4' target=\"_blank\">sleek-sweep-6</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/h1khzwx4' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/h1khzwx4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.938 | Train acc: 0.16 | Val loss: 1.953 | Val acc: 0.12\n",
      "Epoch:    1 | Train loss: 26.296 | Train acc: 0.40 | Val loss: 21.826 | Val acc: 0.42\n",
      "Epoch:    2 | Train loss: 28.003 | Train acc: 0.31 | Val loss: 35.381 | Val acc: 0.23\n",
      "Epoch:    3 | Train loss: 2.956 | Train acc: 0.64 | Val loss: 7.939 | Val acc: 0.35\n",
      "Epoch:    4 | Train loss: 4.399 | Train acc: 0.34 | Val loss: 6.721 | Val acc: 0.19\n",
      "Epoch:    5 | Train loss: 3.713 | Train acc: 0.40 | Val loss: 4.624 | Val acc: 0.22\n",
      "Epoch:    6 | Train loss: 3.512 | Train acc: 0.38 | Val loss: 3.665 | Val acc: 0.22\n",
      "Epoch:    7 | Train loss: 1.925 | Train acc: 0.41 | Val loss: 2.558 | Val acc: 0.24\n",
      "Epoch:    8 | Train loss: 1.837 | Train acc: 0.43 | Val loss: 2.090 | Val acc: 0.21\n",
      "Epoch:    9 | Train loss: 1.476 | Train acc: 0.41 | Val loss: 1.839 | Val acc: 0.22\n",
      "Epoch:   10 | Train loss: 1.627 | Train acc: 0.39 | Val loss: 1.717 | Val acc: 0.46\n",
      "Epoch:   11 | Train loss: 1.642 | Train acc: 0.43 | Val loss: 1.762 | Val acc: 0.45\n",
      "Epoch:   12 | Train loss: 1.551 | Train acc: 0.44 | Val loss: 1.830 | Val acc: 0.46\n",
      "Epoch:   13 | Train loss: 1.590 | Train acc: 0.43 | Val loss: 1.715 | Val acc: 0.46\n",
      "Epoch:   14 | Train loss: 1.532 | Train acc: 0.43 | Val loss: 1.870 | Val acc: 0.46\n",
      "Epoch:   15 | Train loss: 1.415 | Train acc: 0.44 | Val loss: 1.806 | Val acc: 0.46\n",
      "Epoch:   16 | Train loss: 1.332 | Train acc: 0.46 | Val loss: 1.616 | Val acc: 0.46\n",
      "Epoch:   17 | Train loss: 1.233 | Train acc: 0.50 | Val loss: 1.683 | Val acc: 0.47\n",
      "Epoch:   18 | Train loss: 1.225 | Train acc: 0.48 | Val loss: 1.902 | Val acc: 0.24\n",
      "Epoch:   19 | Train loss: 1.538 | Train acc: 0.43 | Val loss: 1.889 | Val acc: 0.24\n",
      "Epoch:   20 | Train loss: 1.218 | Train acc: 0.51 | Val loss: 2.388 | Val acc: 0.25\n",
      "Epoch:   21 | Train loss: 1.194 | Train acc: 0.52 | Val loss: 2.389 | Val acc: 0.26\n",
      "Epoch:   22 | Train loss: 1.145 | Train acc: 0.54 | Val loss: 2.009 | Val acc: 0.25\n",
      "Epoch:   23 | Train loss: 1.138 | Train acc: 0.52 | Val loss: 2.619 | Val acc: 0.25\n",
      "Epoch:   24 | Train loss: 1.205 | Train acc: 0.48 | Val loss: 2.278 | Val acc: 0.25\n",
      "Epoch:   25 | Train loss: 1.207 | Train acc: 0.46 | Val loss: 2.009 | Val acc: 0.24\n",
      "Epoch:   26 | Train loss: 1.155 | Train acc: 0.46 | Val loss: 1.904 | Val acc: 0.21\n",
      "EARLY STOPPING condition met. Stopped at epoch: 26.\n",
      "Total training time: 0.33 seconds\n",
      "\n",
      "Test loss: 1.785  |  Test acc: 0.46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>training_acc</td><td>▁▅▃█▄▅▄▅▅▅▄▅▅▅▅▅▅▆▆▅▆▆▇▆▆▅▅</td></tr><tr><td>training_loss</td><td>▁██▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▇▃▅▂▃▃▃▃▃████████▃▃▄▄▃▄▃▃▃</td></tr><tr><td>val_loss</td><td>▁▅█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>26</td></tr><tr><td>training_acc</td><td>0.46429</td></tr><tr><td>training_loss</td><td>1.15534</td></tr><tr><td>val_acc</td><td>0.212</td></tr><tr><td>val_loss</td><td>1.9044</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sleek-sweep-6</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/h1khzwx4' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/h1khzwx4</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234211-h1khzwx4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lt8x7vj0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234230-lt8x7vj0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/lt8x7vj0' target=\"_blank\">neat-sweep-7</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/lt8x7vj0' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/lt8x7vj0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.952 | Train acc: 0.09 | Val loss: 1.957 | Val acc: 0.10\n",
      "Epoch:    1 | Train loss: 1.856 | Train acc: 0.46 | Val loss: 1.906 | Val acc: 0.27\n",
      "Epoch:    2 | Train loss: 1.742 | Train acc: 0.54 | Val loss: 1.844 | Val acc: 0.37\n",
      "Epoch:    3 | Train loss: 1.608 | Train acc: 0.62 | Val loss: 1.776 | Val acc: 0.41\n",
      "Epoch:    4 | Train loss: 1.467 | Train acc: 0.69 | Val loss: 1.692 | Val acc: 0.46\n",
      "Epoch:    5 | Train loss: 1.340 | Train acc: 0.70 | Val loss: 1.648 | Val acc: 0.45\n",
      "Epoch:    6 | Train loss: 1.239 | Train acc: 0.73 | Val loss: 1.559 | Val acc: 0.52\n",
      "Epoch:    7 | Train loss: 1.063 | Train acc: 0.82 | Val loss: 1.492 | Val acc: 0.58\n",
      "Epoch:    8 | Train loss: 0.988 | Train acc: 0.86 | Val loss: 1.413 | Val acc: 0.61\n",
      "Epoch:    9 | Train loss: 0.867 | Train acc: 0.88 | Val loss: 1.316 | Val acc: 0.64\n",
      "Epoch:   10 | Train loss: 0.791 | Train acc: 0.92 | Val loss: 1.254 | Val acc: 0.68\n",
      "Epoch:   11 | Train loss: 0.738 | Train acc: 0.92 | Val loss: 1.182 | Val acc: 0.68\n",
      "Epoch:   12 | Train loss: 0.697 | Train acc: 0.89 | Val loss: 1.126 | Val acc: 0.74\n",
      "Epoch:   13 | Train loss: 0.561 | Train acc: 0.93 | Val loss: 1.074 | Val acc: 0.70\n",
      "Epoch:   14 | Train loss: 0.562 | Train acc: 0.91 | Val loss: 1.070 | Val acc: 0.71\n",
      "Epoch:   15 | Train loss: 0.444 | Train acc: 0.94 | Val loss: 0.985 | Val acc: 0.70\n",
      "Epoch:   16 | Train loss: 0.423 | Train acc: 0.93 | Val loss: 0.948 | Val acc: 0.73\n",
      "Epoch:   17 | Train loss: 0.400 | Train acc: 0.96 | Val loss: 0.964 | Val acc: 0.70\n",
      "Epoch:   18 | Train loss: 0.379 | Train acc: 0.94 | Val loss: 0.895 | Val acc: 0.74\n",
      "Epoch:   19 | Train loss: 0.313 | Train acc: 0.96 | Val loss: 0.870 | Val acc: 0.76\n",
      "Epoch:   20 | Train loss: 0.265 | Train acc: 0.96 | Val loss: 0.830 | Val acc: 0.76\n",
      "Epoch:   21 | Train loss: 0.268 | Train acc: 0.94 | Val loss: 0.865 | Val acc: 0.74\n",
      "Epoch:   22 | Train loss: 0.246 | Train acc: 0.95 | Val loss: 0.826 | Val acc: 0.77\n",
      "Epoch:   23 | Train loss: 0.223 | Train acc: 0.97 | Val loss: 0.848 | Val acc: 0.76\n",
      "Epoch:   24 | Train loss: 0.219 | Train acc: 0.94 | Val loss: 0.845 | Val acc: 0.75\n",
      "Epoch:   25 | Train loss: 0.160 | Train acc: 0.99 | Val loss: 0.860 | Val acc: 0.74\n",
      "Epoch:   26 | Train loss: 0.170 | Train acc: 0.97 | Val loss: 0.834 | Val acc: 0.71\n",
      "Epoch:   27 | Train loss: 0.154 | Train acc: 0.96 | Val loss: 0.866 | Val acc: 0.76\n",
      "Epoch:   28 | Train loss: 0.136 | Train acc: 0.98 | Val loss: 0.915 | Val acc: 0.72\n",
      "Epoch:   29 | Train loss: 0.143 | Train acc: 0.98 | Val loss: 0.878 | Val acc: 0.74\n",
      "Epoch:   30 | Train loss: 0.120 | Train acc: 0.99 | Val loss: 0.901 | Val acc: 0.74\n",
      "Epoch:   31 | Train loss: 0.118 | Train acc: 0.98 | Val loss: 0.793 | Val acc: 0.76\n",
      "Epoch:   32 | Train loss: 0.102 | Train acc: 0.99 | Val loss: 0.798 | Val acc: 0.79\n",
      "Epoch:   33 | Train loss: 0.116 | Train acc: 0.97 | Val loss: 0.857 | Val acc: 0.76\n",
      "Epoch:   34 | Train loss: 0.106 | Train acc: 0.99 | Val loss: 0.930 | Val acc: 0.75\n",
      "Epoch:   35 | Train loss: 0.120 | Train acc: 0.98 | Val loss: 0.896 | Val acc: 0.77\n",
      "Epoch:   36 | Train loss: 0.101 | Train acc: 0.98 | Val loss: 0.906 | Val acc: 0.74\n",
      "Epoch:   37 | Train loss: 0.087 | Train acc: 0.99 | Val loss: 0.861 | Val acc: 0.78\n",
      "Epoch:   38 | Train loss: 0.086 | Train acc: 0.98 | Val loss: 0.946 | Val acc: 0.77\n",
      "Epoch:   39 | Train loss: 0.091 | Train acc: 0.99 | Val loss: 0.996 | Val acc: 0.71\n",
      "Epoch:   40 | Train loss: 0.101 | Train acc: 0.97 | Val loss: 0.813 | Val acc: 0.79\n",
      "Epoch:   41 | Train loss: 0.064 | Train acc: 0.99 | Val loss: 0.886 | Val acc: 0.76\n",
      "EARLY STOPPING condition met. Stopped at epoch: 41.\n",
      "Total training time: 0.49 seconds\n",
      "\n",
      "Test loss: 0.731  |  Test acc: 0.77\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>training_acc</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇█▇███████████████████████</td></tr><tr><td>training_loss</td><td>██▇▇▆▆▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇███████▇█▇██████████▇█</td></tr><tr><td>val_loss</td><td>██▇▇▆▆▆▅▅▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▁▁▁▂▂▂▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>41</td></tr><tr><td>training_acc</td><td>0.99286</td></tr><tr><td>training_loss</td><td>0.06356</td></tr><tr><td>val_acc</td><td>0.76</td></tr><tr><td>val_loss</td><td>0.8865</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neat-sweep-7</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/lt8x7vj0' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/lt8x7vj0</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234230-lt8x7vj0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vltleh3v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adadelta\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234246-vltleh3v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/vltleh3v' target=\"_blank\">fanciful-sweep-8</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/vltleh3v' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/vltleh3v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.953 | Train acc: 0.09 | Val loss: 1.956 | Val acc: 0.10\n",
      "Epoch:    1 | Train loss: 1.951 | Train acc: 0.09 | Val loss: 1.957 | Val acc: 0.09\n",
      "Epoch:    2 | Train loss: 1.954 | Train acc: 0.09 | Val loss: 1.952 | Val acc: 0.11\n",
      "Epoch:    3 | Train loss: 1.953 | Train acc: 0.16 | Val loss: 1.953 | Val acc: 0.09\n",
      "Epoch:    4 | Train loss: 1.950 | Train acc: 0.08 | Val loss: 1.953 | Val acc: 0.11\n",
      "Epoch:    5 | Train loss: 1.954 | Train acc: 0.13 | Val loss: 1.955 | Val acc: 0.11\n",
      "Epoch:    6 | Train loss: 1.954 | Train acc: 0.16 | Val loss: 1.952 | Val acc: 0.13\n",
      "Epoch:    7 | Train loss: 1.948 | Train acc: 0.14 | Val loss: 1.953 | Val acc: 0.10\n",
      "Epoch:    8 | Train loss: 1.949 | Train acc: 0.11 | Val loss: 1.951 | Val acc: 0.09\n",
      "Epoch:    9 | Train loss: 1.949 | Train acc: 0.13 | Val loss: 1.946 | Val acc: 0.11\n",
      "Epoch:   10 | Train loss: 1.947 | Train acc: 0.14 | Val loss: 1.950 | Val acc: 0.11\n",
      "Epoch:   11 | Train loss: 1.951 | Train acc: 0.13 | Val loss: 1.955 | Val acc: 0.10\n",
      "Epoch:   12 | Train loss: 1.947 | Train acc: 0.11 | Val loss: 1.955 | Val acc: 0.08\n",
      "Epoch:   13 | Train loss: 1.946 | Train acc: 0.14 | Val loss: 1.953 | Val acc: 0.11\n",
      "Epoch:   14 | Train loss: 1.949 | Train acc: 0.11 | Val loss: 1.949 | Val acc: 0.12\n",
      "Epoch:   15 | Train loss: 1.949 | Train acc: 0.09 | Val loss: 1.953 | Val acc: 0.11\n",
      "Epoch:   16 | Train loss: 1.950 | Train acc: 0.14 | Val loss: 1.954 | Val acc: 0.12\n",
      "Epoch:   17 | Train loss: 1.947 | Train acc: 0.13 | Val loss: 1.952 | Val acc: 0.12\n",
      "Epoch:   18 | Train loss: 1.951 | Train acc: 0.16 | Val loss: 1.955 | Val acc: 0.10\n",
      "Epoch:   19 | Train loss: 1.943 | Train acc: 0.14 | Val loss: 1.954 | Val acc: 0.11\n",
      "EARLY STOPPING condition met. Stopped at epoch: 19.\n",
      "Total training time: 0.24 seconds\n",
      "\n",
      "Test loss: 1.953  |  Test acc: 0.13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>training_acc</td><td>▂▂▂█▁▅█▇▄▅▇▅▄▆▄▂▆▅█▆</td></tr><tr><td>training_loss</td><td>▇▆█▇▆▇█▄▅▅▄▆▄▃▅▅▅▃▆▁</td></tr><tr><td>val_acc</td><td>▃▂▄▂▅▅█▃▂▆▅▃▁▅▆▄▆▆▄▅</td></tr><tr><td>val_loss</td><td>▇█▅▆▆▇▅▆▄▁▄▇▇▆▃▆▆▅▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>training_acc</td><td>0.13571</td></tr><tr><td>training_loss</td><td>1.9425</td></tr><tr><td>val_acc</td><td>0.108</td></tr><tr><td>val_loss</td><td>1.95364</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fanciful-sweep-8</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/vltleh3v' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/vltleh3v</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234246-vltleh3v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ub696ayq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adadelta\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234306-ub696ayq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/ub696ayq' target=\"_blank\">scarlet-sweep-9</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/ub696ayq' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/ub696ayq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.941 | Train acc: 0.14 | Val loss: 1.949 | Val acc: 0.14\n",
      "Epoch:    1 | Train loss: 1.924 | Train acc: 0.19 | Val loss: 1.939 | Val acc: 0.16\n",
      "Epoch:    2 | Train loss: 1.911 | Train acc: 0.20 | Val loss: 1.935 | Val acc: 0.16\n",
      "Epoch:    3 | Train loss: 1.889 | Train acc: 0.29 | Val loss: 1.927 | Val acc: 0.19\n",
      "Epoch:    4 | Train loss: 1.868 | Train acc: 0.31 | Val loss: 1.915 | Val acc: 0.20\n",
      "Epoch:    5 | Train loss: 1.840 | Train acc: 0.40 | Val loss: 1.904 | Val acc: 0.22\n",
      "Epoch:    6 | Train loss: 1.822 | Train acc: 0.42 | Val loss: 1.896 | Val acc: 0.21\n",
      "Epoch:    7 | Train loss: 1.792 | Train acc: 0.46 | Val loss: 1.877 | Val acc: 0.25\n",
      "Epoch:    8 | Train loss: 1.752 | Train acc: 0.44 | Val loss: 1.855 | Val acc: 0.27\n",
      "Epoch:    9 | Train loss: 1.729 | Train acc: 0.49 | Val loss: 1.839 | Val acc: 0.28\n",
      "Epoch:   10 | Train loss: 1.701 | Train acc: 0.49 | Val loss: 1.821 | Val acc: 0.32\n",
      "Epoch:   11 | Train loss: 1.661 | Train acc: 0.59 | Val loss: 1.793 | Val acc: 0.36\n",
      "Epoch:   12 | Train loss: 1.621 | Train acc: 0.66 | Val loss: 1.769 | Val acc: 0.39\n",
      "Epoch:   13 | Train loss: 1.592 | Train acc: 0.61 | Val loss: 1.743 | Val acc: 0.42\n",
      "Epoch:   14 | Train loss: 1.562 | Train acc: 0.64 | Val loss: 1.715 | Val acc: 0.43\n",
      "Epoch:   15 | Train loss: 1.516 | Train acc: 0.72 | Val loss: 1.682 | Val acc: 0.50\n",
      "Epoch:   16 | Train loss: 1.495 | Train acc: 0.75 | Val loss: 1.663 | Val acc: 0.52\n",
      "Epoch:   17 | Train loss: 1.462 | Train acc: 0.79 | Val loss: 1.645 | Val acc: 0.57\n",
      "Epoch:   18 | Train loss: 1.409 | Train acc: 0.81 | Val loss: 1.615 | Val acc: 0.63\n",
      "Epoch:   19 | Train loss: 1.404 | Train acc: 0.77 | Val loss: 1.600 | Val acc: 0.58\n",
      "Epoch:   20 | Train loss: 1.335 | Train acc: 0.79 | Val loss: 1.580 | Val acc: 0.60\n",
      "Epoch:   21 | Train loss: 1.340 | Train acc: 0.81 | Val loss: 1.546 | Val acc: 0.60\n",
      "Epoch:   22 | Train loss: 1.262 | Train acc: 0.81 | Val loss: 1.504 | Val acc: 0.67\n",
      "Epoch:   23 | Train loss: 1.212 | Train acc: 0.86 | Val loss: 1.484 | Val acc: 0.65\n",
      "Epoch:   24 | Train loss: 1.198 | Train acc: 0.81 | Val loss: 1.501 | Val acc: 0.66\n",
      "Epoch:   25 | Train loss: 1.164 | Train acc: 0.86 | Val loss: 1.446 | Val acc: 0.67\n",
      "Epoch:   26 | Train loss: 1.151 | Train acc: 0.86 | Val loss: 1.425 | Val acc: 0.68\n",
      "Epoch:   27 | Train loss: 1.066 | Train acc: 0.85 | Val loss: 1.384 | Val acc: 0.68\n",
      "Epoch:   28 | Train loss: 1.040 | Train acc: 0.86 | Val loss: 1.356 | Val acc: 0.73\n",
      "Epoch:   29 | Train loss: 1.031 | Train acc: 0.86 | Val loss: 1.387 | Val acc: 0.70\n",
      "Epoch:   30 | Train loss: 1.022 | Train acc: 0.86 | Val loss: 1.331 | Val acc: 0.74\n",
      "Epoch:   31 | Train loss: 0.987 | Train acc: 0.89 | Val loss: 1.341 | Val acc: 0.66\n",
      "Epoch:   32 | Train loss: 0.956 | Train acc: 0.89 | Val loss: 1.270 | Val acc: 0.73\n",
      "Epoch:   33 | Train loss: 0.934 | Train acc: 0.86 | Val loss: 1.242 | Val acc: 0.73\n",
      "Epoch:   34 | Train loss: 0.945 | Train acc: 0.91 | Val loss: 1.260 | Val acc: 0.73\n",
      "Epoch:   35 | Train loss: 0.927 | Train acc: 0.89 | Val loss: 1.229 | Val acc: 0.73\n",
      "Epoch:   36 | Train loss: 0.857 | Train acc: 0.90 | Val loss: 1.173 | Val acc: 0.76\n",
      "Epoch:   37 | Train loss: 0.853 | Train acc: 0.91 | Val loss: 1.196 | Val acc: 0.75\n",
      "Epoch:   38 | Train loss: 0.827 | Train acc: 0.91 | Val loss: 1.200 | Val acc: 0.72\n",
      "Epoch:   39 | Train loss: 0.764 | Train acc: 0.91 | Val loss: 1.148 | Val acc: 0.73\n",
      "Epoch:   40 | Train loss: 0.758 | Train acc: 0.89 | Val loss: 1.114 | Val acc: 0.73\n",
      "Epoch:   41 | Train loss: 0.773 | Train acc: 0.91 | Val loss: 1.146 | Val acc: 0.74\n",
      "Epoch:   42 | Train loss: 0.744 | Train acc: 0.89 | Val loss: 1.123 | Val acc: 0.72\n",
      "Epoch:   43 | Train loss: 0.691 | Train acc: 0.94 | Val loss: 1.102 | Val acc: 0.73\n",
      "Epoch:   44 | Train loss: 0.668 | Train acc: 0.91 | Val loss: 1.051 | Val acc: 0.74\n",
      "Epoch:   45 | Train loss: 0.664 | Train acc: 0.90 | Val loss: 1.036 | Val acc: 0.73\n",
      "Epoch:   46 | Train loss: 0.642 | Train acc: 0.89 | Val loss: 1.027 | Val acc: 0.75\n",
      "Epoch:   47 | Train loss: 0.668 | Train acc: 0.88 | Val loss: 1.057 | Val acc: 0.73\n",
      "Epoch:   48 | Train loss: 0.655 | Train acc: 0.89 | Val loss: 1.098 | Val acc: 0.71\n",
      "Epoch:   49 | Train loss: 0.544 | Train acc: 0.92 | Val loss: 0.981 | Val acc: 0.76\n",
      "Epoch:   50 | Train loss: 0.594 | Train acc: 0.91 | Val loss: 1.008 | Val acc: 0.73\n",
      "Epoch:   51 | Train loss: 0.607 | Train acc: 0.91 | Val loss: 0.977 | Val acc: 0.75\n",
      "Epoch:   52 | Train loss: 0.525 | Train acc: 0.92 | Val loss: 1.015 | Val acc: 0.74\n",
      "Epoch:   53 | Train loss: 0.555 | Train acc: 0.91 | Val loss: 1.017 | Val acc: 0.74\n",
      "Epoch:   54 | Train loss: 0.568 | Train acc: 0.89 | Val loss: 0.976 | Val acc: 0.75\n",
      "Epoch:   55 | Train loss: 0.547 | Train acc: 0.91 | Val loss: 1.059 | Val acc: 0.67\n",
      "Epoch:   56 | Train loss: 0.567 | Train acc: 0.92 | Val loss: 0.972 | Val acc: 0.72\n",
      "Epoch:   57 | Train loss: 0.523 | Train acc: 0.93 | Val loss: 0.896 | Val acc: 0.75\n",
      "Epoch:   58 | Train loss: 0.502 | Train acc: 0.92 | Val loss: 0.914 | Val acc: 0.76\n",
      "Epoch:   59 | Train loss: 0.469 | Train acc: 0.91 | Val loss: 0.930 | Val acc: 0.74\n",
      "Epoch:   60 | Train loss: 0.450 | Train acc: 0.96 | Val loss: 0.876 | Val acc: 0.78\n",
      "Epoch:   61 | Train loss: 0.437 | Train acc: 0.94 | Val loss: 0.881 | Val acc: 0.76\n",
      "Epoch:   62 | Train loss: 0.430 | Train acc: 0.94 | Val loss: 0.932 | Val acc: 0.73\n",
      "Epoch:   63 | Train loss: 0.456 | Train acc: 0.94 | Val loss: 0.906 | Val acc: 0.75\n",
      "Epoch:   64 | Train loss: 0.477 | Train acc: 0.92 | Val loss: 0.880 | Val acc: 0.74\n",
      "Epoch:   65 | Train loss: 0.417 | Train acc: 0.91 | Val loss: 0.906 | Val acc: 0.73\n",
      "Epoch:   66 | Train loss: 0.446 | Train acc: 0.92 | Val loss: 0.902 | Val acc: 0.78\n",
      "Epoch:   67 | Train loss: 0.446 | Train acc: 0.96 | Val loss: 0.909 | Val acc: 0.74\n",
      "Epoch:   68 | Train loss: 0.384 | Train acc: 0.95 | Val loss: 0.852 | Val acc: 0.76\n",
      "Epoch:   69 | Train loss: 0.372 | Train acc: 0.96 | Val loss: 0.827 | Val acc: 0.76\n",
      "Epoch:   70 | Train loss: 0.375 | Train acc: 0.95 | Val loss: 0.970 | Val acc: 0.72\n",
      "Epoch:   71 | Train loss: 0.416 | Train acc: 0.94 | Val loss: 0.926 | Val acc: 0.70\n",
      "Epoch:   72 | Train loss: 0.407 | Train acc: 0.93 | Val loss: 0.860 | Val acc: 0.76\n",
      "Epoch:   73 | Train loss: 0.382 | Train acc: 0.98 | Val loss: 0.889 | Val acc: 0.74\n",
      "Epoch:   74 | Train loss: 0.356 | Train acc: 0.97 | Val loss: 0.818 | Val acc: 0.78\n",
      "Epoch:   75 | Train loss: 0.346 | Train acc: 0.94 | Val loss: 0.860 | Val acc: 0.76\n",
      "Epoch:   76 | Train loss: 0.342 | Train acc: 0.99 | Val loss: 0.823 | Val acc: 0.77\n",
      "Epoch:   77 | Train loss: 0.340 | Train acc: 0.96 | Val loss: 0.888 | Val acc: 0.74\n",
      "Epoch:   78 | Train loss: 0.365 | Train acc: 0.95 | Val loss: 0.860 | Val acc: 0.75\n",
      "Epoch:   79 | Train loss: 0.359 | Train acc: 0.94 | Val loss: 0.880 | Val acc: 0.75\n",
      "Epoch:   80 | Train loss: 0.376 | Train acc: 0.93 | Val loss: 0.820 | Val acc: 0.77\n",
      "Epoch:   81 | Train loss: 0.320 | Train acc: 0.96 | Val loss: 0.800 | Val acc: 0.76\n",
      "Epoch:   82 | Train loss: 0.296 | Train acc: 0.97 | Val loss: 0.825 | Val acc: 0.75\n",
      "Epoch:   83 | Train loss: 0.313 | Train acc: 0.97 | Val loss: 0.783 | Val acc: 0.77\n",
      "Epoch:   84 | Train loss: 0.337 | Train acc: 0.95 | Val loss: 0.875 | Val acc: 0.73\n",
      "Epoch:   85 | Train loss: 0.304 | Train acc: 0.94 | Val loss: 0.796 | Val acc: 0.77\n",
      "Epoch:   86 | Train loss: 0.300 | Train acc: 0.96 | Val loss: 0.850 | Val acc: 0.73\n",
      "Epoch:   87 | Train loss: 0.300 | Train acc: 0.96 | Val loss: 0.858 | Val acc: 0.73\n",
      "Epoch:   88 | Train loss: 0.285 | Train acc: 0.98 | Val loss: 0.811 | Val acc: 0.76\n",
      "Epoch:   89 | Train loss: 0.322 | Train acc: 0.95 | Val loss: 0.863 | Val acc: 0.73\n",
      "Epoch:   90 | Train loss: 0.318 | Train acc: 0.94 | Val loss: 0.818 | Val acc: 0.77\n",
      "Epoch:   91 | Train loss: 0.326 | Train acc: 0.93 | Val loss: 0.867 | Val acc: 0.74\n",
      "Epoch:   92 | Train loss: 0.277 | Train acc: 0.98 | Val loss: 0.773 | Val acc: 0.77\n",
      "Epoch:   93 | Train loss: 0.272 | Train acc: 0.96 | Val loss: 0.811 | Val acc: 0.75\n",
      "Epoch:   94 | Train loss: 0.312 | Train acc: 0.97 | Val loss: 0.865 | Val acc: 0.74\n",
      "Epoch:   95 | Train loss: 0.309 | Train acc: 0.94 | Val loss: 0.806 | Val acc: 0.75\n",
      "Epoch:   96 | Train loss: 0.283 | Train acc: 0.96 | Val loss: 0.803 | Val acc: 0.75\n",
      "Epoch:   97 | Train loss: 0.286 | Train acc: 0.97 | Val loss: 0.824 | Val acc: 0.79\n",
      "Epoch:   98 | Train loss: 0.259 | Train acc: 0.96 | Val loss: 0.857 | Val acc: 0.74\n",
      "Epoch:   99 | Train loss: 0.263 | Train acc: 0.96 | Val loss: 0.878 | Val acc: 0.72\n",
      "Epoch:  100 | Train loss: 0.274 | Train acc: 0.98 | Val loss: 0.775 | Val acc: 0.76\n",
      "Epoch:  101 | Train loss: 0.265 | Train acc: 0.99 | Val loss: 0.779 | Val acc: 0.75\n",
      "Epoch:  102 | Train loss: 0.258 | Train acc: 0.97 | Val loss: 0.773 | Val acc: 0.75\n",
      "Epoch:  103 | Train loss: 0.295 | Train acc: 0.94 | Val loss: 0.771 | Val acc: 0.76\n",
      "Epoch:  104 | Train loss: 0.312 | Train acc: 0.94 | Val loss: 0.901 | Val acc: 0.72\n",
      "Epoch:  105 | Train loss: 0.262 | Train acc: 0.97 | Val loss: 0.772 | Val acc: 0.74\n",
      "Epoch:  106 | Train loss: 0.259 | Train acc: 0.95 | Val loss: 0.800 | Val acc: 0.75\n",
      "Epoch:  107 | Train loss: 0.237 | Train acc: 0.99 | Val loss: 0.801 | Val acc: 0.75\n",
      "Epoch:  108 | Train loss: 0.292 | Train acc: 0.96 | Val loss: 0.811 | Val acc: 0.74\n",
      "Epoch:  109 | Train loss: 0.265 | Train acc: 0.97 | Val loss: 0.860 | Val acc: 0.74\n",
      "Epoch:  110 | Train loss: 0.214 | Train acc: 0.98 | Val loss: 0.725 | Val acc: 0.78\n",
      "Epoch:  111 | Train loss: 0.246 | Train acc: 0.96 | Val loss: 0.783 | Val acc: 0.74\n",
      "Epoch:  112 | Train loss: 0.256 | Train acc: 0.96 | Val loss: 0.747 | Val acc: 0.75\n",
      "Epoch:  113 | Train loss: 0.247 | Train acc: 0.97 | Val loss: 0.817 | Val acc: 0.74\n",
      "Epoch:  114 | Train loss: 0.242 | Train acc: 0.96 | Val loss: 0.814 | Val acc: 0.75\n",
      "Epoch:  115 | Train loss: 0.252 | Train acc: 0.96 | Val loss: 0.780 | Val acc: 0.77\n",
      "Epoch:  116 | Train loss: 0.261 | Train acc: 0.98 | Val loss: 0.748 | Val acc: 0.78\n",
      "Epoch:  117 | Train loss: 0.248 | Train acc: 0.98 | Val loss: 0.799 | Val acc: 0.75\n",
      "Epoch:  118 | Train loss: 0.222 | Train acc: 0.97 | Val loss: 0.796 | Val acc: 0.74\n",
      "Epoch:  119 | Train loss: 0.223 | Train acc: 0.96 | Val loss: 0.815 | Val acc: 0.73\n",
      "Epoch:  120 | Train loss: 0.220 | Train acc: 0.98 | Val loss: 0.767 | Val acc: 0.75\n",
      "EARLY STOPPING condition met. Stopped at epoch: 120.\n",
      "Total training time: 1.41 seconds\n",
      "\n",
      "Test loss: 0.692  |  Test acc: 0.81\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_acc</td><td>▁▂▃▄▅▆▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇██████████████████</td></tr><tr><td>training_loss</td><td>███▇▇▆▆▆▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▄▅▆▆▇▇█▇█▇▇███▇████▇████▇▇████▇█████</td></tr><tr><td>val_loss</td><td>███▇▇▆▆▆▅▅▄▄▄▃▃▃▂▃▃▂▂▂▂▂▂▂▂▁▂▂▁▁▂▁▂▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>120</td></tr><tr><td>training_acc</td><td>0.97857</td></tr><tr><td>training_loss</td><td>0.22008</td></tr><tr><td>val_acc</td><td>0.752</td></tr><tr><td>val_loss</td><td>0.76713</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">scarlet-sweep-9</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/ub696ayq' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/ub696ayq</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234306-ub696ayq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6kgzehvj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adadelta\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234332-6kgzehvj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/6kgzehvj' target=\"_blank\">lunar-sweep-10</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/6kgzehvj' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/6kgzehvj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.956 | Train acc: 0.11 | Val loss: 1.937 | Val acc: 0.21\n",
      "Epoch:    1 | Train loss: 1.957 | Train acc: 0.14 | Val loss: 1.934 | Val acc: 0.22\n",
      "Epoch:    2 | Train loss: 1.951 | Train acc: 0.13 | Val loss: 1.933 | Val acc: 0.22\n",
      "Epoch:    3 | Train loss: 1.949 | Train acc: 0.13 | Val loss: 1.933 | Val acc: 0.23\n",
      "Epoch:    4 | Train loss: 1.948 | Train acc: 0.20 | Val loss: 1.932 | Val acc: 0.23\n",
      "Epoch:    5 | Train loss: 1.944 | Train acc: 0.18 | Val loss: 1.933 | Val acc: 0.24\n",
      "Epoch:    6 | Train loss: 1.946 | Train acc: 0.15 | Val loss: 1.931 | Val acc: 0.23\n",
      "Epoch:    7 | Train loss: 1.943 | Train acc: 0.19 | Val loss: 1.928 | Val acc: 0.25\n",
      "Epoch:    8 | Train loss: 1.939 | Train acc: 0.20 | Val loss: 1.927 | Val acc: 0.24\n",
      "Epoch:    9 | Train loss: 1.941 | Train acc: 0.15 | Val loss: 1.928 | Val acc: 0.25\n",
      "Epoch:   10 | Train loss: 1.940 | Train acc: 0.19 | Val loss: 1.927 | Val acc: 0.24\n",
      "Epoch:   11 | Train loss: 1.933 | Train acc: 0.21 | Val loss: 1.925 | Val acc: 0.29\n",
      "Epoch:   12 | Train loss: 1.930 | Train acc: 0.26 | Val loss: 1.923 | Val acc: 0.28\n",
      "Epoch:   13 | Train loss: 1.925 | Train acc: 0.25 | Val loss: 1.922 | Val acc: 0.25\n",
      "Epoch:   14 | Train loss: 1.931 | Train acc: 0.23 | Val loss: 1.921 | Val acc: 0.27\n",
      "Epoch:   15 | Train loss: 1.925 | Train acc: 0.23 | Val loss: 1.919 | Val acc: 0.30\n",
      "Epoch:   16 | Train loss: 1.924 | Train acc: 0.25 | Val loss: 1.919 | Val acc: 0.30\n",
      "Epoch:   17 | Train loss: 1.929 | Train acc: 0.16 | Val loss: 1.919 | Val acc: 0.25\n",
      "Epoch:   18 | Train loss: 1.917 | Train acc: 0.23 | Val loss: 1.918 | Val acc: 0.26\n",
      "Epoch:   19 | Train loss: 1.916 | Train acc: 0.21 | Val loss: 1.915 | Val acc: 0.30\n",
      "Epoch:   20 | Train loss: 1.918 | Train acc: 0.25 | Val loss: 1.911 | Val acc: 0.30\n",
      "Epoch:   21 | Train loss: 1.914 | Train acc: 0.31 | Val loss: 1.916 | Val acc: 0.31\n",
      "Epoch:   22 | Train loss: 1.905 | Train acc: 0.30 | Val loss: 1.911 | Val acc: 0.31\n",
      "Epoch:   23 | Train loss: 1.908 | Train acc: 0.30 | Val loss: 1.909 | Val acc: 0.30\n",
      "Epoch:   24 | Train loss: 1.907 | Train acc: 0.33 | Val loss: 1.904 | Val acc: 0.35\n",
      "Epoch:   25 | Train loss: 1.898 | Train acc: 0.30 | Val loss: 1.905 | Val acc: 0.31\n",
      "Epoch:   26 | Train loss: 1.903 | Train acc: 0.39 | Val loss: 1.903 | Val acc: 0.35\n",
      "Epoch:   27 | Train loss: 1.905 | Train acc: 0.31 | Val loss: 1.903 | Val acc: 0.34\n",
      "Epoch:   28 | Train loss: 1.897 | Train acc: 0.34 | Val loss: 1.903 | Val acc: 0.35\n",
      "Epoch:   29 | Train loss: 1.897 | Train acc: 0.37 | Val loss: 1.899 | Val acc: 0.35\n",
      "Epoch:   30 | Train loss: 1.894 | Train acc: 0.33 | Val loss: 1.898 | Val acc: 0.33\n",
      "Epoch:   31 | Train loss: 1.883 | Train acc: 0.34 | Val loss: 1.890 | Val acc: 0.41\n",
      "Epoch:   32 | Train loss: 1.886 | Train acc: 0.32 | Val loss: 1.894 | Val acc: 0.34\n",
      "Epoch:   33 | Train loss: 1.881 | Train acc: 0.39 | Val loss: 1.894 | Val acc: 0.36\n",
      "Epoch:   34 | Train loss: 1.880 | Train acc: 0.39 | Val loss: 1.894 | Val acc: 0.33\n",
      "Epoch:   35 | Train loss: 1.875 | Train acc: 0.36 | Val loss: 1.889 | Val acc: 0.37\n",
      "Epoch:   36 | Train loss: 1.875 | Train acc: 0.40 | Val loss: 1.888 | Val acc: 0.39\n",
      "Epoch:   37 | Train loss: 1.873 | Train acc: 0.41 | Val loss: 1.884 | Val acc: 0.40\n",
      "Epoch:   38 | Train loss: 1.858 | Train acc: 0.41 | Val loss: 1.886 | Val acc: 0.36\n",
      "Epoch:   39 | Train loss: 1.865 | Train acc: 0.33 | Val loss: 1.879 | Val acc: 0.36\n",
      "Epoch:   40 | Train loss: 1.863 | Train acc: 0.43 | Val loss: 1.879 | Val acc: 0.37\n",
      "Epoch:   41 | Train loss: 1.860 | Train acc: 0.36 | Val loss: 1.878 | Val acc: 0.38\n",
      "Epoch:   42 | Train loss: 1.857 | Train acc: 0.42 | Val loss: 1.874 | Val acc: 0.40\n",
      "Epoch:   43 | Train loss: 1.854 | Train acc: 0.37 | Val loss: 1.873 | Val acc: 0.36\n",
      "Epoch:   44 | Train loss: 1.856 | Train acc: 0.38 | Val loss: 1.876 | Val acc: 0.37\n",
      "Epoch:   45 | Train loss: 1.852 | Train acc: 0.41 | Val loss: 1.870 | Val acc: 0.37\n",
      "Epoch:   46 | Train loss: 1.845 | Train acc: 0.43 | Val loss: 1.873 | Val acc: 0.37\n",
      "Epoch:   47 | Train loss: 1.836 | Train acc: 0.43 | Val loss: 1.864 | Val acc: 0.42\n",
      "Epoch:   48 | Train loss: 1.836 | Train acc: 0.44 | Val loss: 1.866 | Val acc: 0.39\n",
      "Epoch:   49 | Train loss: 1.825 | Train acc: 0.46 | Val loss: 1.859 | Val acc: 0.38\n",
      "Epoch:   50 | Train loss: 1.831 | Train acc: 0.43 | Val loss: 1.857 | Val acc: 0.41\n",
      "Epoch:   51 | Train loss: 1.826 | Train acc: 0.46 | Val loss: 1.857 | Val acc: 0.39\n",
      "Epoch:   52 | Train loss: 1.823 | Train acc: 0.51 | Val loss: 1.858 | Val acc: 0.41\n",
      "Epoch:   53 | Train loss: 1.819 | Train acc: 0.51 | Val loss: 1.850 | Val acc: 0.38\n",
      "Epoch:   54 | Train loss: 1.816 | Train acc: 0.49 | Val loss: 1.852 | Val acc: 0.40\n",
      "Epoch:   55 | Train loss: 1.809 | Train acc: 0.51 | Val loss: 1.841 | Val acc: 0.44\n",
      "Epoch:   56 | Train loss: 1.808 | Train acc: 0.51 | Val loss: 1.840 | Val acc: 0.42\n",
      "Epoch:   57 | Train loss: 1.807 | Train acc: 0.51 | Val loss: 1.844 | Val acc: 0.44\n",
      "Epoch:   58 | Train loss: 1.795 | Train acc: 0.49 | Val loss: 1.843 | Val acc: 0.43\n",
      "Epoch:   59 | Train loss: 1.789 | Train acc: 0.54 | Val loss: 1.835 | Val acc: 0.41\n",
      "Epoch:   60 | Train loss: 1.793 | Train acc: 0.51 | Val loss: 1.836 | Val acc: 0.42\n",
      "Epoch:   61 | Train loss: 1.793 | Train acc: 0.49 | Val loss: 1.834 | Val acc: 0.41\n",
      "Epoch:   62 | Train loss: 1.783 | Train acc: 0.54 | Val loss: 1.825 | Val acc: 0.45\n",
      "Epoch:   63 | Train loss: 1.774 | Train acc: 0.55 | Val loss: 1.822 | Val acc: 0.49\n",
      "Epoch:   64 | Train loss: 1.776 | Train acc: 0.54 | Val loss: 1.819 | Val acc: 0.45\n",
      "Epoch:   65 | Train loss: 1.768 | Train acc: 0.56 | Val loss: 1.825 | Val acc: 0.45\n",
      "Epoch:   66 | Train loss: 1.762 | Train acc: 0.56 | Val loss: 1.816 | Val acc: 0.46\n",
      "Epoch:   67 | Train loss: 1.764 | Train acc: 0.52 | Val loss: 1.807 | Val acc: 0.51\n",
      "Epoch:   68 | Train loss: 1.764 | Train acc: 0.55 | Val loss: 1.821 | Val acc: 0.44\n",
      "Epoch:   69 | Train loss: 1.753 | Train acc: 0.57 | Val loss: 1.805 | Val acc: 0.51\n",
      "Epoch:   70 | Train loss: 1.748 | Train acc: 0.53 | Val loss: 1.799 | Val acc: 0.47\n",
      "Epoch:   71 | Train loss: 1.742 | Train acc: 0.58 | Val loss: 1.799 | Val acc: 0.50\n",
      "Epoch:   72 | Train loss: 1.746 | Train acc: 0.59 | Val loss: 1.811 | Val acc: 0.46\n",
      "Epoch:   73 | Train loss: 1.749 | Train acc: 0.56 | Val loss: 1.794 | Val acc: 0.49\n",
      "Epoch:   74 | Train loss: 1.739 | Train acc: 0.62 | Val loss: 1.795 | Val acc: 0.51\n",
      "Epoch:   75 | Train loss: 1.706 | Train acc: 0.59 | Val loss: 1.786 | Val acc: 0.53\n",
      "Epoch:   76 | Train loss: 1.736 | Train acc: 0.56 | Val loss: 1.789 | Val acc: 0.47\n",
      "Epoch:   77 | Train loss: 1.725 | Train acc: 0.60 | Val loss: 1.797 | Val acc: 0.50\n",
      "Epoch:   78 | Train loss: 1.718 | Train acc: 0.62 | Val loss: 1.787 | Val acc: 0.50\n",
      "Epoch:   79 | Train loss: 1.725 | Train acc: 0.66 | Val loss: 1.785 | Val acc: 0.53\n",
      "Epoch:   80 | Train loss: 1.683 | Train acc: 0.66 | Val loss: 1.780 | Val acc: 0.51\n",
      "Epoch:   81 | Train loss: 1.698 | Train acc: 0.64 | Val loss: 1.778 | Val acc: 0.51\n",
      "Epoch:   82 | Train loss: 1.684 | Train acc: 0.68 | Val loss: 1.779 | Val acc: 0.50\n",
      "Epoch:   83 | Train loss: 1.699 | Train acc: 0.61 | Val loss: 1.781 | Val acc: 0.50\n",
      "Epoch:   84 | Train loss: 1.695 | Train acc: 0.64 | Val loss: 1.771 | Val acc: 0.51\n",
      "Epoch:   85 | Train loss: 1.696 | Train acc: 0.64 | Val loss: 1.773 | Val acc: 0.50\n",
      "Epoch:   86 | Train loss: 1.676 | Train acc: 0.68 | Val loss: 1.762 | Val acc: 0.52\n",
      "Epoch:   87 | Train loss: 1.677 | Train acc: 0.66 | Val loss: 1.752 | Val acc: 0.56\n",
      "Epoch:   88 | Train loss: 1.671 | Train acc: 0.63 | Val loss: 1.762 | Val acc: 0.54\n",
      "Epoch:   89 | Train loss: 1.665 | Train acc: 0.66 | Val loss: 1.750 | Val acc: 0.57\n",
      "Epoch:   90 | Train loss: 1.651 | Train acc: 0.69 | Val loss: 1.758 | Val acc: 0.52\n",
      "Epoch:   91 | Train loss: 1.662 | Train acc: 0.71 | Val loss: 1.745 | Val acc: 0.58\n",
      "Epoch:   92 | Train loss: 1.649 | Train acc: 0.65 | Val loss: 1.743 | Val acc: 0.54\n",
      "Epoch:   93 | Train loss: 1.647 | Train acc: 0.74 | Val loss: 1.744 | Val acc: 0.55\n",
      "Epoch:   94 | Train loss: 1.644 | Train acc: 0.76 | Val loss: 1.750 | Val acc: 0.52\n",
      "Epoch:   95 | Train loss: 1.637 | Train acc: 0.69 | Val loss: 1.741 | Val acc: 0.58\n",
      "Epoch:   96 | Train loss: 1.650 | Train acc: 0.67 | Val loss: 1.725 | Val acc: 0.55\n",
      "Epoch:   97 | Train loss: 1.631 | Train acc: 0.69 | Val loss: 1.734 | Val acc: 0.55\n",
      "Epoch:   98 | Train loss: 1.639 | Train acc: 0.71 | Val loss: 1.738 | Val acc: 0.54\n",
      "Epoch:   99 | Train loss: 1.635 | Train acc: 0.71 | Val loss: 1.737 | Val acc: 0.57\n",
      "Total training time: 1.19 seconds\n",
      "\n",
      "Test loss: 1.747  |  Test acc: 0.65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_acc</td><td>▁▁▂▂▂▃▂▂▃▃▃▃▃▄▄▄▅▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇██▇█</td></tr><tr><td>training_loss</td><td>█████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▂▂▂▃▂▃▃▃▄▃▄▄▄▄▄▄▄▅▄▅▅▅▆▆▅▇▆▆▆▇▇▇▇█▇▇█</td></tr><tr><td>val_loss</td><td>██████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>training_acc</td><td>0.71429</td></tr><tr><td>training_loss</td><td>1.63451</td></tr><tr><td>val_acc</td><td>0.574</td></tr><tr><td>val_loss</td><td>1.73663</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lunar-sweep-10</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/6kgzehvj' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/6kgzehvj</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234332-6kgzehvj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d1gd5i81 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adadelta\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234358-d1gd5i81</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/d1gd5i81' target=\"_blank\">celestial-sweep-11</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/d1gd5i81' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/d1gd5i81</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.951 | Train acc: 0.17 | Val loss: 1.934 | Val acc: 0.24\n",
      "Epoch:    1 | Train loss: 1.960 | Train acc: 0.09 | Val loss: 1.937 | Val acc: 0.21\n",
      "Epoch:    2 | Train loss: 1.958 | Train acc: 0.12 | Val loss: 1.941 | Val acc: 0.19\n",
      "Epoch:    3 | Train loss: 1.953 | Train acc: 0.11 | Val loss: 1.934 | Val acc: 0.18\n",
      "Epoch:    4 | Train loss: 1.951 | Train acc: 0.16 | Val loss: 1.935 | Val acc: 0.22\n",
      "Epoch:    5 | Train loss: 1.951 | Train acc: 0.16 | Val loss: 1.934 | Val acc: 0.23\n",
      "Epoch:    6 | Train loss: 1.953 | Train acc: 0.16 | Val loss: 1.937 | Val acc: 0.25\n",
      "Epoch:    7 | Train loss: 1.945 | Train acc: 0.14 | Val loss: 1.936 | Val acc: 0.22\n",
      "Epoch:    8 | Train loss: 1.953 | Train acc: 0.11 | Val loss: 1.934 | Val acc: 0.18\n",
      "Epoch:    9 | Train loss: 1.952 | Train acc: 0.11 | Val loss: 1.938 | Val acc: 0.20\n",
      "Epoch:   10 | Train loss: 1.949 | Train acc: 0.16 | Val loss: 1.936 | Val acc: 0.20\n",
      "Epoch:   11 | Train loss: 1.953 | Train acc: 0.12 | Val loss: 1.936 | Val acc: 0.20\n",
      "Epoch:   12 | Train loss: 1.946 | Train acc: 0.13 | Val loss: 1.937 | Val acc: 0.17\n",
      "Epoch:   13 | Train loss: 1.949 | Train acc: 0.12 | Val loss: 1.935 | Val acc: 0.21\n",
      "EARLY STOPPING condition met. Stopped at epoch: 13.\n",
      "Total training time: 0.18 seconds\n",
      "\n",
      "Test loss: 1.943  |  Test acc: 0.15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>training_acc</td><td>█▁▄▃▇▇▇▆▃▃▇▄▅▄</td></tr><tr><td>training_loss</td><td>▄█▇▅▄▄▅▁▅▄▃▅▂▃</td></tr><tr><td>val_acc</td><td>▇▅▃▂▆▆█▆▂▄▃▄▁▄</td></tr><tr><td>val_loss</td><td>▁▄█▁▂▁▄▄▁▅▄▃▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>13</td></tr><tr><td>training_acc</td><td>0.12143</td></tr><tr><td>training_loss</td><td>1.9491</td></tr><tr><td>val_acc</td><td>0.208</td></tr><tr><td>val_loss</td><td>1.93452</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-sweep-11</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/d1gd5i81' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/d1gd5i81</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234358-d1gd5i81/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7umivdgl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adadelta\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234417-7umivdgl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/7umivdgl' target=\"_blank\">efficient-sweep-12</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/7umivdgl' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/7umivdgl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.956 | Train acc: 0.09 | Val loss: 1.925 | Val acc: 0.30\n",
      "Epoch:    1 | Train loss: 1.952 | Train acc: 0.10 | Val loss: 1.920 | Val acc: 0.28\n",
      "Epoch:    2 | Train loss: 1.950 | Train acc: 0.11 | Val loss: 1.923 | Val acc: 0.29\n",
      "Epoch:    3 | Train loss: 1.944 | Train acc: 0.12 | Val loss: 1.918 | Val acc: 0.32\n",
      "Epoch:    4 | Train loss: 1.953 | Train acc: 0.10 | Val loss: 1.921 | Val acc: 0.27\n",
      "Epoch:    5 | Train loss: 1.946 | Train acc: 0.14 | Val loss: 1.924 | Val acc: 0.28\n",
      "Epoch:    6 | Train loss: 1.935 | Train acc: 0.14 | Val loss: 1.909 | Val acc: 0.31\n",
      "Epoch:    7 | Train loss: 1.942 | Train acc: 0.13 | Val loss: 1.913 | Val acc: 0.34\n",
      "Epoch:    8 | Train loss: 1.938 | Train acc: 0.14 | Val loss: 1.914 | Val acc: 0.29\n",
      "Epoch:    9 | Train loss: 1.934 | Train acc: 0.15 | Val loss: 1.919 | Val acc: 0.28\n",
      "Epoch:   10 | Train loss: 1.928 | Train acc: 0.16 | Val loss: 1.917 | Val acc: 0.28\n",
      "Epoch:   11 | Train loss: 1.922 | Train acc: 0.13 | Val loss: 1.911 | Val acc: 0.32\n",
      "Epoch:   12 | Train loss: 1.927 | Train acc: 0.14 | Val loss: 1.911 | Val acc: 0.29\n",
      "Epoch:   13 | Train loss: 1.925 | Train acc: 0.14 | Val loss: 1.911 | Val acc: 0.30\n",
      "Epoch:   14 | Train loss: 1.923 | Train acc: 0.17 | Val loss: 1.908 | Val acc: 0.31\n",
      "Epoch:   15 | Train loss: 1.926 | Train acc: 0.16 | Val loss: 1.909 | Val acc: 0.32\n",
      "Epoch:   16 | Train loss: 1.916 | Train acc: 0.19 | Val loss: 1.906 | Val acc: 0.34\n",
      "Epoch:   17 | Train loss: 1.921 | Train acc: 0.19 | Val loss: 1.902 | Val acc: 0.34\n",
      "Epoch:   18 | Train loss: 1.915 | Train acc: 0.14 | Val loss: 1.906 | Val acc: 0.32\n",
      "Epoch:   19 | Train loss: 1.911 | Train acc: 0.19 | Val loss: 1.901 | Val acc: 0.32\n",
      "Epoch:   20 | Train loss: 1.910 | Train acc: 0.20 | Val loss: 1.903 | Val acc: 0.31\n",
      "Epoch:   21 | Train loss: 1.908 | Train acc: 0.21 | Val loss: 1.899 | Val acc: 0.31\n",
      "Epoch:   22 | Train loss: 1.907 | Train acc: 0.18 | Val loss: 1.902 | Val acc: 0.30\n",
      "Epoch:   23 | Train loss: 1.910 | Train acc: 0.24 | Val loss: 1.901 | Val acc: 0.34\n",
      "Epoch:   24 | Train loss: 1.896 | Train acc: 0.26 | Val loss: 1.897 | Val acc: 0.31\n",
      "Epoch:   25 | Train loss: 1.899 | Train acc: 0.21 | Val loss: 1.895 | Val acc: 0.31\n",
      "Epoch:   26 | Train loss: 1.895 | Train acc: 0.29 | Val loss: 1.893 | Val acc: 0.34\n",
      "Epoch:   27 | Train loss: 1.902 | Train acc: 0.26 | Val loss: 1.897 | Val acc: 0.30\n",
      "Epoch:   28 | Train loss: 1.898 | Train acc: 0.24 | Val loss: 1.891 | Val acc: 0.32\n",
      "Epoch:   29 | Train loss: 1.896 | Train acc: 0.27 | Val loss: 1.891 | Val acc: 0.34\n",
      "Epoch:   30 | Train loss: 1.886 | Train acc: 0.34 | Val loss: 1.889 | Val acc: 0.32\n",
      "Epoch:   31 | Train loss: 1.888 | Train acc: 0.29 | Val loss: 1.886 | Val acc: 0.36\n",
      "Epoch:   32 | Train loss: 1.883 | Train acc: 0.38 | Val loss: 1.888 | Val acc: 0.36\n",
      "Epoch:   33 | Train loss: 1.879 | Train acc: 0.29 | Val loss: 1.882 | Val acc: 0.36\n",
      "Epoch:   34 | Train loss: 1.873 | Train acc: 0.34 | Val loss: 1.882 | Val acc: 0.34\n",
      "Epoch:   35 | Train loss: 1.873 | Train acc: 0.37 | Val loss: 1.879 | Val acc: 0.37\n",
      "Epoch:   36 | Train loss: 1.873 | Train acc: 0.30 | Val loss: 1.880 | Val acc: 0.35\n",
      "Epoch:   37 | Train loss: 1.875 | Train acc: 0.39 | Val loss: 1.876 | Val acc: 0.33\n",
      "Epoch:   38 | Train loss: 1.872 | Train acc: 0.34 | Val loss: 1.876 | Val acc: 0.39\n",
      "Epoch:   39 | Train loss: 1.867 | Train acc: 0.39 | Val loss: 1.875 | Val acc: 0.37\n",
      "Epoch:   40 | Train loss: 1.856 | Train acc: 0.41 | Val loss: 1.870 | Val acc: 0.37\n",
      "Epoch:   41 | Train loss: 1.865 | Train acc: 0.34 | Val loss: 1.876 | Val acc: 0.36\n",
      "Epoch:   42 | Train loss: 1.853 | Train acc: 0.45 | Val loss: 1.867 | Val acc: 0.40\n",
      "Epoch:   43 | Train loss: 1.853 | Train acc: 0.43 | Val loss: 1.865 | Val acc: 0.41\n",
      "Epoch:   44 | Train loss: 1.849 | Train acc: 0.44 | Val loss: 1.865 | Val acc: 0.42\n",
      "Epoch:   45 | Train loss: 1.854 | Train acc: 0.47 | Val loss: 1.865 | Val acc: 0.40\n",
      "Epoch:   46 | Train loss: 1.853 | Train acc: 0.46 | Val loss: 1.864 | Val acc: 0.37\n",
      "Epoch:   47 | Train loss: 1.839 | Train acc: 0.49 | Val loss: 1.862 | Val acc: 0.41\n",
      "Epoch:   48 | Train loss: 1.836 | Train acc: 0.46 | Val loss: 1.854 | Val acc: 0.42\n",
      "Epoch:   49 | Train loss: 1.834 | Train acc: 0.46 | Val loss: 1.859 | Val acc: 0.39\n",
      "Epoch:   50 | Train loss: 1.839 | Train acc: 0.47 | Val loss: 1.847 | Val acc: 0.43\n",
      "Epoch:   51 | Train loss: 1.831 | Train acc: 0.48 | Val loss: 1.854 | Val acc: 0.42\n",
      "Epoch:   52 | Train loss: 1.829 | Train acc: 0.52 | Val loss: 1.849 | Val acc: 0.41\n",
      "Epoch:   53 | Train loss: 1.826 | Train acc: 0.49 | Val loss: 1.849 | Val acc: 0.42\n",
      "Epoch:   54 | Train loss: 1.813 | Train acc: 0.50 | Val loss: 1.842 | Val acc: 0.41\n",
      "Epoch:   55 | Train loss: 1.821 | Train acc: 0.50 | Val loss: 1.847 | Val acc: 0.41\n",
      "Epoch:   56 | Train loss: 1.819 | Train acc: 0.54 | Val loss: 1.845 | Val acc: 0.44\n",
      "Epoch:   57 | Train loss: 1.807 | Train acc: 0.56 | Val loss: 1.840 | Val acc: 0.40\n",
      "Epoch:   58 | Train loss: 1.800 | Train acc: 0.51 | Val loss: 1.837 | Val acc: 0.46\n",
      "Epoch:   59 | Train loss: 1.801 | Train acc: 0.55 | Val loss: 1.836 | Val acc: 0.43\n",
      "Epoch:   60 | Train loss: 1.797 | Train acc: 0.51 | Val loss: 1.834 | Val acc: 0.42\n",
      "Epoch:   61 | Train loss: 1.796 | Train acc: 0.52 | Val loss: 1.830 | Val acc: 0.46\n",
      "Epoch:   62 | Train loss: 1.784 | Train acc: 0.56 | Val loss: 1.825 | Val acc: 0.43\n",
      "Epoch:   63 | Train loss: 1.790 | Train acc: 0.56 | Val loss: 1.826 | Val acc: 0.45\n",
      "Epoch:   64 | Train loss: 1.784 | Train acc: 0.59 | Val loss: 1.825 | Val acc: 0.44\n",
      "Epoch:   65 | Train loss: 1.776 | Train acc: 0.60 | Val loss: 1.825 | Val acc: 0.45\n",
      "Epoch:   66 | Train loss: 1.788 | Train acc: 0.54 | Val loss: 1.823 | Val acc: 0.45\n",
      "Epoch:   67 | Train loss: 1.785 | Train acc: 0.59 | Val loss: 1.821 | Val acc: 0.49\n",
      "Epoch:   68 | Train loss: 1.779 | Train acc: 0.57 | Val loss: 1.816 | Val acc: 0.50\n",
      "Epoch:   69 | Train loss: 1.780 | Train acc: 0.56 | Val loss: 1.819 | Val acc: 0.45\n",
      "Epoch:   70 | Train loss: 1.781 | Train acc: 0.52 | Val loss: 1.811 | Val acc: 0.47\n",
      "Epoch:   71 | Train loss: 1.773 | Train acc: 0.59 | Val loss: 1.814 | Val acc: 0.47\n",
      "Epoch:   72 | Train loss: 1.768 | Train acc: 0.55 | Val loss: 1.818 | Val acc: 0.44\n",
      "Epoch:   73 | Train loss: 1.775 | Train acc: 0.51 | Val loss: 1.808 | Val acc: 0.43\n",
      "Epoch:   74 | Train loss: 1.751 | Train acc: 0.61 | Val loss: 1.808 | Val acc: 0.46\n",
      "Epoch:   75 | Train loss: 1.756 | Train acc: 0.56 | Val loss: 1.798 | Val acc: 0.50\n",
      "Epoch:   76 | Train loss: 1.761 | Train acc: 0.49 | Val loss: 1.804 | Val acc: 0.46\n",
      "Epoch:   77 | Train loss: 1.743 | Train acc: 0.59 | Val loss: 1.797 | Val acc: 0.50\n",
      "Epoch:   78 | Train loss: 1.749 | Train acc: 0.59 | Val loss: 1.798 | Val acc: 0.46\n",
      "Epoch:   79 | Train loss: 1.743 | Train acc: 0.63 | Val loss: 1.798 | Val acc: 0.49\n",
      "Epoch:   80 | Train loss: 1.740 | Train acc: 0.61 | Val loss: 1.805 | Val acc: 0.45\n",
      "Epoch:   81 | Train loss: 1.725 | Train acc: 0.64 | Val loss: 1.789 | Val acc: 0.51\n",
      "Epoch:   82 | Train loss: 1.738 | Train acc: 0.59 | Val loss: 1.800 | Val acc: 0.46\n",
      "Epoch:   83 | Train loss: 1.712 | Train acc: 0.61 | Val loss: 1.781 | Val acc: 0.50\n",
      "Epoch:   84 | Train loss: 1.728 | Train acc: 0.57 | Val loss: 1.796 | Val acc: 0.41\n",
      "Epoch:   85 | Train loss: 1.703 | Train acc: 0.66 | Val loss: 1.783 | Val acc: 0.48\n",
      "Epoch:   86 | Train loss: 1.726 | Train acc: 0.61 | Val loss: 1.785 | Val acc: 0.49\n",
      "Epoch:   87 | Train loss: 1.709 | Train acc: 0.61 | Val loss: 1.774 | Val acc: 0.48\n",
      "Epoch:   88 | Train loss: 1.714 | Train acc: 0.63 | Val loss: 1.775 | Val acc: 0.50\n",
      "Epoch:   89 | Train loss: 1.705 | Train acc: 0.59 | Val loss: 1.766 | Val acc: 0.54\n",
      "Epoch:   90 | Train loss: 1.705 | Train acc: 0.59 | Val loss: 1.778 | Val acc: 0.44\n",
      "Epoch:   91 | Train loss: 1.691 | Train acc: 0.66 | Val loss: 1.764 | Val acc: 0.50\n",
      "Epoch:   92 | Train loss: 1.704 | Train acc: 0.63 | Val loss: 1.778 | Val acc: 0.45\n",
      "Epoch:   93 | Train loss: 1.694 | Train acc: 0.66 | Val loss: 1.772 | Val acc: 0.49\n",
      "Epoch:   94 | Train loss: 1.703 | Train acc: 0.61 | Val loss: 1.770 | Val acc: 0.46\n",
      "Epoch:   95 | Train loss: 1.686 | Train acc: 0.63 | Val loss: 1.764 | Val acc: 0.49\n",
      "Epoch:   96 | Train loss: 1.674 | Train acc: 0.66 | Val loss: 1.759 | Val acc: 0.47\n",
      "Epoch:   97 | Train loss: 1.676 | Train acc: 0.69 | Val loss: 1.757 | Val acc: 0.50\n",
      "Epoch:   98 | Train loss: 1.676 | Train acc: 0.63 | Val loss: 1.748 | Val acc: 0.52\n",
      "Epoch:   99 | Train loss: 1.672 | Train acc: 0.68 | Val loss: 1.751 | Val acc: 0.52\n",
      "Total training time: 1.18 seconds\n",
      "\n",
      "Test loss: 1.747  |  Test acc: 0.59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_acc</td><td>▁▁▂▁▂▂▂▂▂▂▂▃▄▃▄▄▅▅▆▅▆▆▆▆▆▇▆▇▇▆▆▇█▇▇▇████</td></tr><tr><td>training_loss</td><td>████▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▄▃▃▂▂▂▂▁▂▁▁</td></tr><tr><td>val_acc</td><td>▂▁▁▃▁▁▂▃▂▂▂▂▂▃▄▄▄▅▄▅▅▅▅▆▅▆▆▇▇▅▆▆█▇▇▇▇▇▇█</td></tr><tr><td>val_loss</td><td>███▇█▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>training_acc</td><td>0.67857</td></tr><tr><td>training_loss</td><td>1.67223</td></tr><tr><td>val_acc</td><td>0.52</td></tr><tr><td>val_loss</td><td>1.75115</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficient-sweep-12</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/7umivdgl' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/7umivdgl</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234417-7umivdgl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tct9l0ky with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 150\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adadelta\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234437-tct9l0ky</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/tct9l0ky' target=\"_blank\">lucky-sweep-13</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/tct9l0ky' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/tct9l0ky</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.957 | Train acc: 0.16 | Val loss: 1.948 | Val acc: 0.18\n",
      "Epoch:    1 | Train loss: 1.954 | Train acc: 0.12 | Val loss: 1.942 | Val acc: 0.22\n",
      "Epoch:    2 | Train loss: 1.947 | Train acc: 0.19 | Val loss: 1.943 | Val acc: 0.24\n",
      "Epoch:    3 | Train loss: 1.956 | Train acc: 0.14 | Val loss: 1.941 | Val acc: 0.19\n",
      "Epoch:    4 | Train loss: 1.949 | Train acc: 0.12 | Val loss: 1.943 | Val acc: 0.21\n",
      "Epoch:    5 | Train loss: 1.947 | Train acc: 0.17 | Val loss: 1.937 | Val acc: 0.24\n",
      "Epoch:    6 | Train loss: 1.946 | Train acc: 0.19 | Val loss: 1.939 | Val acc: 0.21\n",
      "Epoch:    7 | Train loss: 1.944 | Train acc: 0.18 | Val loss: 1.936 | Val acc: 0.25\n",
      "Epoch:    8 | Train loss: 1.940 | Train acc: 0.20 | Val loss: 1.938 | Val acc: 0.22\n",
      "Epoch:    9 | Train loss: 1.939 | Train acc: 0.22 | Val loss: 1.938 | Val acc: 0.23\n",
      "Epoch:   10 | Train loss: 1.938 | Train acc: 0.19 | Val loss: 1.932 | Val acc: 0.27\n",
      "Epoch:   11 | Train loss: 1.940 | Train acc: 0.19 | Val loss: 1.933 | Val acc: 0.26\n",
      "Epoch:   12 | Train loss: 1.932 | Train acc: 0.21 | Val loss: 1.933 | Val acc: 0.25\n",
      "Epoch:   13 | Train loss: 1.932 | Train acc: 0.23 | Val loss: 1.928 | Val acc: 0.31\n",
      "Epoch:   14 | Train loss: 1.928 | Train acc: 0.24 | Val loss: 1.933 | Val acc: 0.26\n",
      "Epoch:   15 | Train loss: 1.926 | Train acc: 0.24 | Val loss: 1.931 | Val acc: 0.27\n",
      "Epoch:   16 | Train loss: 1.928 | Train acc: 0.23 | Val loss: 1.925 | Val acc: 0.34\n",
      "Epoch:   17 | Train loss: 1.927 | Train acc: 0.25 | Val loss: 1.928 | Val acc: 0.30\n",
      "Epoch:   18 | Train loss: 1.924 | Train acc: 0.23 | Val loss: 1.927 | Val acc: 0.29\n",
      "Epoch:   19 | Train loss: 1.918 | Train acc: 0.28 | Val loss: 1.923 | Val acc: 0.32\n",
      "Epoch:   20 | Train loss: 1.921 | Train acc: 0.29 | Val loss: 1.923 | Val acc: 0.31\n",
      "Epoch:   21 | Train loss: 1.921 | Train acc: 0.29 | Val loss: 1.925 | Val acc: 0.30\n",
      "Epoch:   22 | Train loss: 1.913 | Train acc: 0.32 | Val loss: 1.924 | Val acc: 0.33\n",
      "Epoch:   23 | Train loss: 1.914 | Train acc: 0.31 | Val loss: 1.921 | Val acc: 0.34\n",
      "Epoch:   24 | Train loss: 1.911 | Train acc: 0.35 | Val loss: 1.924 | Val acc: 0.29\n",
      "Epoch:   25 | Train loss: 1.914 | Train acc: 0.26 | Val loss: 1.924 | Val acc: 0.29\n",
      "Epoch:   26 | Train loss: 1.910 | Train acc: 0.27 | Val loss: 1.922 | Val acc: 0.32\n",
      "Epoch:   27 | Train loss: 1.904 | Train acc: 0.36 | Val loss: 1.919 | Val acc: 0.32\n",
      "Epoch:   28 | Train loss: 1.901 | Train acc: 0.34 | Val loss: 1.917 | Val acc: 0.37\n",
      "Epoch:   29 | Train loss: 1.900 | Train acc: 0.39 | Val loss: 1.916 | Val acc: 0.35\n",
      "Epoch:   30 | Train loss: 1.897 | Train acc: 0.37 | Val loss: 1.914 | Val acc: 0.35\n",
      "Epoch:   31 | Train loss: 1.901 | Train acc: 0.35 | Val loss: 1.916 | Val acc: 0.33\n",
      "Epoch:   32 | Train loss: 1.894 | Train acc: 0.41 | Val loss: 1.917 | Val acc: 0.36\n",
      "Epoch:   33 | Train loss: 1.895 | Train acc: 0.34 | Val loss: 1.920 | Val acc: 0.29\n",
      "Epoch:   34 | Train loss: 1.888 | Train acc: 0.40 | Val loss: 1.911 | Val acc: 0.35\n",
      "Epoch:   35 | Train loss: 1.893 | Train acc: 0.44 | Val loss: 1.915 | Val acc: 0.34\n",
      "Epoch:   36 | Train loss: 1.886 | Train acc: 0.43 | Val loss: 1.913 | Val acc: 0.35\n",
      "Epoch:   37 | Train loss: 1.886 | Train acc: 0.40 | Val loss: 1.907 | Val acc: 0.34\n",
      "Epoch:   38 | Train loss: 1.885 | Train acc: 0.47 | Val loss: 1.907 | Val acc: 0.35\n",
      "Epoch:   39 | Train loss: 1.883 | Train acc: 0.42 | Val loss: 1.910 | Val acc: 0.34\n",
      "Epoch:   40 | Train loss: 1.871 | Train acc: 0.48 | Val loss: 1.901 | Val acc: 0.41\n",
      "Epoch:   41 | Train loss: 1.879 | Train acc: 0.47 | Val loss: 1.904 | Val acc: 0.39\n",
      "Epoch:   42 | Train loss: 1.875 | Train acc: 0.42 | Val loss: 1.909 | Val acc: 0.31\n",
      "Epoch:   43 | Train loss: 1.876 | Train acc: 0.45 | Val loss: 1.905 | Val acc: 0.34\n",
      "Epoch:   44 | Train loss: 1.870 | Train acc: 0.41 | Val loss: 1.905 | Val acc: 0.36\n",
      "Epoch:   45 | Train loss: 1.867 | Train acc: 0.43 | Val loss: 1.902 | Val acc: 0.37\n",
      "Epoch:   46 | Train loss: 1.870 | Train acc: 0.50 | Val loss: 1.900 | Val acc: 0.38\n",
      "Epoch:   47 | Train loss: 1.861 | Train acc: 0.48 | Val loss: 1.899 | Val acc: 0.40\n",
      "Epoch:   48 | Train loss: 1.863 | Train acc: 0.42 | Val loss: 1.898 | Val acc: 0.38\n",
      "Epoch:   49 | Train loss: 1.859 | Train acc: 0.46 | Val loss: 1.894 | Val acc: 0.39\n",
      "Epoch:   50 | Train loss: 1.858 | Train acc: 0.49 | Val loss: 1.903 | Val acc: 0.37\n",
      "Epoch:   51 | Train loss: 1.856 | Train acc: 0.45 | Val loss: 1.897 | Val acc: 0.37\n",
      "Epoch:   52 | Train loss: 1.850 | Train acc: 0.53 | Val loss: 1.889 | Val acc: 0.43\n",
      "Epoch:   53 | Train loss: 1.841 | Train acc: 0.54 | Val loss: 1.887 | Val acc: 0.45\n",
      "Epoch:   54 | Train loss: 1.845 | Train acc: 0.54 | Val loss: 1.891 | Val acc: 0.41\n",
      "Epoch:   55 | Train loss: 1.837 | Train acc: 0.56 | Val loss: 1.886 | Val acc: 0.43\n",
      "Epoch:   56 | Train loss: 1.846 | Train acc: 0.44 | Val loss: 1.885 | Val acc: 0.40\n",
      "Epoch:   57 | Train loss: 1.841 | Train acc: 0.56 | Val loss: 1.881 | Val acc: 0.44\n",
      "Epoch:   58 | Train loss: 1.827 | Train acc: 0.55 | Val loss: 1.877 | Val acc: 0.41\n",
      "Epoch:   59 | Train loss: 1.834 | Train acc: 0.55 | Val loss: 1.876 | Val acc: 0.47\n",
      "Epoch:   60 | Train loss: 1.830 | Train acc: 0.54 | Val loss: 1.878 | Val acc: 0.41\n",
      "Epoch:   61 | Train loss: 1.833 | Train acc: 0.58 | Val loss: 1.878 | Val acc: 0.44\n",
      "Epoch:   62 | Train loss: 1.820 | Train acc: 0.56 | Val loss: 1.882 | Val acc: 0.40\n",
      "Epoch:   63 | Train loss: 1.816 | Train acc: 0.61 | Val loss: 1.877 | Val acc: 0.43\n",
      "Epoch:   64 | Train loss: 1.811 | Train acc: 0.57 | Val loss: 1.871 | Val acc: 0.42\n",
      "Epoch:   65 | Train loss: 1.812 | Train acc: 0.59 | Val loss: 1.866 | Val acc: 0.44\n",
      "Epoch:   66 | Train loss: 1.816 | Train acc: 0.59 | Val loss: 1.863 | Val acc: 0.46\n",
      "Epoch:   67 | Train loss: 1.811 | Train acc: 0.57 | Val loss: 1.866 | Val acc: 0.41\n",
      "Epoch:   68 | Train loss: 1.791 | Train acc: 0.61 | Val loss: 1.860 | Val acc: 0.44\n",
      "Epoch:   69 | Train loss: 1.803 | Train acc: 0.59 | Val loss: 1.860 | Val acc: 0.46\n",
      "Epoch:   70 | Train loss: 1.801 | Train acc: 0.59 | Val loss: 1.861 | Val acc: 0.47\n",
      "Epoch:   71 | Train loss: 1.782 | Train acc: 0.63 | Val loss: 1.852 | Val acc: 0.47\n",
      "Epoch:   72 | Train loss: 1.796 | Train acc: 0.59 | Val loss: 1.857 | Val acc: 0.45\n",
      "Epoch:   73 | Train loss: 1.793 | Train acc: 0.54 | Val loss: 1.846 | Val acc: 0.49\n",
      "Epoch:   74 | Train loss: 1.781 | Train acc: 0.61 | Val loss: 1.853 | Val acc: 0.49\n",
      "Epoch:   75 | Train loss: 1.781 | Train acc: 0.62 | Val loss: 1.848 | Val acc: 0.50\n",
      "Epoch:   76 | Train loss: 1.780 | Train acc: 0.59 | Val loss: 1.855 | Val acc: 0.42\n",
      "Epoch:   77 | Train loss: 1.775 | Train acc: 0.60 | Val loss: 1.846 | Val acc: 0.51\n",
      "Epoch:   78 | Train loss: 1.772 | Train acc: 0.61 | Val loss: 1.851 | Val acc: 0.46\n",
      "Epoch:   79 | Train loss: 1.755 | Train acc: 0.69 | Val loss: 1.845 | Val acc: 0.49\n",
      "Epoch:   80 | Train loss: 1.770 | Train acc: 0.61 | Val loss: 1.834 | Val acc: 0.52\n",
      "Epoch:   81 | Train loss: 1.759 | Train acc: 0.62 | Val loss: 1.842 | Val acc: 0.46\n",
      "Epoch:   82 | Train loss: 1.758 | Train acc: 0.63 | Val loss: 1.833 | Val acc: 0.49\n",
      "Epoch:   83 | Train loss: 1.746 | Train acc: 0.66 | Val loss: 1.836 | Val acc: 0.46\n",
      "Epoch:   84 | Train loss: 1.744 | Train acc: 0.60 | Val loss: 1.831 | Val acc: 0.48\n",
      "Epoch:   85 | Train loss: 1.753 | Train acc: 0.66 | Val loss: 1.844 | Val acc: 0.47\n",
      "Epoch:   86 | Train loss: 1.721 | Train acc: 0.65 | Val loss: 1.833 | Val acc: 0.48\n",
      "Epoch:   87 | Train loss: 1.753 | Train acc: 0.64 | Val loss: 1.825 | Val acc: 0.53\n",
      "Epoch:   88 | Train loss: 1.726 | Train acc: 0.64 | Val loss: 1.809 | Val acc: 0.58\n",
      "Epoch:   89 | Train loss: 1.729 | Train acc: 0.67 | Val loss: 1.818 | Val acc: 0.50\n",
      "Epoch:   90 | Train loss: 1.732 | Train acc: 0.62 | Val loss: 1.831 | Val acc: 0.46\n",
      "Epoch:   91 | Train loss: 1.731 | Train acc: 0.62 | Val loss: 1.815 | Val acc: 0.54\n",
      "Epoch:   92 | Train loss: 1.723 | Train acc: 0.71 | Val loss: 1.810 | Val acc: 0.54\n",
      "Epoch:   93 | Train loss: 1.709 | Train acc: 0.69 | Val loss: 1.800 | Val acc: 0.57\n",
      "Epoch:   94 | Train loss: 1.712 | Train acc: 0.67 | Val loss: 1.805 | Val acc: 0.52\n",
      "Epoch:   95 | Train loss: 1.692 | Train acc: 0.79 | Val loss: 1.803 | Val acc: 0.53\n",
      "Epoch:   96 | Train loss: 1.708 | Train acc: 0.64 | Val loss: 1.810 | Val acc: 0.51\n",
      "Epoch:   97 | Train loss: 1.693 | Train acc: 0.70 | Val loss: 1.807 | Val acc: 0.51\n",
      "Epoch:   98 | Train loss: 1.696 | Train acc: 0.66 | Val loss: 1.805 | Val acc: 0.50\n",
      "Epoch:   99 | Train loss: 1.689 | Train acc: 0.71 | Val loss: 1.791 | Val acc: 0.53\n",
      "Epoch:  100 | Train loss: 1.669 | Train acc: 0.71 | Val loss: 1.791 | Val acc: 0.53\n",
      "Epoch:  101 | Train loss: 1.682 | Train acc: 0.74 | Val loss: 1.807 | Val acc: 0.47\n",
      "Epoch:  102 | Train loss: 1.674 | Train acc: 0.66 | Val loss: 1.804 | Val acc: 0.51\n",
      "Epoch:  103 | Train loss: 1.677 | Train acc: 0.67 | Val loss: 1.789 | Val acc: 0.53\n",
      "Epoch:  104 | Train loss: 1.660 | Train acc: 0.72 | Val loss: 1.790 | Val acc: 0.54\n",
      "Epoch:  105 | Train loss: 1.645 | Train acc: 0.75 | Val loss: 1.768 | Val acc: 0.61\n",
      "Epoch:  106 | Train loss: 1.633 | Train acc: 0.76 | Val loss: 1.758 | Val acc: 0.60\n",
      "Epoch:  107 | Train loss: 1.660 | Train acc: 0.69 | Val loss: 1.768 | Val acc: 0.59\n",
      "Epoch:  108 | Train loss: 1.642 | Train acc: 0.79 | Val loss: 1.779 | Val acc: 0.54\n",
      "Epoch:  109 | Train loss: 1.655 | Train acc: 0.70 | Val loss: 1.760 | Val acc: 0.60\n",
      "Epoch:  110 | Train loss: 1.642 | Train acc: 0.73 | Val loss: 1.772 | Val acc: 0.53\n",
      "Epoch:  111 | Train loss: 1.638 | Train acc: 0.77 | Val loss: 1.762 | Val acc: 0.58\n",
      "Epoch:  112 | Train loss: 1.623 | Train acc: 0.77 | Val loss: 1.767 | Val acc: 0.56\n",
      "Epoch:  113 | Train loss: 1.598 | Train acc: 0.78 | Val loss: 1.743 | Val acc: 0.59\n",
      "Epoch:  114 | Train loss: 1.630 | Train acc: 0.69 | Val loss: 1.747 | Val acc: 0.57\n",
      "Epoch:  115 | Train loss: 1.619 | Train acc: 0.77 | Val loss: 1.744 | Val acc: 0.58\n",
      "Epoch:  116 | Train loss: 1.604 | Train acc: 0.72 | Val loss: 1.750 | Val acc: 0.57\n",
      "Epoch:  117 | Train loss: 1.618 | Train acc: 0.72 | Val loss: 1.747 | Val acc: 0.58\n",
      "Epoch:  118 | Train loss: 1.613 | Train acc: 0.71 | Val loss: 1.765 | Val acc: 0.51\n",
      "Epoch:  119 | Train loss: 1.594 | Train acc: 0.79 | Val loss: 1.751 | Val acc: 0.54\n",
      "Epoch:  120 | Train loss: 1.595 | Train acc: 0.75 | Val loss: 1.745 | Val acc: 0.59\n",
      "Epoch:  121 | Train loss: 1.596 | Train acc: 0.73 | Val loss: 1.735 | Val acc: 0.57\n",
      "Epoch:  122 | Train loss: 1.601 | Train acc: 0.74 | Val loss: 1.709 | Val acc: 0.63\n",
      "Epoch:  123 | Train loss: 1.595 | Train acc: 0.70 | Val loss: 1.732 | Val acc: 0.58\n",
      "Epoch:  124 | Train loss: 1.580 | Train acc: 0.78 | Val loss: 1.723 | Val acc: 0.62\n",
      "Epoch:  125 | Train loss: 1.585 | Train acc: 0.78 | Val loss: 1.718 | Val acc: 0.64\n",
      "Epoch:  126 | Train loss: 1.559 | Train acc: 0.74 | Val loss: 1.725 | Val acc: 0.58\n",
      "Epoch:  127 | Train loss: 1.561 | Train acc: 0.79 | Val loss: 1.705 | Val acc: 0.64\n",
      "Epoch:  128 | Train loss: 1.578 | Train acc: 0.78 | Val loss: 1.723 | Val acc: 0.59\n",
      "Epoch:  129 | Train loss: 1.549 | Train acc: 0.82 | Val loss: 1.707 | Val acc: 0.60\n",
      "Epoch:  130 | Train loss: 1.566 | Train acc: 0.75 | Val loss: 1.703 | Val acc: 0.63\n",
      "Epoch:  131 | Train loss: 1.530 | Train acc: 0.79 | Val loss: 1.697 | Val acc: 0.63\n",
      "Epoch:  132 | Train loss: 1.536 | Train acc: 0.77 | Val loss: 1.698 | Val acc: 0.63\n",
      "Epoch:  133 | Train loss: 1.535 | Train acc: 0.76 | Val loss: 1.703 | Val acc: 0.60\n",
      "Epoch:  134 | Train loss: 1.534 | Train acc: 0.81 | Val loss: 1.684 | Val acc: 0.64\n",
      "Epoch:  135 | Train loss: 1.535 | Train acc: 0.81 | Val loss: 1.692 | Val acc: 0.61\n",
      "Epoch:  136 | Train loss: 1.537 | Train acc: 0.77 | Val loss: 1.702 | Val acc: 0.60\n",
      "Epoch:  137 | Train loss: 1.527 | Train acc: 0.76 | Val loss: 1.697 | Val acc: 0.59\n",
      "Epoch:  138 | Train loss: 1.513 | Train acc: 0.82 | Val loss: 1.671 | Val acc: 0.64\n",
      "Epoch:  139 | Train loss: 1.519 | Train acc: 0.84 | Val loss: 1.690 | Val acc: 0.62\n",
      "Epoch:  140 | Train loss: 1.512 | Train acc: 0.72 | Val loss: 1.673 | Val acc: 0.63\n",
      "Epoch:  141 | Train loss: 1.501 | Train acc: 0.76 | Val loss: 1.683 | Val acc: 0.61\n",
      "Epoch:  142 | Train loss: 1.482 | Train acc: 0.85 | Val loss: 1.659 | Val acc: 0.65\n",
      "Epoch:  143 | Train loss: 1.531 | Train acc: 0.74 | Val loss: 1.680 | Val acc: 0.61\n",
      "Epoch:  144 | Train loss: 1.476 | Train acc: 0.79 | Val loss: 1.658 | Val acc: 0.65\n",
      "Epoch:  145 | Train loss: 1.495 | Train acc: 0.77 | Val loss: 1.660 | Val acc: 0.62\n",
      "Epoch:  146 | Train loss: 1.490 | Train acc: 0.77 | Val loss: 1.666 | Val acc: 0.68\n",
      "Epoch:  147 | Train loss: 1.489 | Train acc: 0.76 | Val loss: 1.643 | Val acc: 0.67\n",
      "Epoch:  148 | Train loss: 1.460 | Train acc: 0.78 | Val loss: 1.634 | Val acc: 0.64\n",
      "Epoch:  149 | Train loss: 1.483 | Train acc: 0.79 | Val loss: 1.664 | Val acc: 0.64\n",
      "Total training time: 1.75 seconds\n",
      "\n",
      "Test loss: 1.638  |  Test acc: 0.73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>training_acc</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▆▆▆▅▆▇▆▆▆█▇▆▇▇█▇▇██▇▇▇▇█</td></tr><tr><td>training_loss</td><td>█████▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▅▆▆▆▆▆▇▇▇▇▇█▇▇▇███</td></tr><tr><td>val_loss</td><td>██████▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>149</td></tr><tr><td>training_acc</td><td>0.79286</td></tr><tr><td>training_loss</td><td>1.48341</td></tr><tr><td>val_acc</td><td>0.644</td></tr><tr><td>val_loss</td><td>1.66401</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lucky-sweep-13</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/tct9l0ky' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/tct9l0ky</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234437-tct9l0ky/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q4uhy8r9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 150\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234458-q4uhy8r9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/q4uhy8r9' target=\"_blank\">iconic-sweep-14</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/q4uhy8r9' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/q4uhy8r9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.951 | Train acc: 0.14 | Val loss: 1.932 | Val acc: 0.20\n",
      "Epoch:    1 | Train loss: 1.389 | Train acc: 0.55 | Val loss: 1.563 | Val acc: 0.55\n",
      "Epoch:    2 | Train loss: 0.808 | Train acc: 0.76 | Val loss: 1.295 | Val acc: 0.54\n",
      "Epoch:    3 | Train loss: 0.528 | Train acc: 0.86 | Val loss: 0.988 | Val acc: 0.68\n",
      "Epoch:    4 | Train loss: 0.385 | Train acc: 0.89 | Val loss: 0.868 | Val acc: 0.72\n",
      "Epoch:    5 | Train loss: 0.199 | Train acc: 0.94 | Val loss: 0.979 | Val acc: 0.73\n",
      "Epoch:    6 | Train loss: 0.104 | Train acc: 0.96 | Val loss: 1.063 | Val acc: 0.72\n",
      "Epoch:    7 | Train loss: 0.169 | Train acc: 0.96 | Val loss: 1.129 | Val acc: 0.75\n",
      "Epoch:    8 | Train loss: 0.152 | Train acc: 0.94 | Val loss: 1.151 | Val acc: 0.74\n",
      "Epoch:    9 | Train loss: 0.123 | Train acc: 0.97 | Val loss: 1.411 | Val acc: 0.72\n",
      "Epoch:   10 | Train loss: 0.081 | Train acc: 0.99 | Val loss: 1.647 | Val acc: 0.71\n",
      "Epoch:   11 | Train loss: 0.113 | Train acc: 0.96 | Val loss: 1.570 | Val acc: 0.75\n",
      "Epoch:   12 | Train loss: 0.096 | Train acc: 0.97 | Val loss: 1.678 | Val acc: 0.73\n",
      "Epoch:   13 | Train loss: 0.107 | Train acc: 0.96 | Val loss: 1.933 | Val acc: 0.68\n",
      "Epoch:   14 | Train loss: 0.145 | Train acc: 0.96 | Val loss: 1.816 | Val acc: 0.74\n",
      "EARLY STOPPING condition met. Stopped at epoch: 14.\n",
      "Total training time: 0.15 seconds\n",
      "\n",
      "Test loss: 1.695  |  Test acc: 0.70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>training_acc</td><td>▁▄▆▇▇██████████</td></tr><tr><td>training_loss</td><td>█▆▄▃▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▅▇█████████▇█</td></tr><tr><td>val_loss</td><td>█▆▄▂▁▂▂▃▃▅▆▆▆█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>training_acc</td><td>0.96429</td></tr><tr><td>training_loss</td><td>0.14523</td></tr><tr><td>val_acc</td><td>0.744</td></tr><tr><td>val_loss</td><td>1.81637</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">iconic-sweep-14</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/q4uhy8r9' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/q4uhy8r9</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234458-q4uhy8r9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: args3shp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adadelta\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234523-args3shp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/args3shp' target=\"_blank\">kind-sweep-15</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/args3shp' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/args3shp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.939 | Train acc: 0.20 | Val loss: 1.956 | Val acc: 0.13\n",
      "Epoch:    1 | Train loss: 1.942 | Train acc: 0.16 | Val loss: 1.957 | Val acc: 0.12\n",
      "Epoch:    2 | Train loss: 1.936 | Train acc: 0.19 | Val loss: 1.953 | Val acc: 0.12\n",
      "Epoch:    3 | Train loss: 1.937 | Train acc: 0.17 | Val loss: 1.955 | Val acc: 0.11\n",
      "Epoch:    4 | Train loss: 1.935 | Train acc: 0.18 | Val loss: 1.956 | Val acc: 0.12\n",
      "Epoch:    5 | Train loss: 1.932 | Train acc: 0.19 | Val loss: 1.954 | Val acc: 0.14\n",
      "Epoch:    6 | Train loss: 1.935 | Train acc: 0.22 | Val loss: 1.954 | Val acc: 0.12\n",
      "Epoch:    7 | Train loss: 1.936 | Train acc: 0.12 | Val loss: 1.950 | Val acc: 0.14\n",
      "Epoch:    8 | Train loss: 1.932 | Train acc: 0.16 | Val loss: 1.950 | Val acc: 0.12\n",
      "Epoch:    9 | Train loss: 1.930 | Train acc: 0.23 | Val loss: 1.952 | Val acc: 0.13\n",
      "Epoch:   10 | Train loss: 1.924 | Train acc: 0.22 | Val loss: 1.947 | Val acc: 0.15\n",
      "Epoch:   11 | Train loss: 1.923 | Train acc: 0.21 | Val loss: 1.952 | Val acc: 0.14\n",
      "Epoch:   12 | Train loss: 1.921 | Train acc: 0.19 | Val loss: 1.949 | Val acc: 0.13\n",
      "Epoch:   13 | Train loss: 1.922 | Train acc: 0.19 | Val loss: 1.945 | Val acc: 0.15\n",
      "Epoch:   14 | Train loss: 1.919 | Train acc: 0.23 | Val loss: 1.948 | Val acc: 0.16\n",
      "Epoch:   15 | Train loss: 1.920 | Train acc: 0.21 | Val loss: 1.947 | Val acc: 0.17\n",
      "Epoch:   16 | Train loss: 1.910 | Train acc: 0.25 | Val loss: 1.944 | Val acc: 0.14\n",
      "Epoch:   17 | Train loss: 1.911 | Train acc: 0.27 | Val loss: 1.941 | Val acc: 0.17\n",
      "Epoch:   18 | Train loss: 1.911 | Train acc: 0.25 | Val loss: 1.946 | Val acc: 0.15\n",
      "Epoch:   19 | Train loss: 1.906 | Train acc: 0.27 | Val loss: 1.943 | Val acc: 0.16\n",
      "Epoch:   20 | Train loss: 1.904 | Train acc: 0.27 | Val loss: 1.944 | Val acc: 0.14\n",
      "Epoch:   21 | Train loss: 1.908 | Train acc: 0.24 | Val loss: 1.943 | Val acc: 0.19\n",
      "Epoch:   22 | Train loss: 1.898 | Train acc: 0.30 | Val loss: 1.941 | Val acc: 0.18\n",
      "Epoch:   23 | Train loss: 1.897 | Train acc: 0.31 | Val loss: 1.936 | Val acc: 0.18\n",
      "Epoch:   24 | Train loss: 1.902 | Train acc: 0.31 | Val loss: 1.939 | Val acc: 0.19\n",
      "Epoch:   25 | Train loss: 1.906 | Train acc: 0.27 | Val loss: 1.938 | Val acc: 0.17\n",
      "Epoch:   26 | Train loss: 1.899 | Train acc: 0.29 | Val loss: 1.934 | Val acc: 0.19\n",
      "Epoch:   27 | Train loss: 1.887 | Train acc: 0.34 | Val loss: 1.935 | Val acc: 0.20\n",
      "Epoch:   28 | Train loss: 1.883 | Train acc: 0.32 | Val loss: 1.933 | Val acc: 0.21\n",
      "Epoch:   29 | Train loss: 1.878 | Train acc: 0.34 | Val loss: 1.932 | Val acc: 0.20\n",
      "Epoch:   30 | Train loss: 1.892 | Train acc: 0.36 | Val loss: 1.933 | Val acc: 0.21\n",
      "Epoch:   31 | Train loss: 1.881 | Train acc: 0.32 | Val loss: 1.929 | Val acc: 0.21\n",
      "Epoch:   32 | Train loss: 1.881 | Train acc: 0.37 | Val loss: 1.933 | Val acc: 0.20\n",
      "Epoch:   33 | Train loss: 1.884 | Train acc: 0.34 | Val loss: 1.929 | Val acc: 0.19\n",
      "Epoch:   34 | Train loss: 1.887 | Train acc: 0.33 | Val loss: 1.927 | Val acc: 0.19\n",
      "Epoch:   35 | Train loss: 1.875 | Train acc: 0.36 | Val loss: 1.929 | Val acc: 0.23\n",
      "Epoch:   36 | Train loss: 1.872 | Train acc: 0.39 | Val loss: 1.928 | Val acc: 0.21\n",
      "Epoch:   37 | Train loss: 1.867 | Train acc: 0.36 | Val loss: 1.923 | Val acc: 0.22\n",
      "Epoch:   38 | Train loss: 1.859 | Train acc: 0.39 | Val loss: 1.916 | Val acc: 0.24\n",
      "Epoch:   39 | Train loss: 1.852 | Train acc: 0.43 | Val loss: 1.922 | Val acc: 0.21\n",
      "Epoch:   40 | Train loss: 1.860 | Train acc: 0.41 | Val loss: 1.915 | Val acc: 0.24\n",
      "Epoch:   41 | Train loss: 1.860 | Train acc: 0.41 | Val loss: 1.921 | Val acc: 0.23\n",
      "Epoch:   42 | Train loss: 1.855 | Train acc: 0.42 | Val loss: 1.922 | Val acc: 0.24\n",
      "Epoch:   43 | Train loss: 1.843 | Train acc: 0.48 | Val loss: 1.915 | Val acc: 0.26\n",
      "Epoch:   44 | Train loss: 1.846 | Train acc: 0.42 | Val loss: 1.922 | Val acc: 0.23\n",
      "Epoch:   45 | Train loss: 1.857 | Train acc: 0.42 | Val loss: 1.911 | Val acc: 0.25\n",
      "Epoch:   46 | Train loss: 1.843 | Train acc: 0.46 | Val loss: 1.910 | Val acc: 0.24\n",
      "Epoch:   47 | Train loss: 1.841 | Train acc: 0.50 | Val loss: 1.909 | Val acc: 0.26\n",
      "Epoch:   48 | Train loss: 1.834 | Train acc: 0.48 | Val loss: 1.906 | Val acc: 0.25\n",
      "Epoch:   49 | Train loss: 1.836 | Train acc: 0.44 | Val loss: 1.910 | Val acc: 0.28\n",
      "Epoch:   50 | Train loss: 1.843 | Train acc: 0.44 | Val loss: 1.907 | Val acc: 0.24\n",
      "Epoch:   51 | Train loss: 1.840 | Train acc: 0.49 | Val loss: 1.906 | Val acc: 0.25\n",
      "Epoch:   52 | Train loss: 1.831 | Train acc: 0.46 | Val loss: 1.897 | Val acc: 0.26\n",
      "Epoch:   53 | Train loss: 1.825 | Train acc: 0.49 | Val loss: 1.906 | Val acc: 0.26\n",
      "Epoch:   54 | Train loss: 1.824 | Train acc: 0.45 | Val loss: 1.899 | Val acc: 0.25\n",
      "Epoch:   55 | Train loss: 1.827 | Train acc: 0.45 | Val loss: 1.901 | Val acc: 0.26\n",
      "Epoch:   56 | Train loss: 1.816 | Train acc: 0.48 | Val loss: 1.904 | Val acc: 0.29\n",
      "Epoch:   57 | Train loss: 1.824 | Train acc: 0.51 | Val loss: 1.896 | Val acc: 0.28\n",
      "Epoch:   58 | Train loss: 1.808 | Train acc: 0.49 | Val loss: 1.893 | Val acc: 0.28\n",
      "Epoch:   59 | Train loss: 1.814 | Train acc: 0.52 | Val loss: 1.894 | Val acc: 0.28\n",
      "Epoch:   60 | Train loss: 1.818 | Train acc: 0.49 | Val loss: 1.893 | Val acc: 0.30\n",
      "Epoch:   61 | Train loss: 1.786 | Train acc: 0.52 | Val loss: 1.883 | Val acc: 0.30\n",
      "Epoch:   62 | Train loss: 1.797 | Train acc: 0.48 | Val loss: 1.887 | Val acc: 0.28\n",
      "Epoch:   63 | Train loss: 1.793 | Train acc: 0.50 | Val loss: 1.886 | Val acc: 0.30\n",
      "Epoch:   64 | Train loss: 1.806 | Train acc: 0.50 | Val loss: 1.886 | Val acc: 0.30\n",
      "Epoch:   65 | Train loss: 1.788 | Train acc: 0.52 | Val loss: 1.880 | Val acc: 0.32\n",
      "Epoch:   66 | Train loss: 1.794 | Train acc: 0.52 | Val loss: 1.881 | Val acc: 0.31\n",
      "Epoch:   67 | Train loss: 1.778 | Train acc: 0.55 | Val loss: 1.883 | Val acc: 0.28\n",
      "Epoch:   68 | Train loss: 1.783 | Train acc: 0.58 | Val loss: 1.874 | Val acc: 0.32\n",
      "Epoch:   69 | Train loss: 1.777 | Train acc: 0.54 | Val loss: 1.871 | Val acc: 0.33\n",
      "Epoch:   70 | Train loss: 1.781 | Train acc: 0.51 | Val loss: 1.875 | Val acc: 0.31\n",
      "Epoch:   71 | Train loss: 1.769 | Train acc: 0.56 | Val loss: 1.867 | Val acc: 0.30\n",
      "Epoch:   72 | Train loss: 1.762 | Train acc: 0.53 | Val loss: 1.869 | Val acc: 0.30\n",
      "Epoch:   73 | Train loss: 1.766 | Train acc: 0.55 | Val loss: 1.861 | Val acc: 0.30\n",
      "Epoch:   74 | Train loss: 1.766 | Train acc: 0.60 | Val loss: 1.863 | Val acc: 0.29\n",
      "Epoch:   75 | Train loss: 1.764 | Train acc: 0.56 | Val loss: 1.863 | Val acc: 0.32\n",
      "Epoch:   76 | Train loss: 1.767 | Train acc: 0.57 | Val loss: 1.869 | Val acc: 0.32\n",
      "Epoch:   77 | Train loss: 1.752 | Train acc: 0.56 | Val loss: 1.853 | Val acc: 0.33\n",
      "Epoch:   78 | Train loss: 1.748 | Train acc: 0.56 | Val loss: 1.854 | Val acc: 0.33\n",
      "Epoch:   79 | Train loss: 1.755 | Train acc: 0.59 | Val loss: 1.853 | Val acc: 0.34\n",
      "Epoch:   80 | Train loss: 1.750 | Train acc: 0.60 | Val loss: 1.861 | Val acc: 0.31\n",
      "Epoch:   81 | Train loss: 1.749 | Train acc: 0.58 | Val loss: 1.855 | Val acc: 0.32\n",
      "Epoch:   82 | Train loss: 1.720 | Train acc: 0.61 | Val loss: 1.845 | Val acc: 0.33\n",
      "Epoch:   83 | Train loss: 1.722 | Train acc: 0.57 | Val loss: 1.851 | Val acc: 0.33\n",
      "Epoch:   84 | Train loss: 1.731 | Train acc: 0.60 | Val loss: 1.848 | Val acc: 0.33\n",
      "Epoch:   85 | Train loss: 1.724 | Train acc: 0.58 | Val loss: 1.858 | Val acc: 0.34\n",
      "Epoch:   86 | Train loss: 1.739 | Train acc: 0.58 | Val loss: 1.847 | Val acc: 0.32\n",
      "Epoch:   87 | Train loss: 1.717 | Train acc: 0.59 | Val loss: 1.848 | Val acc: 0.32\n",
      "Epoch:   88 | Train loss: 1.736 | Train acc: 0.59 | Val loss: 1.847 | Val acc: 0.34\n",
      "Epoch:   89 | Train loss: 1.714 | Train acc: 0.62 | Val loss: 1.832 | Val acc: 0.34\n",
      "Epoch:   90 | Train loss: 1.718 | Train acc: 0.60 | Val loss: 1.840 | Val acc: 0.32\n",
      "Epoch:   91 | Train loss: 1.719 | Train acc: 0.56 | Val loss: 1.836 | Val acc: 0.35\n",
      "Epoch:   92 | Train loss: 1.699 | Train acc: 0.63 | Val loss: 1.824 | Val acc: 0.36\n",
      "Epoch:   93 | Train loss: 1.692 | Train acc: 0.65 | Val loss: 1.829 | Val acc: 0.36\n",
      "Epoch:   94 | Train loss: 1.687 | Train acc: 0.63 | Val loss: 1.835 | Val acc: 0.35\n",
      "Epoch:   95 | Train loss: 1.700 | Train acc: 0.61 | Val loss: 1.834 | Val acc: 0.34\n",
      "Epoch:   96 | Train loss: 1.669 | Train acc: 0.66 | Val loss: 1.817 | Val acc: 0.37\n",
      "Epoch:   97 | Train loss: 1.697 | Train acc: 0.59 | Val loss: 1.815 | Val acc: 0.34\n",
      "Epoch:   98 | Train loss: 1.689 | Train acc: 0.61 | Val loss: 1.819 | Val acc: 0.37\n",
      "Epoch:   99 | Train loss: 1.680 | Train acc: 0.65 | Val loss: 1.814 | Val acc: 0.37\n",
      "Epoch:  100 | Train loss: 1.665 | Train acc: 0.61 | Val loss: 1.811 | Val acc: 0.38\n",
      "Epoch:  101 | Train loss: 1.672 | Train acc: 0.66 | Val loss: 1.809 | Val acc: 0.37\n",
      "Epoch:  102 | Train loss: 1.674 | Train acc: 0.60 | Val loss: 1.822 | Val acc: 0.36\n",
      "Epoch:  103 | Train loss: 1.678 | Train acc: 0.58 | Val loss: 1.824 | Val acc: 0.35\n",
      "Epoch:  104 | Train loss: 1.663 | Train acc: 0.64 | Val loss: 1.803 | Val acc: 0.35\n",
      "Epoch:  105 | Train loss: 1.672 | Train acc: 0.66 | Val loss: 1.802 | Val acc: 0.38\n",
      "Epoch:  106 | Train loss: 1.656 | Train acc: 0.65 | Val loss: 1.805 | Val acc: 0.39\n",
      "Epoch:  107 | Train loss: 1.646 | Train acc: 0.65 | Val loss: 1.808 | Val acc: 0.38\n",
      "Epoch:  108 | Train loss: 1.646 | Train acc: 0.66 | Val loss: 1.796 | Val acc: 0.38\n",
      "Epoch:  109 | Train loss: 1.652 | Train acc: 0.64 | Val loss: 1.803 | Val acc: 0.38\n",
      "Epoch:  110 | Train loss: 1.648 | Train acc: 0.66 | Val loss: 1.796 | Val acc: 0.38\n",
      "Epoch:  111 | Train loss: 1.651 | Train acc: 0.64 | Val loss: 1.805 | Val acc: 0.38\n",
      "Epoch:  112 | Train loss: 1.654 | Train acc: 0.66 | Val loss: 1.798 | Val acc: 0.38\n",
      "Epoch:  113 | Train loss: 1.620 | Train acc: 0.67 | Val loss: 1.791 | Val acc: 0.39\n",
      "Epoch:  114 | Train loss: 1.632 | Train acc: 0.70 | Val loss: 1.777 | Val acc: 0.39\n",
      "Epoch:  115 | Train loss: 1.613 | Train acc: 0.69 | Val loss: 1.768 | Val acc: 0.41\n",
      "Epoch:  116 | Train loss: 1.605 | Train acc: 0.71 | Val loss: 1.770 | Val acc: 0.38\n",
      "Epoch:  117 | Train loss: 1.601 | Train acc: 0.71 | Val loss: 1.780 | Val acc: 0.39\n",
      "Epoch:  118 | Train loss: 1.613 | Train acc: 0.68 | Val loss: 1.772 | Val acc: 0.39\n",
      "Epoch:  119 | Train loss: 1.613 | Train acc: 0.73 | Val loss: 1.776 | Val acc: 0.40\n",
      "Epoch:  120 | Train loss: 1.604 | Train acc: 0.71 | Val loss: 1.771 | Val acc: 0.42\n",
      "Epoch:  121 | Train loss: 1.610 | Train acc: 0.74 | Val loss: 1.770 | Val acc: 0.42\n",
      "Epoch:  122 | Train loss: 1.593 | Train acc: 0.69 | Val loss: 1.759 | Val acc: 0.44\n",
      "Epoch:  123 | Train loss: 1.618 | Train acc: 0.67 | Val loss: 1.777 | Val acc: 0.41\n",
      "Epoch:  124 | Train loss: 1.573 | Train acc: 0.69 | Val loss: 1.760 | Val acc: 0.42\n",
      "Epoch:  125 | Train loss: 1.586 | Train acc: 0.66 | Val loss: 1.756 | Val acc: 0.41\n",
      "Epoch:  126 | Train loss: 1.592 | Train acc: 0.71 | Val loss: 1.761 | Val acc: 0.45\n",
      "Epoch:  127 | Train loss: 1.593 | Train acc: 0.64 | Val loss: 1.760 | Val acc: 0.43\n",
      "Epoch:  128 | Train loss: 1.591 | Train acc: 0.72 | Val loss: 1.760 | Val acc: 0.42\n",
      "Epoch:  129 | Train loss: 1.565 | Train acc: 0.67 | Val loss: 1.749 | Val acc: 0.40\n",
      "Epoch:  130 | Train loss: 1.570 | Train acc: 0.68 | Val loss: 1.746 | Val acc: 0.42\n",
      "Epoch:  131 | Train loss: 1.571 | Train acc: 0.67 | Val loss: 1.755 | Val acc: 0.40\n",
      "Epoch:  132 | Train loss: 1.552 | Train acc: 0.72 | Val loss: 1.748 | Val acc: 0.42\n",
      "Epoch:  133 | Train loss: 1.559 | Train acc: 0.76 | Val loss: 1.755 | Val acc: 0.43\n",
      "Epoch:  134 | Train loss: 1.573 | Train acc: 0.69 | Val loss: 1.733 | Val acc: 0.43\n",
      "Epoch:  135 | Train loss: 1.559 | Train acc: 0.75 | Val loss: 1.746 | Val acc: 0.41\n",
      "Epoch:  136 | Train loss: 1.535 | Train acc: 0.74 | Val loss: 1.727 | Val acc: 0.47\n",
      "Epoch:  137 | Train loss: 1.569 | Train acc: 0.71 | Val loss: 1.736 | Val acc: 0.43\n",
      "Epoch:  138 | Train loss: 1.542 | Train acc: 0.70 | Val loss: 1.735 | Val acc: 0.42\n",
      "Epoch:  139 | Train loss: 1.571 | Train acc: 0.71 | Val loss: 1.736 | Val acc: 0.45\n",
      "Epoch:  140 | Train loss: 1.545 | Train acc: 0.74 | Val loss: 1.737 | Val acc: 0.44\n",
      "Epoch:  141 | Train loss: 1.526 | Train acc: 0.73 | Val loss: 1.720 | Val acc: 0.44\n",
      "Epoch:  142 | Train loss: 1.524 | Train acc: 0.72 | Val loss: 1.729 | Val acc: 0.44\n",
      "Epoch:  143 | Train loss: 1.529 | Train acc: 0.68 | Val loss: 1.725 | Val acc: 0.48\n",
      "Epoch:  144 | Train loss: 1.517 | Train acc: 0.74 | Val loss: 1.711 | Val acc: 0.47\n",
      "Epoch:  145 | Train loss: 1.507 | Train acc: 0.76 | Val loss: 1.736 | Val acc: 0.47\n",
      "Epoch:  146 | Train loss: 1.522 | Train acc: 0.75 | Val loss: 1.717 | Val acc: 0.49\n",
      "Epoch:  147 | Train loss: 1.513 | Train acc: 0.73 | Val loss: 1.721 | Val acc: 0.45\n",
      "Epoch:  148 | Train loss: 1.497 | Train acc: 0.76 | Val loss: 1.714 | Val acc: 0.46\n",
      "Epoch:  149 | Train loss: 1.523 | Train acc: 0.74 | Val loss: 1.712 | Val acc: 0.48\n",
      "Epoch:  150 | Train loss: 1.512 | Train acc: 0.73 | Val loss: 1.697 | Val acc: 0.48\n",
      "Epoch:  151 | Train loss: 1.503 | Train acc: 0.74 | Val loss: 1.698 | Val acc: 0.49\n",
      "Epoch:  152 | Train loss: 1.471 | Train acc: 0.77 | Val loss: 1.702 | Val acc: 0.47\n",
      "Epoch:  153 | Train loss: 1.507 | Train acc: 0.71 | Val loss: 1.709 | Val acc: 0.47\n",
      "Epoch:  154 | Train loss: 1.492 | Train acc: 0.76 | Val loss: 1.699 | Val acc: 0.46\n",
      "Epoch:  155 | Train loss: 1.469 | Train acc: 0.76 | Val loss: 1.685 | Val acc: 0.48\n",
      "Epoch:  156 | Train loss: 1.452 | Train acc: 0.76 | Val loss: 1.689 | Val acc: 0.50\n",
      "Epoch:  157 | Train loss: 1.451 | Train acc: 0.78 | Val loss: 1.674 | Val acc: 0.50\n",
      "Epoch:  158 | Train loss: 1.474 | Train acc: 0.74 | Val loss: 1.693 | Val acc: 0.48\n",
      "Epoch:  159 | Train loss: 1.455 | Train acc: 0.79 | Val loss: 1.677 | Val acc: 0.50\n",
      "Epoch:  160 | Train loss: 1.435 | Train acc: 0.77 | Val loss: 1.664 | Val acc: 0.52\n",
      "Epoch:  161 | Train loss: 1.444 | Train acc: 0.77 | Val loss: 1.691 | Val acc: 0.51\n",
      "Epoch:  162 | Train loss: 1.410 | Train acc: 0.79 | Val loss: 1.664 | Val acc: 0.53\n",
      "Epoch:  163 | Train loss: 1.455 | Train acc: 0.79 | Val loss: 1.673 | Val acc: 0.50\n",
      "Epoch:  164 | Train loss: 1.446 | Train acc: 0.78 | Val loss: 1.665 | Val acc: 0.51\n",
      "Epoch:  165 | Train loss: 1.438 | Train acc: 0.76 | Val loss: 1.652 | Val acc: 0.53\n",
      "Epoch:  166 | Train loss: 1.461 | Train acc: 0.77 | Val loss: 1.674 | Val acc: 0.51\n",
      "Epoch:  167 | Train loss: 1.428 | Train acc: 0.78 | Val loss: 1.649 | Val acc: 0.54\n",
      "Epoch:  168 | Train loss: 1.420 | Train acc: 0.83 | Val loss: 1.667 | Val acc: 0.52\n",
      "Epoch:  169 | Train loss: 1.438 | Train acc: 0.79 | Val loss: 1.660 | Val acc: 0.52\n",
      "Epoch:  170 | Train loss: 1.440 | Train acc: 0.78 | Val loss: 1.651 | Val acc: 0.53\n",
      "Epoch:  171 | Train loss: 1.433 | Train acc: 0.81 | Val loss: 1.668 | Val acc: 0.50\n",
      "Epoch:  172 | Train loss: 1.420 | Train acc: 0.79 | Val loss: 1.652 | Val acc: 0.56\n",
      "Epoch:  173 | Train loss: 1.390 | Train acc: 0.84 | Val loss: 1.630 | Val acc: 0.53\n",
      "Epoch:  174 | Train loss: 1.415 | Train acc: 0.76 | Val loss: 1.648 | Val acc: 0.53\n",
      "Epoch:  175 | Train loss: 1.404 | Train acc: 0.81 | Val loss: 1.628 | Val acc: 0.59\n",
      "Epoch:  176 | Train loss: 1.386 | Train acc: 0.80 | Val loss: 1.648 | Val acc: 0.55\n",
      "Epoch:  177 | Train loss: 1.401 | Train acc: 0.82 | Val loss: 1.633 | Val acc: 0.53\n",
      "Epoch:  178 | Train loss: 1.383 | Train acc: 0.81 | Val loss: 1.634 | Val acc: 0.53\n",
      "Epoch:  179 | Train loss: 1.413 | Train acc: 0.77 | Val loss: 1.629 | Val acc: 0.53\n",
      "Epoch:  180 | Train loss: 1.362 | Train acc: 0.78 | Val loss: 1.610 | Val acc: 0.58\n",
      "Epoch:  181 | Train loss: 1.381 | Train acc: 0.79 | Val loss: 1.621 | Val acc: 0.57\n",
      "Epoch:  182 | Train loss: 1.373 | Train acc: 0.81 | Val loss: 1.627 | Val acc: 0.56\n",
      "Epoch:  183 | Train loss: 1.361 | Train acc: 0.84 | Val loss: 1.626 | Val acc: 0.57\n",
      "Epoch:  184 | Train loss: 1.382 | Train acc: 0.84 | Val loss: 1.627 | Val acc: 0.54\n",
      "Epoch:  185 | Train loss: 1.335 | Train acc: 0.79 | Val loss: 1.627 | Val acc: 0.55\n",
      "Epoch:  186 | Train loss: 1.348 | Train acc: 0.79 | Val loss: 1.612 | Val acc: 0.58\n",
      "Epoch:  187 | Train loss: 1.359 | Train acc: 0.79 | Val loss: 1.615 | Val acc: 0.54\n",
      "Epoch:  188 | Train loss: 1.339 | Train acc: 0.76 | Val loss: 1.604 | Val acc: 0.59\n",
      "Epoch:  189 | Train loss: 1.319 | Train acc: 0.80 | Val loss: 1.599 | Val acc: 0.56\n",
      "Epoch:  190 | Train loss: 1.332 | Train acc: 0.81 | Val loss: 1.589 | Val acc: 0.59\n",
      "Epoch:  191 | Train loss: 1.325 | Train acc: 0.79 | Val loss: 1.591 | Val acc: 0.56\n",
      "Epoch:  192 | Train loss: 1.328 | Train acc: 0.82 | Val loss: 1.590 | Val acc: 0.58\n",
      "Epoch:  193 | Train loss: 1.318 | Train acc: 0.81 | Val loss: 1.566 | Val acc: 0.62\n",
      "Epoch:  194 | Train loss: 1.320 | Train acc: 0.84 | Val loss: 1.586 | Val acc: 0.63\n",
      "Epoch:  195 | Train loss: 1.307 | Train acc: 0.79 | Val loss: 1.582 | Val acc: 0.57\n",
      "Epoch:  196 | Train loss: 1.304 | Train acc: 0.84 | Val loss: 1.589 | Val acc: 0.55\n",
      "Epoch:  197 | Train loss: 1.284 | Train acc: 0.82 | Val loss: 1.564 | Val acc: 0.60\n",
      "Epoch:  198 | Train loss: 1.292 | Train acc: 0.84 | Val loss: 1.556 | Val acc: 0.61\n",
      "Epoch:  199 | Train loss: 1.317 | Train acc: 0.86 | Val loss: 1.589 | Val acc: 0.58\n",
      "Total training time: 2.36 seconds\n",
      "\n",
      "Test loss: 1.564  |  Test acc: 0.66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_acc</td><td>▁▁▁▁▂▂▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▆▇▇▆▇▇▇▇▇███▇▇█</td></tr><tr><td>training_loss</td><td>██████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█▇</td></tr><tr><td>val_loss</td><td>██████▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▂▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>training_acc</td><td>0.86429</td></tr><tr><td>training_loss</td><td>1.31705</td></tr><tr><td>val_acc</td><td>0.582</td></tr><tr><td>val_loss</td><td>1.58869</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">kind-sweep-15</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/args3shp' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/args3shp</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234523-args3shp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lsns8dml with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochh: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlrval: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizerval: Adadelta\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/vg2507/DL/pytorch-GCN/src/wandb/run-20240513_234542-lsns8dml</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/lsns8dml' target=\"_blank\">polished-sweep-16</a></strong> to <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/sweeps/xnresywg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/lsns8dml' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/lsns8dml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | Train loss: 1.935 | Train acc: 0.16 | Val loss: 1.952 | Val acc: 0.13\n",
      "Epoch:    1 | Train loss: 1.940 | Train acc: 0.14 | Val loss: 1.952 | Val acc: 0.15\n",
      "Epoch:    2 | Train loss: 1.931 | Train acc: 0.16 | Val loss: 1.948 | Val acc: 0.13\n",
      "Epoch:    3 | Train loss: 1.932 | Train acc: 0.18 | Val loss: 1.945 | Val acc: 0.14\n",
      "Epoch:    4 | Train loss: 1.924 | Train acc: 0.20 | Val loss: 1.945 | Val acc: 0.15\n",
      "Epoch:    5 | Train loss: 1.928 | Train acc: 0.18 | Val loss: 1.948 | Val acc: 0.14\n",
      "Epoch:    6 | Train loss: 1.919 | Train acc: 0.23 | Val loss: 1.944 | Val acc: 0.15\n",
      "Epoch:    7 | Train loss: 1.925 | Train acc: 0.21 | Val loss: 1.942 | Val acc: 0.15\n",
      "Epoch:    8 | Train loss: 1.916 | Train acc: 0.26 | Val loss: 1.943 | Val acc: 0.14\n",
      "Epoch:    9 | Train loss: 1.921 | Train acc: 0.19 | Val loss: 1.942 | Val acc: 0.13\n",
      "Epoch:   10 | Train loss: 1.915 | Train acc: 0.23 | Val loss: 1.943 | Val acc: 0.16\n",
      "Epoch:   11 | Train loss: 1.914 | Train acc: 0.24 | Val loss: 1.939 | Val acc: 0.15\n",
      "Epoch:   12 | Train loss: 1.909 | Train acc: 0.24 | Val loss: 1.937 | Val acc: 0.17\n",
      "Epoch:   13 | Train loss: 1.913 | Train acc: 0.23 | Val loss: 1.937 | Val acc: 0.15\n",
      "Epoch:   14 | Train loss: 1.909 | Train acc: 0.24 | Val loss: 1.935 | Val acc: 0.17\n",
      "Epoch:   15 | Train loss: 1.902 | Train acc: 0.27 | Val loss: 1.930 | Val acc: 0.18\n",
      "Epoch:   16 | Train loss: 1.896 | Train acc: 0.27 | Val loss: 1.932 | Val acc: 0.19\n",
      "Epoch:   17 | Train loss: 1.895 | Train acc: 0.27 | Val loss: 1.929 | Val acc: 0.17\n",
      "Epoch:   18 | Train loss: 1.893 | Train acc: 0.32 | Val loss: 1.926 | Val acc: 0.19\n",
      "Epoch:   19 | Train loss: 1.896 | Train acc: 0.29 | Val loss: 1.930 | Val acc: 0.20\n",
      "Epoch:   20 | Train loss: 1.891 | Train acc: 0.31 | Val loss: 1.931 | Val acc: 0.18\n",
      "Epoch:   21 | Train loss: 1.884 | Train acc: 0.29 | Val loss: 1.926 | Val acc: 0.18\n",
      "Epoch:   22 | Train loss: 1.884 | Train acc: 0.32 | Val loss: 1.924 | Val acc: 0.19\n",
      "Epoch:   23 | Train loss: 1.880 | Train acc: 0.31 | Val loss: 1.919 | Val acc: 0.21\n",
      "Epoch:   24 | Train loss: 1.876 | Train acc: 0.33 | Val loss: 1.922 | Val acc: 0.16\n",
      "Epoch:   25 | Train loss: 1.873 | Train acc: 0.32 | Val loss: 1.921 | Val acc: 0.21\n",
      "Epoch:   26 | Train loss: 1.872 | Train acc: 0.28 | Val loss: 1.918 | Val acc: 0.18\n",
      "Epoch:   27 | Train loss: 1.870 | Train acc: 0.29 | Val loss: 1.917 | Val acc: 0.19\n",
      "Epoch:   28 | Train loss: 1.870 | Train acc: 0.32 | Val loss: 1.921 | Val acc: 0.19\n",
      "Epoch:   29 | Train loss: 1.870 | Train acc: 0.34 | Val loss: 1.921 | Val acc: 0.20\n",
      "Epoch:   30 | Train loss: 1.859 | Train acc: 0.32 | Val loss: 1.907 | Val acc: 0.21\n",
      "Epoch:   31 | Train loss: 1.862 | Train acc: 0.34 | Val loss: 1.914 | Val acc: 0.21\n",
      "Epoch:   32 | Train loss: 1.860 | Train acc: 0.31 | Val loss: 1.911 | Val acc: 0.20\n",
      "Epoch:   33 | Train loss: 1.849 | Train acc: 0.32 | Val loss: 1.902 | Val acc: 0.22\n",
      "Epoch:   34 | Train loss: 1.846 | Train acc: 0.36 | Val loss: 1.905 | Val acc: 0.24\n",
      "Epoch:   35 | Train loss: 1.850 | Train acc: 0.34 | Val loss: 1.908 | Val acc: 0.20\n",
      "Epoch:   36 | Train loss: 1.837 | Train acc: 0.36 | Val loss: 1.897 | Val acc: 0.23\n",
      "Epoch:   37 | Train loss: 1.844 | Train acc: 0.34 | Val loss: 1.906 | Val acc: 0.21\n",
      "Epoch:   38 | Train loss: 1.829 | Train acc: 0.37 | Val loss: 1.899 | Val acc: 0.22\n",
      "Epoch:   39 | Train loss: 1.834 | Train acc: 0.39 | Val loss: 1.901 | Val acc: 0.23\n",
      "Epoch:   40 | Train loss: 1.825 | Train acc: 0.30 | Val loss: 1.898 | Val acc: 0.21\n",
      "Epoch:   41 | Train loss: 1.822 | Train acc: 0.37 | Val loss: 1.891 | Val acc: 0.21\n",
      "Epoch:   42 | Train loss: 1.824 | Train acc: 0.36 | Val loss: 1.888 | Val acc: 0.25\n",
      "Epoch:   43 | Train loss: 1.830 | Train acc: 0.35 | Val loss: 1.894 | Val acc: 0.20\n",
      "Epoch:   44 | Train loss: 1.814 | Train acc: 0.34 | Val loss: 1.893 | Val acc: 0.20\n",
      "Epoch:   45 | Train loss: 1.818 | Train acc: 0.40 | Val loss: 1.892 | Val acc: 0.23\n",
      "Epoch:   46 | Train loss: 1.816 | Train acc: 0.42 | Val loss: 1.883 | Val acc: 0.24\n",
      "Epoch:   47 | Train loss: 1.808 | Train acc: 0.38 | Val loss: 1.886 | Val acc: 0.24\n",
      "Epoch:   48 | Train loss: 1.802 | Train acc: 0.41 | Val loss: 1.875 | Val acc: 0.27\n",
      "Epoch:   49 | Train loss: 1.807 | Train acc: 0.39 | Val loss: 1.885 | Val acc: 0.23\n",
      "Epoch:   50 | Train loss: 1.802 | Train acc: 0.39 | Val loss: 1.887 | Val acc: 0.23\n",
      "Epoch:   51 | Train loss: 1.797 | Train acc: 0.40 | Val loss: 1.883 | Val acc: 0.22\n",
      "Epoch:   52 | Train loss: 1.796 | Train acc: 0.44 | Val loss: 1.882 | Val acc: 0.24\n",
      "Epoch:   53 | Train loss: 1.787 | Train acc: 0.44 | Val loss: 1.874 | Val acc: 0.27\n",
      "Epoch:   54 | Train loss: 1.764 | Train acc: 0.44 | Val loss: 1.866 | Val acc: 0.25\n",
      "Epoch:   55 | Train loss: 1.776 | Train acc: 0.41 | Val loss: 1.864 | Val acc: 0.27\n",
      "Epoch:   56 | Train loss: 1.781 | Train acc: 0.43 | Val loss: 1.867 | Val acc: 0.26\n",
      "Epoch:   57 | Train loss: 1.766 | Train acc: 0.48 | Val loss: 1.859 | Val acc: 0.28\n",
      "Epoch:   58 | Train loss: 1.782 | Train acc: 0.40 | Val loss: 1.870 | Val acc: 0.23\n",
      "Epoch:   59 | Train loss: 1.767 | Train acc: 0.42 | Val loss: 1.859 | Val acc: 0.26\n",
      "Epoch:   60 | Train loss: 1.757 | Train acc: 0.44 | Val loss: 1.858 | Val acc: 0.27\n",
      "Epoch:   61 | Train loss: 1.762 | Train acc: 0.42 | Val loss: 1.862 | Val acc: 0.27\n",
      "Epoch:   62 | Train loss: 1.760 | Train acc: 0.45 | Val loss: 1.865 | Val acc: 0.24\n",
      "Epoch:   63 | Train loss: 1.759 | Train acc: 0.42 | Val loss: 1.850 | Val acc: 0.26\n",
      "Epoch:   64 | Train loss: 1.754 | Train acc: 0.40 | Val loss: 1.857 | Val acc: 0.29\n",
      "Epoch:   65 | Train loss: 1.745 | Train acc: 0.46 | Val loss: 1.861 | Val acc: 0.27\n",
      "Epoch:   66 | Train loss: 1.756 | Train acc: 0.43 | Val loss: 1.859 | Val acc: 0.24\n",
      "Epoch:   67 | Train loss: 1.719 | Train acc: 0.56 | Val loss: 1.848 | Val acc: 0.31\n",
      "Epoch:   68 | Train loss: 1.738 | Train acc: 0.44 | Val loss: 1.851 | Val acc: 0.24\n",
      "Epoch:   69 | Train loss: 1.723 | Train acc: 0.46 | Val loss: 1.839 | Val acc: 0.28\n",
      "Epoch:   70 | Train loss: 1.719 | Train acc: 0.46 | Val loss: 1.850 | Val acc: 0.27\n",
      "Epoch:   71 | Train loss: 1.719 | Train acc: 0.47 | Val loss: 1.844 | Val acc: 0.28\n",
      "Epoch:   72 | Train loss: 1.728 | Train acc: 0.55 | Val loss: 1.835 | Val acc: 0.31\n",
      "Epoch:   73 | Train loss: 1.711 | Train acc: 0.53 | Val loss: 1.825 | Val acc: 0.33\n",
      "Epoch:   74 | Train loss: 1.722 | Train acc: 0.46 | Val loss: 1.831 | Val acc: 0.31\n",
      "Epoch:   75 | Train loss: 1.698 | Train acc: 0.52 | Val loss: 1.837 | Val acc: 0.32\n",
      "Epoch:   76 | Train loss: 1.697 | Train acc: 0.54 | Val loss: 1.835 | Val acc: 0.29\n",
      "Epoch:   77 | Train loss: 1.715 | Train acc: 0.52 | Val loss: 1.840 | Val acc: 0.30\n",
      "Epoch:   78 | Train loss: 1.702 | Train acc: 0.54 | Val loss: 1.824 | Val acc: 0.33\n",
      "Epoch:   79 | Train loss: 1.697 | Train acc: 0.47 | Val loss: 1.827 | Val acc: 0.33\n",
      "Epoch:   80 | Train loss: 1.700 | Train acc: 0.56 | Val loss: 1.820 | Val acc: 0.34\n",
      "Epoch:   81 | Train loss: 1.698 | Train acc: 0.57 | Val loss: 1.829 | Val acc: 0.34\n",
      "Epoch:   82 | Train loss: 1.670 | Train acc: 0.56 | Val loss: 1.814 | Val acc: 0.33\n",
      "Epoch:   83 | Train loss: 1.679 | Train acc: 0.52 | Val loss: 1.816 | Val acc: 0.32\n",
      "Epoch:   84 | Train loss: 1.661 | Train acc: 0.54 | Val loss: 1.811 | Val acc: 0.34\n",
      "Epoch:   85 | Train loss: 1.670 | Train acc: 0.55 | Val loss: 1.807 | Val acc: 0.35\n",
      "Epoch:   86 | Train loss: 1.672 | Train acc: 0.56 | Val loss: 1.805 | Val acc: 0.33\n",
      "Epoch:   87 | Train loss: 1.675 | Train acc: 0.54 | Val loss: 1.815 | Val acc: 0.34\n",
      "Epoch:   88 | Train loss: 1.663 | Train acc: 0.57 | Val loss: 1.811 | Val acc: 0.36\n",
      "Epoch:   89 | Train loss: 1.648 | Train acc: 0.59 | Val loss: 1.797 | Val acc: 0.36\n",
      "Epoch:   90 | Train loss: 1.649 | Train acc: 0.59 | Val loss: 1.804 | Val acc: 0.38\n",
      "Epoch:   91 | Train loss: 1.641 | Train acc: 0.53 | Val loss: 1.804 | Val acc: 0.35\n",
      "Epoch:   92 | Train loss: 1.640 | Train acc: 0.59 | Val loss: 1.801 | Val acc: 0.36\n",
      "Epoch:   93 | Train loss: 1.635 | Train acc: 0.60 | Val loss: 1.789 | Val acc: 0.40\n",
      "Epoch:   94 | Train loss: 1.647 | Train acc: 0.59 | Val loss: 1.796 | Val acc: 0.36\n",
      "Epoch:   95 | Train loss: 1.639 | Train acc: 0.56 | Val loss: 1.792 | Val acc: 0.37\n",
      "Epoch:   96 | Train loss: 1.616 | Train acc: 0.60 | Val loss: 1.781 | Val acc: 0.39\n",
      "Epoch:   97 | Train loss: 1.623 | Train acc: 0.59 | Val loss: 1.787 | Val acc: 0.34\n",
      "Epoch:   98 | Train loss: 1.611 | Train acc: 0.58 | Val loss: 1.781 | Val acc: 0.39\n",
      "Epoch:   99 | Train loss: 1.627 | Train acc: 0.58 | Val loss: 1.784 | Val acc: 0.40\n",
      "Epoch:  100 | Train loss: 1.611 | Train acc: 0.59 | Val loss: 1.778 | Val acc: 0.40\n",
      "Epoch:  101 | Train loss: 1.618 | Train acc: 0.65 | Val loss: 1.778 | Val acc: 0.41\n",
      "Epoch:  102 | Train loss: 1.592 | Train acc: 0.61 | Val loss: 1.768 | Val acc: 0.40\n",
      "Epoch:  103 | Train loss: 1.599 | Train acc: 0.60 | Val loss: 1.770 | Val acc: 0.39\n",
      "Epoch:  104 | Train loss: 1.603 | Train acc: 0.68 | Val loss: 1.770 | Val acc: 0.44\n",
      "Epoch:  105 | Train loss: 1.570 | Train acc: 0.71 | Val loss: 1.753 | Val acc: 0.44\n",
      "Epoch:  106 | Train loss: 1.600 | Train acc: 0.62 | Val loss: 1.774 | Val acc: 0.38\n",
      "Epoch:  107 | Train loss: 1.578 | Train acc: 0.71 | Val loss: 1.745 | Val acc: 0.43\n",
      "Epoch:  108 | Train loss: 1.565 | Train acc: 0.66 | Val loss: 1.753 | Val acc: 0.42\n",
      "Epoch:  109 | Train loss: 1.594 | Train acc: 0.64 | Val loss: 1.765 | Val acc: 0.38\n",
      "Epoch:  110 | Train loss: 1.563 | Train acc: 0.69 | Val loss: 1.749 | Val acc: 0.43\n",
      "Epoch:  111 | Train loss: 1.558 | Train acc: 0.64 | Val loss: 1.745 | Val acc: 0.41\n",
      "Epoch:  112 | Train loss: 1.576 | Train acc: 0.64 | Val loss: 1.749 | Val acc: 0.41\n",
      "Epoch:  113 | Train loss: 1.557 | Train acc: 0.65 | Val loss: 1.741 | Val acc: 0.46\n",
      "Epoch:  114 | Train loss: 1.567 | Train acc: 0.70 | Val loss: 1.739 | Val acc: 0.45\n",
      "Epoch:  115 | Train loss: 1.552 | Train acc: 0.70 | Val loss: 1.717 | Val acc: 0.49\n",
      "Epoch:  116 | Train loss: 1.550 | Train acc: 0.68 | Val loss: 1.734 | Val acc: 0.44\n",
      "Epoch:  117 | Train loss: 1.551 | Train acc: 0.69 | Val loss: 1.731 | Val acc: 0.42\n",
      "Epoch:  118 | Train loss: 1.545 | Train acc: 0.66 | Val loss: 1.741 | Val acc: 0.43\n",
      "Epoch:  119 | Train loss: 1.530 | Train acc: 0.74 | Val loss: 1.725 | Val acc: 0.47\n",
      "Epoch:  120 | Train loss: 1.547 | Train acc: 0.74 | Val loss: 1.731 | Val acc: 0.44\n",
      "Epoch:  121 | Train loss: 1.533 | Train acc: 0.72 | Val loss: 1.733 | Val acc: 0.44\n",
      "Epoch:  122 | Train loss: 1.530 | Train acc: 0.74 | Val loss: 1.728 | Val acc: 0.50\n",
      "Epoch:  123 | Train loss: 1.504 | Train acc: 0.75 | Val loss: 1.709 | Val acc: 0.48\n",
      "Epoch:  124 | Train loss: 1.517 | Train acc: 0.71 | Val loss: 1.695 | Val acc: 0.49\n",
      "Epoch:  125 | Train loss: 1.504 | Train acc: 0.74 | Val loss: 1.722 | Val acc: 0.45\n",
      "Epoch:  126 | Train loss: 1.501 | Train acc: 0.75 | Val loss: 1.713 | Val acc: 0.46\n",
      "Epoch:  127 | Train loss: 1.506 | Train acc: 0.68 | Val loss: 1.708 | Val acc: 0.47\n",
      "Epoch:  128 | Train loss: 1.522 | Train acc: 0.67 | Val loss: 1.691 | Val acc: 0.51\n",
      "Epoch:  129 | Train loss: 1.524 | Train acc: 0.74 | Val loss: 1.707 | Val acc: 0.50\n",
      "Epoch:  130 | Train loss: 1.502 | Train acc: 0.74 | Val loss: 1.702 | Val acc: 0.51\n",
      "Epoch:  131 | Train loss: 1.498 | Train acc: 0.68 | Val loss: 1.714 | Val acc: 0.49\n",
      "Epoch:  132 | Train loss: 1.516 | Train acc: 0.71 | Val loss: 1.706 | Val acc: 0.47\n",
      "Epoch:  133 | Train loss: 1.490 | Train acc: 0.72 | Val loss: 1.703 | Val acc: 0.48\n",
      "Epoch:  134 | Train loss: 1.500 | Train acc: 0.73 | Val loss: 1.699 | Val acc: 0.51\n",
      "Epoch:  135 | Train loss: 1.491 | Train acc: 0.74 | Val loss: 1.698 | Val acc: 0.49\n",
      "Epoch:  136 | Train loss: 1.470 | Train acc: 0.73 | Val loss: 1.676 | Val acc: 0.51\n",
      "Epoch:  137 | Train loss: 1.479 | Train acc: 0.78 | Val loss: 1.673 | Val acc: 0.54\n",
      "Epoch:  138 | Train loss: 1.480 | Train acc: 0.76 | Val loss: 1.684 | Val acc: 0.48\n",
      "Epoch:  139 | Train loss: 1.471 | Train acc: 0.74 | Val loss: 1.682 | Val acc: 0.50\n",
      "Epoch:  140 | Train loss: 1.471 | Train acc: 0.74 | Val loss: 1.679 | Val acc: 0.51\n",
      "Epoch:  141 | Train loss: 1.440 | Train acc: 0.78 | Val loss: 1.657 | Val acc: 0.58\n",
      "Epoch:  142 | Train loss: 1.461 | Train acc: 0.76 | Val loss: 1.663 | Val acc: 0.57\n",
      "Epoch:  143 | Train loss: 1.431 | Train acc: 0.77 | Val loss: 1.677 | Val acc: 0.52\n",
      "Epoch:  144 | Train loss: 1.443 | Train acc: 0.81 | Val loss: 1.649 | Val acc: 0.57\n",
      "Epoch:  145 | Train loss: 1.439 | Train acc: 0.75 | Val loss: 1.660 | Val acc: 0.50\n",
      "Epoch:  146 | Train loss: 1.462 | Train acc: 0.78 | Val loss: 1.673 | Val acc: 0.49\n",
      "Epoch:  147 | Train loss: 1.469 | Train acc: 0.75 | Val loss: 1.682 | Val acc: 0.49\n",
      "Epoch:  148 | Train loss: 1.409 | Train acc: 0.79 | Val loss: 1.636 | Val acc: 0.56\n",
      "Epoch:  149 | Train loss: 1.442 | Train acc: 0.76 | Val loss: 1.677 | Val acc: 0.51\n",
      "Epoch:  150 | Train loss: 1.450 | Train acc: 0.76 | Val loss: 1.639 | Val acc: 0.56\n",
      "Epoch:  151 | Train loss: 1.435 | Train acc: 0.76 | Val loss: 1.658 | Val acc: 0.48\n",
      "Epoch:  152 | Train loss: 1.433 | Train acc: 0.77 | Val loss: 1.652 | Val acc: 0.57\n",
      "Epoch:  153 | Train loss: 1.393 | Train acc: 0.81 | Val loss: 1.626 | Val acc: 0.56\n",
      "Epoch:  154 | Train loss: 1.400 | Train acc: 0.78 | Val loss: 1.629 | Val acc: 0.57\n",
      "Epoch:  155 | Train loss: 1.414 | Train acc: 0.78 | Val loss: 1.663 | Val acc: 0.50\n",
      "Epoch:  156 | Train loss: 1.397 | Train acc: 0.79 | Val loss: 1.624 | Val acc: 0.58\n",
      "Epoch:  157 | Train loss: 1.397 | Train acc: 0.74 | Val loss: 1.638 | Val acc: 0.50\n",
      "Epoch:  158 | Train loss: 1.379 | Train acc: 0.79 | Val loss: 1.644 | Val acc: 0.53\n",
      "Epoch:  159 | Train loss: 1.379 | Train acc: 0.76 | Val loss: 1.616 | Val acc: 0.56\n",
      "Epoch:  160 | Train loss: 1.376 | Train acc: 0.79 | Val loss: 1.610 | Val acc: 0.59\n",
      "Epoch:  161 | Train loss: 1.406 | Train acc: 0.79 | Val loss: 1.615 | Val acc: 0.55\n",
      "Epoch:  162 | Train loss: 1.374 | Train acc: 0.81 | Val loss: 1.618 | Val acc: 0.57\n",
      "Epoch:  163 | Train loss: 1.369 | Train acc: 0.78 | Val loss: 1.609 | Val acc: 0.55\n",
      "Epoch:  164 | Train loss: 1.375 | Train acc: 0.77 | Val loss: 1.615 | Val acc: 0.57\n",
      "Epoch:  165 | Train loss: 1.393 | Train acc: 0.77 | Val loss: 1.611 | Val acc: 0.55\n",
      "Epoch:  166 | Train loss: 1.344 | Train acc: 0.82 | Val loss: 1.598 | Val acc: 0.57\n",
      "Epoch:  167 | Train loss: 1.348 | Train acc: 0.79 | Val loss: 1.596 | Val acc: 0.60\n",
      "Epoch:  168 | Train loss: 1.343 | Train acc: 0.75 | Val loss: 1.613 | Val acc: 0.57\n",
      "Epoch:  169 | Train loss: 1.338 | Train acc: 0.78 | Val loss: 1.585 | Val acc: 0.55\n",
      "Epoch:  170 | Train loss: 1.313 | Train acc: 0.80 | Val loss: 1.584 | Val acc: 0.60\n",
      "Epoch:  171 | Train loss: 1.350 | Train acc: 0.76 | Val loss: 1.604 | Val acc: 0.56\n",
      "Epoch:  172 | Train loss: 1.299 | Train acc: 0.82 | Val loss: 1.573 | Val acc: 0.61\n",
      "Epoch:  173 | Train loss: 1.316 | Train acc: 0.84 | Val loss: 1.572 | Val acc: 0.62\n",
      "Epoch:  174 | Train loss: 1.298 | Train acc: 0.84 | Val loss: 1.569 | Val acc: 0.60\n",
      "Epoch:  175 | Train loss: 1.309 | Train acc: 0.83 | Val loss: 1.571 | Val acc: 0.60\n",
      "Epoch:  176 | Train loss: 1.305 | Train acc: 0.84 | Val loss: 1.554 | Val acc: 0.64\n",
      "Epoch:  177 | Train loss: 1.344 | Train acc: 0.77 | Val loss: 1.599 | Val acc: 0.58\n",
      "Epoch:  178 | Train loss: 1.320 | Train acc: 0.85 | Val loss: 1.566 | Val acc: 0.60\n",
      "Epoch:  179 | Train loss: 1.354 | Train acc: 0.80 | Val loss: 1.571 | Val acc: 0.60\n",
      "Epoch:  180 | Train loss: 1.322 | Train acc: 0.80 | Val loss: 1.566 | Val acc: 0.61\n",
      "Epoch:  181 | Train loss: 1.298 | Train acc: 0.83 | Val loss: 1.572 | Val acc: 0.61\n",
      "Epoch:  182 | Train loss: 1.300 | Train acc: 0.82 | Val loss: 1.556 | Val acc: 0.64\n",
      "Epoch:  183 | Train loss: 1.288 | Train acc: 0.79 | Val loss: 1.566 | Val acc: 0.58\n",
      "Epoch:  184 | Train loss: 1.287 | Train acc: 0.82 | Val loss: 1.572 | Val acc: 0.56\n",
      "Epoch:  185 | Train loss: 1.293 | Train acc: 0.84 | Val loss: 1.546 | Val acc: 0.59\n",
      "Epoch:  186 | Train loss: 1.257 | Train acc: 0.85 | Val loss: 1.526 | Val acc: 0.63\n",
      "Epoch:  187 | Train loss: 1.259 | Train acc: 0.86 | Val loss: 1.517 | Val acc: 0.64\n",
      "Epoch:  188 | Train loss: 1.254 | Train acc: 0.81 | Val loss: 1.527 | Val acc: 0.63\n",
      "Epoch:  189 | Train loss: 1.258 | Train acc: 0.83 | Val loss: 1.532 | Val acc: 0.60\n",
      "Epoch:  190 | Train loss: 1.272 | Train acc: 0.82 | Val loss: 1.539 | Val acc: 0.62\n",
      "Epoch:  191 | Train loss: 1.254 | Train acc: 0.84 | Val loss: 1.528 | Val acc: 0.61\n",
      "Epoch:  192 | Train loss: 1.276 | Train acc: 0.83 | Val loss: 1.547 | Val acc: 0.59\n",
      "Epoch:  193 | Train loss: 1.262 | Train acc: 0.84 | Val loss: 1.538 | Val acc: 0.62\n",
      "Epoch:  194 | Train loss: 1.236 | Train acc: 0.84 | Val loss: 1.526 | Val acc: 0.60\n",
      "Epoch:  195 | Train loss: 1.267 | Train acc: 0.84 | Val loss: 1.533 | Val acc: 0.60\n",
      "Epoch:  196 | Train loss: 1.229 | Train acc: 0.86 | Val loss: 1.500 | Val acc: 0.64\n",
      "Epoch:  197 | Train loss: 1.233 | Train acc: 0.85 | Val loss: 1.517 | Val acc: 0.66\n",
      "Epoch:  198 | Train loss: 1.241 | Train acc: 0.86 | Val loss: 1.521 | Val acc: 0.61\n",
      "Epoch:  199 | Train loss: 1.250 | Train acc: 0.85 | Val loss: 1.523 | Val acc: 0.62\n",
      "Total training time: 1.74 seconds\n",
      "\n",
      "Test loss: 1.479  |  Test acc: 0.70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_acc</td><td>▁▁▂▂▃▃▃▃▃▄▄▄▄▅▄▅▅▅▅▅▆▇▆▆▇▆▇▇▇▇█▇▇▇█▇▇███</td></tr><tr><td>training_loss</td><td>████▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▇▆▆▇▆▇▇█▇▇███</td></tr><tr><td>val_loss</td><td>██████▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>training_acc</td><td>0.85</td></tr><tr><td>training_loss</td><td>1.24974</td></tr><tr><td>val_acc</td><td>0.622</td></tr><tr><td>val_loss</td><td>1.52343</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polished-sweep-16</strong> at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run/runs/lsns8dml' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run/runs/lsns8dml</a><br/> View project at: <a href='https://wandb.ai/team9449/dl-gcn-project-final-run' target=\"_blank\">https://wandb.ai/team9449/dl-gcn-project-final-run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_234542-lsns8dml/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features, labels, adj, edges = load_data(configg)\n",
    "visualize_graph(edges, labels.cpu().tolist(), save=False)\n",
    "NUM_CLASSES = int(labels.max().item() + 1)\n",
    "\n",
    "train_set_ind, val_set_ind, test_set_ind = prepare_dataset(labels, NUM_CLASSES, configg)\n",
    "\n",
    "def sweepFunction(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        model = GCN(features.shape[1], configg.hidden_dim, NUM_CLASSES, configg.dropout, configg.use_bias)\n",
    "        val_acc, val_loss = training_loop(model, features, labels, adj, train_set_ind, val_set_ind, configg, config.epochh, config.optimizerval, config.lrval)\n",
    "        out_features = evaluate_on_test(model, features, labels, adj, test_set_ind, configg)\n",
    "        \n",
    "        # visualize_validation_performance(val_acc, val_loss)\n",
    "        # visualize_embedding_tSNE(labels, out_features, NUM_CLASSES)\n",
    "\n",
    "wandb.agent(sweep_id, sweepFunction, count=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56114df5-f8bb-4b3f-bb61-6ab99f0555f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envpls",
   "language": "python",
   "name": "envpls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
